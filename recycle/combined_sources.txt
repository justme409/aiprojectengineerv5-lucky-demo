PROMPT = r"""
You are generating a Construction Program summary as structured JSON using the shared plan schema (title, revision?, metadata?, sections[] with nested content blocks: text, bullets, numbered, table, note, link). Return ONLY valid JSON.
"""



PROMPT = r"""
You are generating an Environmental Management Plan (EMP/CEMP) as structured JSON using the shared plan schema (title, revision?, metadata?, sections[] with nested content blocks: text, bullets, numbered, table, note, link).

Structured output requirements:
- Return ONLY valid JSON (no prose outside the JSON object).
- Must conform exactly to the PlanJson schema.
- Use only allowed content block types.
- Organize sections cleanly and avoid duplication.

QSE system usage (critical):
- The prompt context includes a QSE SYSTEM REFERENCE adjacency list of corporate procedures/templates/pages.
- Heavily leverage existing corporate procedures/templates when relevant by inserting link blocks to those items using their title and path.
- Do not fabricate links; only reference items present in the QSE SYSTEM REFERENCE.
- If no relevant QSE item exists, derive content from PROJECT DOCUMENTS and best practice; include a brief note indicating project-specific development where needed.

Use the most relevant jurisdictional template below (QLD, SA, TAS, WA). If none applies, use the Generic template. Populate and expand sections based on PROJECT DOCUMENTS. Do not include any instructional text in the output; return only the final PlanJson object.

--- TEMPLATE: QLD (MRTS51) ---
{
  "title": "Queensland Environmental Management Plan (EMP) — Layout (MRTS51)",
  "revision": "March 2025",
  "metadata": {
    "jurisdiction": "QLD",
    "agency": "Department of Transport and Main Roads",
    "source_document": "MRTS51 Environmental Management"
  },
  "sections": [
    { "id": "intro", "title": "Introduction" },
    { "id": "definitions", "title": "Definitions" },
    { "id": "references", "title": "References" },
    { "id": "standard-test-methods", "title": "Standard Test Methods and Compliance Testing" },
    {
      "id": "quality-system-requirements",
      "title": "Quality System Requirements",
      "children": [
        { "id": "hold-points-and-milestones", "title": "Hold Points and Milestones" },
        { "id": "nonconformances", "title": "Non-conformances with Specification" }
      ]
    },
    {
      "id": "empc-governance",
      "title": "EMP(C) Governance",
      "children": [
        { "id": "empc-general", "title": "General Requirements" },
        { "id": "contract-specific-reqs", "title": "Contract-Specific Requirements (Annexure MRTS51.1)" },
        { "id": "empc-development", "title": "EMP(C) Development and Content" },
        { "id": "empc-updates", "title": "EMP(C) Updates and Version Control" }
      ]
    },
    {
      "id": "empc-admin",
      "title": "EMP(C) Administrative Requirements",
      "children": [
        { "id": "legal-compliance", "title": "Legal and Other Compliance" },
        { "id": "document-control", "title": "Document Control and Records" },
        { "id": "admin-nonconformance", "title": "Non-conformance Management" },
        { "id": "surveillance-audits", "title": "Principal’s Surveillance and Audits" },
        { "id": "monthly-reporting", "title": "Monthly Environmental Reporting" },
        { "id": "complaints", "title": "Complaints Management" },
        { "id": "incident-notification", "title": "Notification and Management of Environmental & Cultural Heritage Incidents" },
        { "id": "stormwater-deposition", "title": "Construction Stormwater and Deposition of Surplus Material" },
        { "id": "fauna-spotter", "title": "Fauna Spotter-Catcher (as applicable)" },
        { "id": "biosecurity-admin", "title": "Biosecurity Management (Admin Duties)" },
        { "id": "sensitive-receptors", "title": "Sensitive Receptors Identification / Mapping" },
        { "id": "site-induction", "title": "Site Induction and Training" }
      ]
    },
    {
      "id": "environmental-elements",
      "title": "EMP(C) Specific Environmental Element Requirements",
      "children": [
        { "id": "water-quality", "title": "Water Quality (Criteria, Monitoring, EMP Requirements)" },
        { "id": "erosion-sediment", "title": "Erosion and Sedimentation (link to MRTS52 where applicable)" },
        { "id": "cultural-heritage", "title": "Cultural Heritage" },
        { "id": "noise", "title": "Noise (incl. TNM CoP V2 where specified)" },
        { "id": "vibration", "title": "Vibration (Human Comfort & Structural)" },
        { "id": "air-quality", "title": "Air Quality and Dust" },
        { "id": "acid-sulfate", "title": "Acid Sulfate Soils" },
        { "id": "contaminated-sites", "title": "Contaminated Sites (incl. asbestos where applicable)" },
        { "id": "native-fauna", "title": "Native Fauna" },
        { "id": "vegetation", "title": "Vegetation Management and Clearing Limits" },
        { "id": "biosecurity", "title": "Biosecurity (Weeds, Pests, Pathogens)" },
        { "id": "waste-resource", "title": "Waste and Resource Management" },
        { "id": "chemicals-fuels", "title": "Chemicals and Fuels" },
        { "id": "materials-sourcing", "title": "Sourcing of Construction Materials (Non-commercial Sources)" }
      ]
    }
  ]
}

--- TEMPLATE: SA (PC-ENV1) ---
{
  "title": "South Australia Environmental Management Plan (EMP) — Layout (PC-ENV1)",
  "revision": "September 2024",
  "metadata": {
    "jurisdiction": "SA",
    "agency": "Department for Infrastructure and Transport",
    "source_document": "Master Specification Part PC-ENV1 Environmental Management"
  },
  "sections": [
    { "id": "general", "title": "General" },
    {
      "id": "documentation",
      "title": "Documentation",
      "children": [
        { "id": "cemp", "title": "Contractor’s Environmental Management Plan (CEMP)" },
        { "id": "quality-records", "title": "Quality Management Records" }
      ]
    },
    { "id": "contractor-obligations", "title": "Contractor’s Environmental Obligations" },
    { "id": "authorisations", "title": "Environmental Authorisations (Approvals, Licences, Permits)" },
    { "id": "objectives", "title": "Environmental Objectives" },
    { "id": "ems", "title": "Environmental Management System (AS/NZS ISO 14001 Certification)" },
    {
      "id": "personnel",
      "title": "Contractor’s Personnel",
      "children": [
        { "id": "emr", "title": "Environmental Management Representative (EMR)" }
      ]
    },
    {
      "id": "training-induction",
      "title": "Training and Induction",
      "children": [
        { "id": "awareness-training", "title": "Environmental Awareness Training" },
        { "id": "induction", "title": "Environmental Induction" }
      ]
    },
    {
      "id": "inspection-audit-reporting",
      "title": "Inspections, Auditing and Reporting",
      "children": [
        { "id": "inspections", "title": "Environmental Inspections (incl. erosion/sediment devices)" },
        { "id": "audits", "title": "Environmental Audits (AS/NZS ISO 19011)" },
        { "id": "veg-removal-register", "title": "Vegetation Removal Register" },
        { "id": "monthly-status", "title": "Monthly Environmental Performance Status Report" }
      ]
    },
    { "id": "emergency-response", "title": "Environmental Emergency Response (incl. marine spills)" },
    { "id": "hold-witness-points", "title": "Hold Points and Witness Points" },
    {
      "id": "issue-specific-subplans",
      "title": "Issue-Specific Sub-plans",
      "content": [
        {
          "type": "note",
          "text": "Prepare issue-specific sub-plans as required by PC-ENV2 Environmental Protection Requirements and referenced guidelines."
        }
      ]
    }
  ]
}

--- TEMPLATE: TAS (Section 176) ---
{
  "title": "Tasmania Environmental Management Plan (EMP) — Layout (Section 176)",
  "revision": "June 2024",
  "metadata": {
    "jurisdiction": "TAS",
    "agency": "Department of State Growth",
    "source_document": "Section 176 Environmental Management"
  },
  "sections": [
    {
      "id": "part-a",
      "title": "Part A — Environmental Management",
      "children": [
        { "id": "a1-intro", "title": "176.A1 Introduction" },
        { "id": "a2-definitions", "title": "176.A2 Definitions" },
        { "id": "a3-emp", "title": "176.A3 Environmental Management Plan (EMP) Requirements" },
        { "id": "a4-training", "title": "176.A4 Training (competence; erosion/sediment control card)" }
      ]
    },
    {
      "id": "part-b",
      "title": "Part B — Water Quality",
      "children": [
        { "id": "b1-water-quality", "title": "176.B1 Water Quality (criteria, monitoring, dewatering)" }
      ]
    },
    {
      "id": "part-c",
      "title": "Part C — Air Quality",
      "children": [
        { "id": "c1-dust", "title": "176.C1 Dust and Air Emissions" }
      ]
    },
    {
      "id": "part-d",
      "title": "Part D — Erosion and Sediment Control",
      "children": [
        { "id": "d1-esc", "title": "176.D1 Erosion and Sediment Control (references, inspections)" },
        { "id": "d2-stockpiles", "title": "176.D2 Stockpiles" },
        { "id": "d3-mud-on-roads", "title": "176.D3 Mud on Public Roads" }
      ]
    },
    {
      "id": "part-e",
      "title": "Part E — Contaminated Soils and Materials",
      "children": [
        { "id": "e1-contaminated", "title": "176.E1 Contaminated Soils and Materials" }
      ]
    },
    {
      "id": "part-f",
      "title": "Part F — Waste and Resource Use",
      "children": [
        { "id": "f1-waste", "title": "176.F1 Waste and Resource Reuse (monitoring)" }
      ]
    },
    {
      "id": "part-g",
      "title": "Part G — Fuels and Chemicals",
      "children": [
        { "id": "g1-fuels-chemicals", "title": "176.G1 Fuels and Chemicals (storage, refuelling, spill kits, monitoring)" }
      ]
    },
    {
      "id": "part-h",
      "title": "Part H — Noise and Vibration",
      "children": [
        { "id": "h1-noise", "title": "176.H1 Noise (controls, scheduling, notifications)" },
        { "id": "h2-vibration", "title": "176.H2 Vibration (criteria, monitoring)" },
        { "id": "h3-blasting", "title": "176.H3 Blasting (limits and monitoring)" }
      ]
    },
    {
      "id": "part-i",
      "title": "Part I — Flora and Fauna",
      "children": [
        { "id": "i1-flora-fauna", "title": "176.I1 Flora and Fauna (no-go zones, inspections)" },
        { "id": "i2-weed-pest-disease", "title": "176.I2 Weed, Pest and Disease Management (hygiene, washdown)" }
      ]
    },
    {
      "id": "part-j",
      "title": "Part J — Cultural Heritage",
      "children": [
        { "id": "j1-general", "title": "176.J1 Cultural Heritage (protection, permits)" },
        { "id": "j2-protection", "title": "Protection of Values and No-Go Zones" },
        { "id": "j3-unanticipated-discovery", "title": "Unanticipated Discovery Plan (items and skeletal remains)" },
        { "id": "j4-monitoring", "title": "Monitoring of No-Go Zones" }
      ]
    },
    {
      "id": "part-k",
      "title": "Part K — Reporting",
      "children": [
        { "id": "k1-reporting", "title": "176.K1 Reporting (tables; frequencies; regulator notices)" }
      ]
    }
  ]
}

--- TEMPLATE: WA (Spec 204) ---
{
  "title": "Western Australia Environmental Management Plan (EMP) — Layout (Spec 204)",
  "revision": "August 2020",
  "metadata": {
    "jurisdiction": "WA",
    "agency": "Main Roads Western Australia",
    "source_document": "Specification 204 Environmental Management (Major Works)"
  },
  "sections": [
    { "id": "scope", "title": "Scope and Applicability (ISO 14001 aligned)" },
    { "id": "policy", "title": "Main Roads Environmental Policy" },
    { "id": "commitment", "title": "Environmental Management Commitment Statement" },
    {
      "id": "planning",
      "title": "Planning",
      "children": [
        { "id": "legal-other", "title": "Legal and Other Compliance Requirements" },
        { "id": "risks-opportunities", "title": "Risks and Opportunities Assessment" },
        { "id": "cemp", "title": "Construction Environmental Management Plan (CEMP) Development and Approval" }
      ]
    },
    {
      "id": "implementation",
      "title": "Implementation",
      "children": [
        { "id": "roles-resp", "title": "Roles and Responsibilities (EMR, Top Management, subcontractors)" },
        { "id": "training", "title": "Training and Competency (Site Induction, evaluation)" },
        { "id": "communication", "title": "Communication (internal/external; regulators via Principal)" },
        { "id": "documentation", "title": "Documentation and Control of Records" },
        { "id": "operational-controls", "title": "Construction Environmental Operational Controls" },
        { "id": "emergency", "title": "Emergency Preparedness and Response" },
        { "id": "incidents", "title": "Environmental Incidents (EQSafe reporting; timeframes)" }
      ]
    },
    {
      "id": "measurement-evaluation",
      "title": "Measurement and Evaluation",
      "children": [
        { "id": "monitoring-measurement", "title": "Monitoring and Measurement (Monthly reporting)" },
        { "id": "audit", "title": "Environmental Audit (schedule; frequency; reports)" },
        { "id": "nonconformance-capa", "title": "Non-conformance and Corrective/Preventative Action" }
      ]
    },
    {
      "id": "management-review",
      "title": "Management Review and Continual Improvement",
      "children": [
        { "id": "review", "title": "Periodic Review (timing; inputs; outputs)" },
        { "id": "continual-improvement", "title": "Continual Improvement Actions" }
      ]
    },
    { "id": "handover", "title": "As-Built and Handover Requirements" },
    {
      "id": "principal-reqs",
      "title": "Annexure 204B — Principal Environmental Management Requirements",
      "content": [
        {
          "type": "bullets",
          "items": [
            "Aboriginal Heritage",
            "Acid Sulfate Soils",
            "Camps and Site Offices",
            "Clearing",
            "Communication",
            "Contamination",
            "Dewatering",
            "Demolition",
            "Dieback Management",
            "Documentation Management",
            "Dust Management",
            "Energy Management",
            "Erosion and Sedimentation Control",
            "European Heritage",
            "Fauna Management",
            "Fencing Installation",
            "Fire Management",
            "Handover Requirements",
            "Hazardous Materials",
            "Induction and Pre-Starts",
            "Machinery and Vehicle Management",
            "Mulch and Topsoil Management",
            "Noise Management",
            "Pegging and Flagging",
            "Pit Management (see Spec 303)",
            "Pre-coating",
            "Pre-construction",
            "Property Condition Survey",
            "Revegetation",
            "Road Marking",
            "Sealing, Priming and Sweeping",
            "Sidetracks and Temporary Access",
            "Special Environmental Areas",
            "Spill Management",
            "Spoil Management",
            "Stockpiles",
            "Traffic Management",
            "Vibration Management",
            "Waste Management",
            "Water Abstraction and Storage",
            "Water Drainage Management",
            "Water Reuse / Efficiency",
            "Weed Management",
            "Other Project-Specific Requirements"
          ]
        },
        { "type": "note", "text": "Use Annexure 204A CEMP Template sections and populate with project-specific operational controls and Hold Points." }
      ]
    }
  ]
}

--- TEMPLATE: GENERIC (Consolidated) ---
{
  "title": "Generic Environmental Management Plan (EMP) — Consolidated Layout",
  "metadata": {
    "jurisdiction": "Generic",
    "source_basis": "QLD MRTS51; SA PC-ENV1; TAS Section 176; WA Spec 204",
    "standards": "AS/NZS ISO 14001; AS/NZS ISO 19011; AS/NZS ISO 31000 (risk)"
  },
  "sections": [
    {
      "id": "governance-context",
      "title": "Governance and Context",
      "children": [
        { "id": "introduction", "title": "Introduction, Scope and Objectives" },
        { "id": "definitions-acronyms", "title": "Definitions and Acronyms" },
        { "id": "legal-other-reqs", "title": "Legal and Other Requirements (Approvals, permits, licences)" },
        { "id": "roles-responsibilities", "title": "Roles and Responsibilities (Top Management, EMR, subcontractors)" },
        { "id": "training-induction", "title": "Training and Induction (competency; awareness)" },
        { "id": "document-records", "title": "Document and Records Management (version control)" }
      ]
    },
    {
      "id": "emp-administration",
      "title": "EMP Administration and Quality",
      "children": [
        { "id": "quality-system", "title": "Quality System Requirements (Hold/Witness Points; milestones)" },
        { "id": "nonconformance", "title": "Non-conformances and Corrective Actions" },
        { "id": "audits-surveillance", "title": "Audits and Surveillance (internal/external)" },
        { "id": "reporting", "title": "Reporting (monthly; status; KPIs)" },
        { "id": "complaints-community", "title": "Complaints and Community Engagement" },
        { "id": "incident-management", "title": "Incident Notification and Management (environmental and cultural heritage)" },
        { "id": "emergency-preparedness", "title": "Emergency Preparedness and Response" }
      ]
    },
    {
      "id": "environmental-elements",
      "title": "Environmental Elements and Controls",
      "children": [
        { "id": "water-quality", "title": "Water Quality (criteria; monitoring; dewatering)" },
        { "id": "erosion-sediment", "title": "Erosion and Sediment Control" },
        { "id": "air-quality", "title": "Air Quality and Dust" },
        { "id": "noise", "title": "Noise" },
        { "id": "vibration", "title": "Vibration (human comfort; structural)" },
        { "id": "acid-sulfate", "title": "Acid Sulfate Soils" },
        { "id": "contaminated-land", "title": "Contaminated Land (incl. asbestos)" },
        { "id": "waste-resource", "title": "Waste and Resource Use (hierarchy; transport)" },
        { "id": "chemicals-fuels", "title": "Chemicals and Fuels (storage; refuelling; spill response)" },
        { "id": "vegetation", "title": "Vegetation Management (clearing limits; offsets/registers)" },
        { "id": "biodiversity-fauna", "title": "Biodiversity and Fauna (no-go zones; spotter-catchers)" },
        { "id": "biosecurity", "title": "Biosecurity (weeds, pests, diseases; hygiene)" },
        { "id": "cultural-heritage", "title": "Cultural Heritage (protection; unanticipated discovery)" },
        { "id": "dewatering", "title": "Dewatering and Water Drainage Management" },
        { "id": "materials-sourcing", "title": "Materials Sourcing (non-commercial; pits; approvals)" },
        { "id": "stockpiles-traffic", "title": "Stockpiles, Mud on Roads, Traffic and Access" },
        { "id": "special-areas", "title": "Special Environmental Areas / Sensitive Receptors" }
      ]
    },
    {
      "id": "monitoring-measurement",
      "title": "Monitoring and Measurement",
      "children": [
        { "id": "criteria", "title": "Performance Criteria and Compliance Testing" },
        { "id": "frequencies-locations", "title": "Frequencies, Locations, Methods and Equipment" },
        { "id": "data-management", "title": "Data Management, Evaluation and Trend Analysis" }
      ]
    },
    {
      "id": "review-improvement",
      "title": "Management Review and Continual Improvement",
      "children": [
        { "id": "periodic-review", "title": "Periodic Review (inputs; outputs; decisions)" },
        { "id": "continual-improvement", "title": "Continual Improvement Opportunities and Actions" }
      ]
    },
    { "id": "handover-closeout", "title": "Handover, As-Builts and Close-Out" }
  ]
}
"""



GENERATE_ITP_PROMPT = """
Generate ITP using: {input}
"""
# Description: Prompts for generate_itp.
# Source: From agents V7 itp_prompt_v2.py. METADATA_CARDS_PROMPT = """
Generate metadata cards for WBS/LBS: {input}
"""
# Description: Prompts for generating WBS/LBS metadata cards.
# Source: From agents V7 relevant prompts. ITP_GENERATION_PROMPT = """
Generate ITP based on: {input}
"""
# Description: Prompts for ITP generation.
# Source: From agents V7 itp prompts. """
ITP Generation Prompt V2

This module contains the enhanced prompt for ITP generation with improved context and structure.
Combines professional ITP examples, Australian civil construction context, and modern data structures.
"""

CONSOLIDATED_ITP_PROMPT_V2 = """
UNDERSTANDING INSPECTION & TEST PLANS (ITPs) IN AUSTRALIAN CIVIL CONSTRUCTION (ESSENTIAL CONTEXT FOR YOUR TASK):
An Inspection and Test Plan (ITP) is a formal quality‐assurance document created for a specific project scope. It details all inspections and tests required to demonstrate that the work meets its contractual and regulatory requirements. In practice, an ITP "maps out inspection and testing checkpoints from start to finish" of a process. Under ISO 9001:2016 (AS/NZS ISO 9001) and typical contract Quality Management System (QMS) clauses, contractors must plan and control all production processes. Preparing ITPs is one way to fulfill ISO 9001 Clause 8 (operational planning and control) by documenting who will do each inspection, how it is done, and what the acceptance criteria are. In short, an ITP is a proactive quality control strategy to ensure each phase of construction meets the required standards. It serves two main purposes: (a) to confirm that the contractor's in-process controls are effective, and (b) to verify that incoming materials and completed work pass specified acceptance criteria.

**When Are ITPs Required?**
ITPs are required whenever the project or applicable standards call for documented verification of quality. Key triggers include:
*   **Standards and Quality Systems:** ISO 9001 (AS/NZS ISO 9001) requires documented procedures for controlling processes and verifying outputs. Construction standards (e.g. AS 3600 for concrete, AS/NZS 5131 for steel, AS 3798 for earthworks, AS 2159 for piling, etc.) specify technical criteria (compressive strengths, dimensional tolerances, test methods) that must be tested or inspected. In many projects the QMS and specifications explicitly call for ITPs to cover all required tests. For example, AS/NZS 5131 (structural steel) mandates weld inspection; Main Roads WA's steelwork spec even requires the contractor to submit an ITP for weld testing in accordance with AS/NZS 5131. Similarly, AS 1379 and AS 3600 require concrete slump and cylinder tests; an ITP will schedule those tests and record their results.
*   **Contract Specifications:** Project contracts almost always include quality clauses. Major road and bridge specifications (e.g. RMS/Austroads specifications) often list mandatory hold/witness points and require an ITP or Quality Plan. For instance, NSW government GC21 "Quality Management" clauses instruct contractors to prepare a Quality Management Plan and Inspection and Test Plans covering the works. The NSW Government Quality Management Guidelines explicitly require contractors to "Submit Inspection and Test Plans (plus any associated checklists) for specified activities ... at least 14 days prior to work" and to "incorporate the listed Hold and Witness points". Many state road authorities similarly identify critical operations (e.g. weld fabrication, concrete pours, specialized surfacing) in their specifications and require a pre-approved ITP for those works. As one example, Northern Territory roadworks specs require an ITP demonstrating compliance for Polymer-Modified Bitumen production and testing.
*   **Typical Civil Activities:** In practice, ITPs are usually required for major or safety‐critical operations. Common examples include concrete works (formwork, reinforcement placement, pouring and curing, including slump and strength tests), steel fabrication and erection (welds, bolt torque, dimensional checks), pavements and earthworks (layer thickness, density and compaction testing per AS 1289/AS 1141), drainage and pipeline installation (pipe alignment, joint testing), piling and foundations (borehole inspection, load tests), and electrical or mechanical installations (functional tests). If a scope item like a large concrete pour or crane lift is in the contract, the ITP must cover it with the appropriate inspections. For example, before a concrete pour the ITP will list a slump test with its required range; for a heavy bridge lift the ITP will include a pre-lift check of rigging as a hold point. (If unsure, one should consult the project specification and standards: if either sets specific testing or hold-point requirements for the activity, an ITP entry is needed.)
*   **Hold and Witness Points:** Contracts define Hold points (mandatory pauses) and Witness points (optional inspections) at critical stages. By definition, work cannot proceed past a hold point without the principal's or supervisor's approval. Whenever the specification or contract contains hold/witness points for a work item, the contractor's ITP must reflect them. In the ITP each hold point is explicitly flagged (often with an "H" in a column) and requires an inspector's signature before continuing. Witness points (marked "W") indicate the client or engineer may attend for inspection, but work may continue if they choose not to. NATSPEC notes that all such verification procedures are documented in the contract Inspection and Test Plan. In summary, any activity with a specified hold or witness trigger must have a corresponding entry in the ITP table.

**Structure and Content of an ITP (Context for your reasoning - you are NOT building the ITP itself):**
A well-structured ITP is usually organized as a table or checklist covering each inspection/test step. It typically includes:
*   **Scope of Work and Task Breakdown:** Defines the scope covered (e.g. "Bridge pier concrete pour – pours C1–C5") and breaks work into distinct activities/inspection points (e.g. "Formwork erected", "Rebar tied").
*   **Inspection/Test Methods and Criteria:** Specifies how inspection/test is done (e.g. AS 1012 test method, visual check, NDT), frequency, and acceptance criteria (numeric values, standards limits, written out in full).
*   **Acceptance Criteria and Records:** Clear pass/fail criteria. Columns for actual measurement/result, acceptance checkbox/signature. Certifications/test reports attached/referenced. Failed inspections trigger Non-Conformance Reports (NCRs).
*   **Responsibilities and Sign-offs:** Identifies who performs/reviews each inspection/test (e.g. "Contractor QC inspector", "Third-party NDT inspector"). Columns for inspector's signature/initials/date, and approving authority's sign-off.
*   **Hold, Witness, and Review Points:** Columns (H, W, R) for Hold (approval required to proceed), Witness (client may attend), and Review points. All contractual H/W points must be in the ITP.

**DATA STRUCTURE DEFINITIONS:**
Each ITP item should conform to the following structure:
- thinking: Optional[str] = A placeholder reasoning, to be set to null.
- id: str = A simple identifier for this item (e.g., 'section_1', 'item_1_1')
- parentId: Optional[str] = The parent item simple ID (null for top-level sections)
- type: str = Item type: 'section' for headers, 'inspection' for rows
- item_no: str = Hierarchical number (e.g., '1.0', '1.1', '2.0', '2.1')
- order_index: int = Order within the parent level for sorting
- section_name: Optional[str] = Name of the section (only for type='section')
- inspection_test_point: Optional[str] = What is being inspected or tested
- acceptance_criteria: Optional[str] = Criteria that must be met
- specification_clause: Optional[str] = Referenced specification clause
- inspection_test_method: Optional[str] = How the inspection/test is performed
- frequency: Optional[str] = How often the inspection occurs
- responsibility: Optional[str] = Who is responsible for the inspection
- hold_witness_point: Optional[str] = Hold or witness point classification

You are an expert civil engineering consultant tasked with generating a detailed, industry-standard Inspection and Test Plan (ITP) based on specific project data. Your output MUST emulate the style, level of detail, and precise formatting of professional engineering ITP examples provided in the User Query.

1.  **Preliminaries & Approvals: (If relevant)**
2.  **Materials: (If physical works involving materials)**
3.  **Pre-Construction: (If site work preparation is involved)**
4.  **Construction: (If physical works/installation)**
5.  **Geometrics/Tolerances: (If dimensional accuracy is critical)**
6.  **Conformance/Lot Completion: (Mandatory if work performed)**

## DETAILED FIELD-BY-FIELD INSTRUCTIONS

### `thinking: Optional[str]`
- **Instruction:** This is a field for reasoning. For this task, you MUST set this field to `null`.

### `id: str`
- **Instruction:** Provide a unique, simple string identifier for each item. For sections, use the format 'section_X' (e.g., 'section_1', 'section_2'). For inspection items, use 'item_X_Y' (e.g., 'item_1_1', 'item_1_2'), where X is the section number and Y is the item number within that section. This is critical for creating the hierarchy.

### `parentId: Optional[str]`
- **Instruction:** For top-level section items, this field MUST be `null`. For all child inspection items, this MUST be the `id` of the parent section (e.g., 'section_1'). The presence of a `parentId` indicates an inspection item, while its absence (`null`) indicates a section header.

### `item_no: str`
- **Instruction:** Use hierarchical numbering. For section headers, use "1.0", "2.0", etc., sequentially. For inspection items, use "1.1", "1.2", "2.1", etc., corresponding to the parent section. This is a placeholder; final numbering is done later.

### `section_name: Optional[str]`
- **Instruction:** Only populate this field for items that are section headers (when `parentId` is `null`). The name MUST be one of the following options, used in this specific order. This field must be `null` for inspection items.
  - "Preliminaries & Approvals"
  - "Materials"
  - "Pre-Construction"
  - "Construction"
  - "Geometrics/Tolerances"
  - "Conformance/Lot Completion"

### `inspection_test_point: Optional[str]`
- **Instruction:** For inspection items (when `parentId` is not `null`), this is a concise description of the check. Use clear action verbs (e.g., "Verify Excavation Depth"). For HOLD/WITNESS points, the description must be in ALL CAPS (e.g., 'HOLD POINT: SURVEY SET-OUT'). This field must be `null` for section headers.

### `acceptance_criteria: Optional[str]`
- **Instruction:** Provide specific, measurable criteria with values and tolerances from the source documents. Be specific and avoid vague terms. This must be `null` for section headers.

### `specification_clause: Optional[str]`
- **Instruction:** Reference the exact specification and clause number, like 'MRTS XX CL Y.Z' or 'Standard Drawing XXXX'. Separate multiple references with `\\n`. This must be `null` for `type: 'section'`.

### `inspection_test_method: Optional[str]`
- **Instruction:** This field describes *how* the inspection point is to be verified. It specifies the nature of the verification activity, answering the question: "Is it a physical test, a visual check, a measurement, or a review of documentation?" Use one of the following standard methods. This must be `null` for `type: 'section'`.
  - **`Visual Onsite`**: For visual inspections performed in the field (e.g., checking for cleanliness, correct installation).
  - **`Measurement`**: For checks involving taking physical measurements (e.g., dimensions, levels, clearances).
  - **`Doc Review`**: For verifying information from documents, reports, or certificates (e.g., checking material delivery dockets, compliance certificates).
  - **`NATA Testing ([Test Method])`**: For formal laboratory testing by an accredited body. The specific test method MUST be included in parentheses (e.g., 'NATA Testing (Q140A)', 'NATA Testing (AS 1012.9)').
  - **`Functional Test`**: For verifying that a system or component operates correctly as intended.
  - **`Survey`**: For checks requiring a formal survey pickup (e.g., set-out, as-built location).

### `frequency: Optional[str]`
- **Instruction:** This field defines how often the specified inspection or test must be performed, a detail typically found in the project specifications or standards. Your answer must be based on the source documents. If no frequency is explicitly stated, use a common-sense industry default like 'Per Lot'. This must be `null` for `type: 'section'`.
  - **`Per Lot / Batch`**: For activities managed in discrete lots or batches (e.g., 'Per Lot', 'Each Batch'). This is a common default.
  - **`Per Item / Delivery`**: For individual items or deliveries (e.g., 'Each Delivery', 'Each Precast Panel', 'Each Joint').
  - **`Volumetric`**: For tests related to volume (e.g., '1 test per 100m³ of fill', 'Every 50m³').
  - **`Linear`**: For tests related to length (e.g., 'Every 50m of pipe', '1 test per 200m').
  - **`Area`**: For tests related to area (e.g., '1 test per 500m²').
  - **`Temporal`**: For time-based checks (e.g., 'Continuously', 'Daily prior to work').
  - **`Event-based`**: For checks tied to specific events (e.g., 'Once prior to first use', 'Prior to concrete pour').

### `responsibility: Optional[str]`
- **Instruction:** Assign responsibility to a specific role within the *contractor's organization*. This is typically the person accountable for ensuring the task is completed correctly. This must be `null` for `type: 'section'`.
  - **`Contractor (Site Engineer)` or `Contractor (Project Engineer)`**: For most on-site activities and test coordination.
  - **`Contractor (Quality Manager)`**: For high-level reviews, document verification, and final approvals.
 
### `hold_witness_point: Optional[str]`
- **Instruction:** This field is critical and MUST be sourced *exclusively* from the project specifications or documents. Do NOT invent or infer these points. They represent mandatory quality checks by the client or their representative.
  - **`HOLD POINT`**: Use this when the specification mandates that work must stop and cannot proceed without formal approval. The reason MUST be included. (e.g., 'Yes - HOLD POINT: Awaiting concrete strength test results.'). The term "HOLD POINT" must be in all caps.
  - **`WITNESS POINT`**: Use this when the specification gives the client the right to witness an activity. The work can proceed if they choose not to attend. The notification requirement MUST be included. (e.g., 'Yes - WITNESS POINT: Notify Engineer 24 hours prior to pour.'). The term "WITNESS POINT" must be in all caps.
  - If no hold or witness point is specified in the documents for the activity, this field MUST be 'No'.
  - This must be `null` for `type: 'section'`.


"""


LBS_EXTRACTION_PROMPT = """
You are an expert spatial analysis architect specializing in creating comprehensive Location Breakdown Structures (LBS) for complex civil engineering projects. Your goal is to analyze project documentation (accessed via cache) and an existing Work Breakdown Structure (WBS) to create a systematic spatial hierarchy that maps physical construction locations to specific work packages with full traceability and reasoning.

Your task is to generate a Location Breakdown Structure (LBS) that organizes the project by actual physical construction locations and then maps each location to applicable work packages from the provided WBS, with comprehensive reasoning and source documentation.

UNDERSTANDING LOCATION BREAKDOWN STRUCTURE (LBS) - Essential Context:

- **Core Definition & Purpose:** A Location Breakdown Structure (LBS) is a hierarchical decomposition of a construction project's physical work locations, construction zones, and building components. It organizes work by "where construction activities will be performed" rather than "what" will be delivered. The LBS answers the critical question: "In what specific physical locations will construction work occur, and how should these locations be organized for optimal construction management?"

- **CRITICAL - Physical Construction Locations Focus:** The LBS must focus on ACTUAL PHYSICAL LOCATIONS where construction activities take place, derived from project documentation, NOT just theoretical spatial divisions. Examples:
  * **Dam Projects:** "Dam Foundation Excavation Zone", "Core Wall Construction Area (Ch. 0+050 to 0+180)", "Spillway Approach Channel", "Left Abutment Grouting Zone", "Outlet Works Chamber"
  * **Road/Bridge Projects:** "Embankment Section Ch. 1+200-1+800", "Bridge Abutment A Foundation", "Culvert Installation Zone Ch. 2+450", "Pavement Layer - Lane 1 Northbound", "Retaining Wall RW-03 Location"
  * **Building Projects:** "Foundation Level - Grid A1-D4", "Ground Floor Slab Pour Zone 1", "Level 2 Structural Frame", "Roof Plant Room", "Basement Car Park Area B"
  * **Infrastructure Projects:** "Pump Station Wet Well", "Pipeline Trench Section 1A", "Electrical Substation Foundation", "Access Road Intersection Node"

- **Construction Logic and Sequence Integration:** The LBS must reflect how construction would realistically be organized, considering:
  * **Construction Access:** How crews and equipment access different areas
  * **Work Sequence:** Logical progression of construction activities
  * **Resource Allocation:** How materials and labor are distributed across locations
  * **Quality Control Zones:** Areas requiring specific inspection and testing protocols
  * **Safety and Logistics:** Site organization for safe and efficient construction

- **Spatial Organization Principles:**
  * **Level 1:** Overall project site/facility boundary
  * **Level 2:** Major construction zones, structures, or linear sections
  * **Level 3:** Specific construction work areas within zones (by elevation, chainage, grid, etc.)
  * **Level 4+:** Detailed work locations where specific construction activities occur

- **Integration with Work Breakdown Structure:** While the WBS organizes by deliverables ("what" needs to be built), the LBS organizes by physical construction location ("where construction activities will be performed"). The mapping between LBS locations and WBS work packages creates a comprehensive matrix for construction planning, resource allocation, progress tracking, and quality management.

- **Document-Driven Spatial Analysis:** The LBS structure must be derived from and justified by the project documentation. This includes:
  * **Drawing References:** Site plans, structural drawings, architectural layouts
  * **Specification Sections:** Location-specific requirements and constraints
  * **Scope of Works:** Physical work area descriptions and boundaries
  * **Construction Methodology:** Sequence and staging requirements

Consider the following:

a. **Comprehensive Document Analysis for Spatial Understanding:** Discuss your interpretation of ALL provided documents (accessed via cache) and their spatial implications. Detail which documents provide critical spatial information and how they inform the physical construction environment. Explain the interrelationships between drawings, specifications, and scope documents in defining physical work locations.

b. **Construction Location Identification & Methodology:** Explain your systematic methodology for identifying actual construction locations from the documentation. Distinguish between:
   - **Primary Construction Zones:** Where major construction activities occur
   - **Support/Access Areas:** Required for construction logistics but not primary work locations
   - **Temporary Works Areas:** Necessary for construction but not permanent
   - **Utility/Services Locations:** Specific areas for infrastructure installation
   - **Quality Control Points:** Locations requiring specific inspection or testing

c. **Spatial Hierarchical Design Strategy:** Articulate your detailed strategy for organizing construction locations into a logical hierarchy. Explain why your chosen hierarchical model is optimal for this specific project, considering:
   - **Construction Sequence Logic:** How the hierarchy supports logical work progression
   - **Resource Management:** How spatial organization facilitates efficient resource allocation
   - **Progress Tracking:** How the structure enables effective construction monitoring
   - **Quality Management:** How locations align with inspection and testing requirements

d. **WBS Integration and Mapping Analysis:** Analyze how the provided WBS work packages relate to your identified construction locations. Explain your methodology for determining which work packages apply to which locations, considering:
   - **Spatial Applicability:** Which work packages can physically occur in each location
   - **Construction Logic:** How work package execution aligns with spatial organization
   - **Resource Efficiency:** How mapping optimizes construction resource utilization
   - **Quality Assurance:** How mapping supports inspection and testing workflows

e. **Ambiguity Resolution & Spatial Assumptions:** Address any ambiguities in the spatial organization, conflicting information in documents, or assumptions made due to incomplete spatial data. Explain how you resolved these issues and what impact they might have on the LBS structure.


INPUTS:
- PROJECT DOCUMENTS (raw text):

- WBS STRUCTURE (adjacency list JSON):

OUTPUT FORMAT (Adjacency List Requirement):
- You MUST return a FLAT ADJACENCY LIST of LBS nodes plus a mapping summary.
- Each node in the `nodes` array MUST have this schema:
  - `id: string` (UNIQUE within this output; parents reference this via `parentId`)
  - `parentId: string | null` (must reference an existing `id` in this same array; root has `null`)
  - `name: string`
  - `location_type: "site"|"zone"|"area"|"work_location"|"component"`
  - `description: string`
  - `applicable_wbs_package_ids: string[]` (populate ONLY for LEAF work locations, using EXACT ids of LEAF WBS nodes)
  - `_reasoning: string` (concise explanation with sources)
  - `_source_references: [{ source: string, hint: string }]` (optional)

VALIDATION RULES:
- `id` values must be unique within the array and used by `parentId` references.
- `applicable_wbs_package_ids` MUST reference ONLY WBS ids that are LEAF nodes in the provided WBS adjacency list.
- Do NOT invent arbitrary ids; use deterministic strings (e.g., slugified names with incremental suffixes) to ensure stability within this output.

LOT CARD GENERATION MODE (Unified Card Schema Override):
- For some runs, you will generate Lot Cards that directly include WBS details in each card while preserving ALL spatial reasoning and WBS integration guidance above.
- In this mode, IGNORE the "OUTPUT FORMAT (Adjacency List Requirement)" and the "STRICT OUTPUT" sections for adjacency lists below. Instead, follow this Lot Card schema and strict output:

Unified Lot Card fields:
- lot_card_id: string (unique per card; deterministic or UUID)
- location_levels: array of { order: int, name: string }
- location_full_path: string
- location_depth: int
- work_levels: array of { order: int, name: string } (WBS hierarchy from root to selected package)
- work_full_path: string
- work_depth: int
- work_package_id: string (MUST match an exact provided WBS node id)
- work_package_name: string (MUST match that WBS node's name)
- work_package_itp_required: boolean (optional)
- work_package_itp_reference: string (optional)
- lot_number: string
- sequence_order: int
- status: "potential" | "in_progress" | "completed" (default "potential")

Lot Card rules:
- Use the same document-driven spatial reasoning to derive all location_* fields.
- Ensure work_* fields faithfully reflect the true WBS hierarchy for the selected package.
- Generate a comprehensive list, not a single illustrative card. Produce as many cards as reasonably needed.
- Populate both 'location_levels' and 'work_levels' for every card (no empty arrays).
- Use a deterministic numbering scheme: 'lot_number' like 'LOT-001', 'LOT-002', ... and 'sequence_order' 1..N.
- Every lot card MUST include all mandatory fields defined above, especially 'work_package_id' and 'work_package_name'. No omissions are allowed.
- The top-level JSON MUST contain ONLY the key 'lot_cards'. Do NOT include any other keys such as 'title', 'summary', 'notes', or 'metadata'.
- The 'lot_cards' array MUST NOT contain any summary or non-card objects. Each element MUST be a valid lot card object conforming to the schema.

STRICT OUTPUT :
{
  "lot_cards": [
    {
      "lot_card_id": "string",
      "location_levels": [{ "order": 1, "name": "..." }, { "order": 2, "name": "..." }],
      "location_full_path": "...",
      "location_depth": 2,
      "work_levels": [{ "order": 1, "name": "..." }, { "order": 2, "name": "..." }],
      "work_full_path": "...",
      "work_depth": 2,
      "work_package_id": "wbs-node-id",
      "work_package_name": "WBS Node Name",
      "work_package_itp_required": true,
      "work_package_itp_reference": "ITP-123",
      "lot_number": "LOT-001",
      "sequence_order": 1,
      "status": "potential"
    },
    {
      "lot_card_id": "string-2",
      "location_levels": [{ "order": 1, "name": "..." }, { "order": 2, "name": "..." }],
      "location_full_path": "...",
      "location_depth": 2,
      "work_levels": [{ "order": 1, "name": "..." }, { "order": 2, "name": "..." }],
      "work_full_path": "...",
      "work_depth": 2,
      "work_package_id": "wbs-node-id-2",
      "work_package_name": "WBS Node Name 2",
      "work_package_itp_required": false,
      "work_package_itp_reference": null,
      "lot_number": "LOT-002",
      "sequence_order": 2,
      "status": "potential"
    }
  ]
}

"""

# Description: Comprehensive, WBS-aware LBS prompt (adjacency-list output) for agents_v9.

PROMPT = r"""
You are generating an OHS Management Plan (OHSMP/WHSMP) as structured JSON using the shared plan schema (title, revision?, metadata?, sections[] with nested content blocks: text, bullets, numbered, table, note, link).

Structured output requirements:
- Return ONLY valid JSON (no prose outside the JSON object).
- Conform exactly to the PlanJson schema.
- Use only allowed content block types and keep sections non-duplicative.

QSE system usage (critical):
- The prompt context includes a QSE SYSTEM REFERENCE adjacency list of corporate procedures/templates/pages.
- Heavily leverage existing corporate procedures/templates where applicable by adding link blocks to those items via their titles and paths.
- Do not invent links; only reference items included in the provided QSE SYSTEM REFERENCE.
- Where no relevant corporate item exists, synthesize content from PROJECT DOCUMENTS and recognized best practice; you may include a short note indicating a project-specific control will be developed.

Use the most relevant jurisdictional template below (VIC, WA). If none applies, use the Generic template. Populate and expand sections based on PROJECT DOCUMENTS. Do not include any instructional text in the output; return only the final PlanJson object.

--- TEMPLATE: VIC (Section 168A – Occupational Health and Safety Management) ---
{
  "title": "Victoria OHS Management Plan (HSMP) — Layout (Section 168A)",
  "revision": "Current",
  "metadata": {
    "jurisdiction": "VIC",
    "agency": "Department of Transport (Vic)",
    "source_document": "Section 168A Occupational Health and Safety Management",
    "standards": "ISO 45001:2018"
  },
  "sections": [
    {
      "id": "part-a-ohs-general",
      "title": "Part A — OHS General",
      "children": [
        { "id": "definitions", "title": "Definitions and Interpretation" },
        { "id": "principal-contractor", "title": "Contractor Responsibilities and Principal Contractor Appointment" },
        { "id": "ohs-risk-management", "title": "OHS Risk Management (workshops; ISO 31000)" },
        { "id": "hsmp-requirements", "title": "Health and Safety Management Plan (HSMP) Requirements" },
        {
          "id": "sub-plans",
          "title": "Required Sub Plans",
          "children": [
            { "id": "depot-site-mgmt", "title": "Depot Site Management Sub Plan" },
            { "id": "fatigue-mgmt", "title": "Fatigue Management Sub Plan" },
            { "id": "cor-hvnl", "title": "Heavy Vehicle National Law Compliance (CoR) Sub Plan" },
            { "id": "occ-health-hygiene", "title": "Occupational Health and Hygiene Sub Plan" },
            { "id": "emergency-incident", "title": "Emergency Response and Incident Management Sub Plan" },
            { "id": "mental-health", "title": "Mental Health and Wellbeing Management Sub Plan" }
          ]
        }
      ]
    },
    {
      "id": "part-b-incident",
      "title": "Part B — Incident Management",
      "children": [
        { "id": "prelim-incident-report", "title": "Preliminary Incident Reporting" },
        { "id": "investigation-report", "title": "Incident Investigation and Reporting" },
        { "id": "notifications", "title": "Statutory Notifications and Regulator Liaison" }
      ]
    },
    {
      "id": "part-c-reporting",
      "title": "Part C — Periodic Safety Reporting",
      "children": [
        { "id": "monthly-hs-performance", "title": "Monthly Health and Safety Performance Reporting" }
      ]
    },
    {
      "id": "part-d-audit-inspection",
      "title": "Part D — Auditing and Inspection",
      "children": [
        { "id": "audit", "title": "Health and Safety Audits (competency; scope; frequency)" },
        { "id": "inspection", "title": "Health and Safety Inspections" },
        { "id": "nonconformance", "title": "Non-conformances and Corrective Actions" }
      ]
    }
  ]
}

--- TEMPLATE: WA (Specification 203 – Health and Safety Management) ---
{
  "title": "Western Australia WHS Management Plan (HSMP) — Layout (Spec 203)",
  "revision": "03/12/2024",
  "metadata": {
    "jurisdiction": "WA",
    "agency": "Main Roads Western Australia",
    "source_document": "Specification 203 Health and Safety Management",
    "standards": "ISO 45001; WHS Act (WA); WHS Regulations (WA)"
  },
  "sections": [
    { "id": "scope", "title": "Scope and Structure" },
    { "id": "hold-points", "title": "Schedule of Hold Points and Identifiable Records" },
    { "id": "management-system", "title": "Management System Requirements (ISO 45001; FSC Accreditation)" },
    { "id": "references", "title": "References (Acts, Regulations, Standards, Codes)" },
    {
      "id": "hsmp",
      "title": "Part A — Health and Safety Management Plan",
      "children": [
        { "id": "leadership", "title": "Leadership, Commitment and Management Responsibility" },
        { "id": "consultation", "title": "Consultation, Cooperation, Coordination and Issue Resolution" },
        { "id": "subcontractors", "title": "Subcontractor Health and Safety Assessment" },
        { "id": "ppe", "title": "Personal Protective Equipment" },
        { "id": "aod", "title": "Alcohol and Other Drugs Testing" },
        { "id": "fatigue", "title": "Management of Fatigue" },
        { "id": "induction", "title": "Health and Safety Induction Training" },
        { "id": "swms", "title": "Safe Work Method Statements (SWMS)" },
        { "id": "auditing-reporting", "title": "Compliance Auditing and Performance Reporting" },
        { "id": "inspections", "title": "Workplace Health and Safety Inspections" },
        { "id": "nonconformance", "title": "Non-conformance and Corrective Action" },
        { "id": "regulatory-orders", "title": "Regulatory Orders, Notices and Convictions" },
        { "id": "incident-mgmt", "title": "Incident Management and EQSafe Reporting" },
        { "id": "monthly-reporting", "title": "Health and Safety Monthly Reporting" },
        { "id": "doc-records", "title": "Documentation and Record Management" },
        { "id": "hsmp-submission", "title": "Submission of the HSMP" },
        { "id": "hsmp-revision", "title": "Revision of the HSMP" }
      ]
    },
    {
      "id": "hirac",
      "title": "Part B — Hazard Identification, Risk Assessment and Control",
      "children": [
        { "id": "works-risk-assessment", "title": "Works WHS Risk Assessment" },
        { "id": "high-risk-work", "title": "High Risk Work and Principal Identified Hazards" },
        { "id": "asbestos", "title": "Asbestos Risk Management" },
        { "id": "fire", "title": "Fire Mitigation and Control" },
        { "id": "first-aid", "title": "First Aid Treatment" },
        { "id": "emp-submission", "title": "Submission of the Emergency Management Plan" },
        { "id": "emp-revision", "title": "Revision of the Emergency Management Plan" }
      ]
    },
    { "id": "handover", "title": "As-Built and Handover Requirements" },
    {
      "id": "annexures",
      "title": "Annexures and Appendices",
      "content": [
        { "type": "bullets", "items": [
          "Annexure 203A: Hold Points and Identifiable Records",
          "Annexure 203B: Minimum WHS Control Standards (High Risk Work & Identified Hazards)",
          "Annexure 203C: Asbestos Locations",
          "Annexure 203D: HSMP Cross Reference Key"
        ]}
      ]
    }
  ]
}

--- TEMPLATE: GENERIC (Consolidated OHS/WHS) ---
{
  "title": "Generic OHS/WHS Management Plan — Consolidated Layout",
  "metadata": {
    "jurisdiction": "Generic",
    "source_basis": "VIC Section 168A; WA Spec 203",
    "standards": "ISO 45001; WHS/OHS legislation as applicable"
  },
  "sections": [
    {
      "id": "governance",
      "title": "Governance and Responsibilities",
      "children": [
        { "id": "intro-scope", "title": "Introduction and Scope" },
        { "id": "roles-resp", "title": "Roles and Responsibilities (PCBU/Principal Contractor; HS Rep)" },
        { "id": "consultation", "title": "Consultation and Issue Resolution" },
        { "id": "legal-refs", "title": "Legislation, Standards and Codes of Practice" },
        { "id": "system-reqs", "title": "Management System Requirements (ISO 45001 certification)" }
      ]
    },
    {
      "id": "hsmp-core",
      "title": "HSMP Core Processes",
      "children": [
        { "id": "risk-management", "title": "Risk Management (HIRAC; workshops; ISO 31000)" },
        { "id": "swms", "title": "SWMS for High Risk Work" },
        { "id": "training-induction", "title": "Training and Induction (competency; assessment)" },
        { "id": "ppe", "title": "Personal Protective Equipment" },
        { "id": "fatigue", "title": "Fatigue Management" },
        { "id": "aod", "title": "Alcohol and Other Drugs" },
        { "id": "subcontractors", "title": "Subcontractor Assessment and Management" },
        { "id": "documentation", "title": "Documentation and Records Control" }
      ]
    },
    {
      "id": "incident-audit-reporting",
      "title": "Incident, Audit and Reporting",
      "children": [
        { "id": "incident-mgmt", "title": "Incident Management (preliminary and investigation reporting)" },
        { "id": "notifications", "title": "Regulatory Notifications and Orders/Notices" },
        { "id": "inspections", "title": "Workplace Inspections" },
        { "id": "auditing", "title": "Compliance Auditing and Performance Reporting" },
        { "id": "nonconformance", "title": "Non-conformance and Corrective Actions" },
        { "id": "monthly-reporting", "title": "Monthly HS Reporting" }
      ]
    },
    {
      "id": "emergency-firstaid",
      "title": "Emergency Management and First Aid",
      "children": [
        { "id": "emp", "title": "Emergency Management Plan (submission; revision)" },
        { "id": "fire", "title": "Fire Mitigation and Control" },
        { "id": "first-aid", "title": "First Aid Treatment and Resources" }
      ]
    },
    { "id": "handover", "title": "As-Built and Handover Requirements" }
  ]
}
"""



PROMPT = r"""
You are generating a Project Quality Plan (PQP) as structured JSON.

Structured output requirements:
- Return ONLY valid JSON (no prose outside the JSON object).
- Conform exactly to the schema specified by the Output Schema instructions provided by the system. If there is any conflict with guidance below, follow the Output Schema.
- Use only these content blocks (if applicable to the chosen schema): text, bullets, numbered, table, note, link.
- Be exhaustive, implementable, and field-usable. Avoid redundancy but prefer complete, practitioner-level detail over brevity.
- Do NOT prefix any titles with numbers (e.g., no "1.", "1.0", "5.1"). Strip numbering embedded in source headings.
- Exclude table-of-contents or PDF artifacts (e.g., "Contents", "Print", page numbers) from titles and content.

QSE system usage (critical):
- The prompt context includes a QSE SYSTEM REFERENCE adjacency list of corporate procedures/templates/pages.
- Heavily leverage existing corporate procedures/templates when relevant by inserting link blocks to those items using their title and path (e.g., {"type":"link","label":"Procedure for Control of Documented Information","url":"/qse/corp-documentation"}).
- Do not fabricate links. Only link to items present in the QSE SYSTEM REFERENCE.
- When no relevant QSE item exists, derive content from PROJECT DOCUMENTS and best practice; you may add a short note block indicating that a project-specific procedure/template will be created.
- Prefer cross-referencing over duplicating corporate content.

Use the most relevant jurisdictional template below (QLD, SA, VIC, NSW). If none applies, use the Generic template. Populate and expand sections based on PROJECT DOCUMENTS. Do not include any instructional text in the output; return only the final plan object.

--- TEMPLATE: QLD (MRTS50 – Specific Quality System Requirements) ---
{
  "title": "Queensland Project Quality Plan (PQP) — Layout (MRTS50)",
  "revision": "March 2025",
  "metadata": {
    "jurisdiction": "QLD",
    "agency": "Department of Transport and Main Roads",
    "source_document": "MRTS50 Specific Quality System Requirements",
    "standards": "AS/NZS ISO 9001"
  },
  "sections": [
    { "id": "introduction", "title": "Introduction (read with MRTS01)" },
    { "id": "definitions", "title": "Definition of Terms" },
    { "id": "referenced-docs", "title": "Referenced Documents" },
    { "id": "quality-system", "title": "Quality System Requirements (ISO 9001 compliant)" },
    {
      "id": "quality-plan",
      "title": "Project Quality Plan",
      "children": [
        { "id": "objectives", "title": "Quality Objectives and Commitment" },
        { "id": "roles-responsibilities", "title": "Roles, Responsibilities and Authorities (incl. subcontractors)" },
        { "id": "procedures-itps", "title": "Construction Procedures and ITPs (register; schedule)" },
        { "id": "lot-control", "title": "Lot Numbering, Identification and Registration" },
        { "id": "materials-approval", "title": "Materials Approval and Control" },
        { "id": "sampling-testing", "title": "Sampling and Testing (frequencies; NATA; CMTSRS)" },
        { "id": "hold-witness", "title": "Hold Points, Witness Points, Milestones and Records" },
        { "id": "nonconformance", "title": "Nonconformance and Corrective Action Procedures" },
        { "id": "records", "title": "Records Retention and Access" }
      ]
    }
  ]
}

--- TEMPLATE: SA (PC-QA2 – Quality Management Requirements for Major Projects) ---
{
  "title": "South Australia Project Quality Plan (PQP) — Layout (PC-QA2)",
  "revision": "September 2024",
  "metadata": {
    "jurisdiction": "SA",
    "agency": "Department for Infrastructure and Transport",
    "source_document": "Master Specification PC-QA2 Quality Management Requirements for Major Projects",
    "standards": "AS/NZS ISO 9001"
  },
  "sections": [
    { "id": "general", "title": "General" },
    {
      "id": "documentation",
      "title": "Documentation",
      "children": [
        { "id": "pqp", "title": "Project Quality Plan (content; organisation; policy; team)" },
        { "id": "as-built", "title": "As-Built Records (digital engineering; registers; QA records)" }
      ]
    },
    { "id": "qms", "title": "Quality Management System (ISO 9001; accessibility; electronic)" },
    { "id": "management-responsibility", "title": "Management Responsibility and Authority (Construction Quality Representative)" },
    { "id": "resource-management", "title": "Resource Management (competency; calibration; equipment)" },
    { "id": "product-realisation", "title": "Product Realisation (procurement; subcontracting; design involvement)" },
    { "id": "work-lots", "title": "Work Lots and Traceability (lot registers; validation)" },
    { "id": "inspection-testing", "title": "Inspection and Testing (ITPs; schedules; competency)" },
    { "id": "nonconformance", "title": "Non-Conformance and System Non-Conformance (registers)" },
    { "id": "audits-surveillance", "title": "Auditing, Surveillance and Notices (Principal, IDC, CV involvement)" },
    { "id": "performance-eval", "title": "Performance Evaluation and Improvement (CAPA register)" },
    { "id": "hold-witness", "title": "Hold Points and Witness Points (register; durations; delegation)" }
  ]
}

--- TEMPLATE: VIC (Section 160 – Construction General, Part A Management Systems) ---
{
  "title": "Victoria Project Quality Plan (PQP) — Layout (Section 160 Part A)",
  "revision": "November 2018",
  "metadata": {
    "jurisdiction": "VIC",
    "agency": "Department of Transport (Vic)",
    "source_document": "Section 160 Construction General (Part A Management Systems)",
    "standards": "AS/NZS ISO 9001; AS/NZS ISO 14001; AS/NZS 4801/ISO 45001"
  },
  "sections": [
    { "id": "qms-standards", "title": "Quality Management System Standards and Definitions" },
    { "id": "qmr", "title": "Quality Management Representative" },
    {
      "id": "quality-plans",
      "title": "Quality Plans and Procedures",
      "children": [
        { "id": "incident", "title": "Incident Management and Reporting (cross-ref Sections 168 & 176)" },
        { "id": "mgmt-system-plans", "title": "Management System Plans: TMP, EMP, HS Coordination Plan" },
        { "id": "hold-points", "title": "Nominated Hold Points" },
        { "id": "records", "title": "Records (format; indexing; media requirements)" },
        { "id": "surveillance-audits", "title": "Surveillance and Audits by the Superintendent" }
      ]
    }
  ]
}

--- TEMPLATE: NSW (TfNSW Q6 – Quality Management Major Works) ---
{
  "title": "New South Wales Project Quality Plan (PQP) — Layout (TfNSW Q6)",
  "revision": "February 2024",
  "metadata": {
    "jurisdiction": "NSW",
    "agency": "Transport for NSW",
    "source_document": "QA Specification Q6 Quality Management (Major Works)",
    "standards": "AS/NZS ISO 9001; AS ISO 10005; AS/NZS ISO 10013"
  },
  "sections": [
    { "id": "scope", "title": "General and Scope" },
    { "id": "quality-manual", "title": "Quality Manual (structure; mapping to ISO 9001)" },
    {
      "id": "project-quality-plan",
      "title": "Project Quality Plan",
      "children": [
        { "id": "staging", "title": "Stage Submissions (coverage of activities)" },
        { "id": "pqr", "title": "Project Quality Representative (authority; availability)" },
        { "id": "competence", "title": "Competence and Awareness (induction and training)" },
        { "id": "design-dev", "title": "Design and Development (design plans; verification)" },
        { "id": "process-control", "title": "Work Process Controls (validation; responsibilities; records)" },
        { "id": "itps", "title": "Inspection and Test Plans (lot definition; sampling; testing)" },
        { "id": "procurement", "title": "Procurement and Supplier Control" },
        { "id": "meas-equip", "title": "Monitoring and Measuring Equipment (calibration; NATA)" }
      ]
    }
  ]
}

--- TEMPLATE: GENERIC (Consolidated Quality) ---
{
  "title": "Generic Project Quality Plan — Consolidated Layout",
  "metadata": {
    "jurisdiction": "Generic",
    "source_basis": "QLD MRTS50; SA PC-QA2; VIC Section 160; NSW TfNSW Q6",
    "standards": "AS/NZS ISO 9001; AS ISO 10005; AS/NZS ISO 10013"
  },
  "sections": [
    { "id": "intro", "title": "Introduction and Referenced Documents" },
    { "id": "qms", "title": "Quality Management System (ISO 9001)" },
    {
      "id": "pqp",
      "title": "Project Quality Plan",
      "children": [
        { "id": "objectives", "title": "Objectives and Policy" },
        { "id": "roles", "title": "Roles and Responsibilities (PQR; org chart)" },
        { "id": "design-procurement", "title": "Design, Procurement and Subcontractor Control" },
        { "id": "itps", "title": "ITPs; Sampling and Testing; Lot Control" },
        { "id": "hold-witness", "title": "Hold/Witness Points and Milestones" },
        { "id": "nonconformance", "title": "Nonconformance and Corrective Actions" },
        { "id": "records", "title": "Records Management and Retention" }
      ]
    }
  ]
}
"""

PROJECT_DETAILS_SYSTEM_PROMPT = r"""
You are a precise information extractor and drafter. Read the concatenated project documents and return ONLY a JSON object that matches the schema below. Keep it simple and factual: one pass, no extra commentary.

Global constraints:
- If a top-level value is unknown, use null.
- The only top-level static fields are project_name and project_address. All other content must be inside the html string.
- Do NOT include source citations, filenames, or hints. Only extracted information.
- The html must be valid, sanitized HTML suitable for direct rendering. Use semantic elements (section, h2, h3, p, ul/li, table/thead/tbody/tr/th/td, dl/dt/dd, address). No scripts, no external resources.
- Tables must include visible borders for all cells. Use inline style attributes on table/th/td to render 1px solid #d1d5db borders with ~8px padding and vertical-align: top; thead should have a subtle background (e.g., #f9fafb).
- Headings must use consistent sizing and spacing: h1 ≈ 1.5rem, h2 ≈ 1.25rem, h3 ≈ 1.125rem with around 0.5–0.75rem top/bottom margins.
- Prefer authoritative sources: cover pages, title blocks, contract summaries, front matter.
- For project_address, return the physical site address (street number/name, suburb/city, state/region, postcode). If multiple addresses are present, pick the primary site location. If unavailable, return null. Do not return PO Boxes or generic regions.

Strict content rules for html:
1) Overview: Provide exactly ONE single concise sentence describing what the project is (e.g., “Design and construction of X at Y for Z”).
   - Do NOT elaborate on scope, methodology, standards, or requirements. No marketing language.

2) Key Parties & Hierarchy: Identify the principal organisations and roles and show the hierarchy.
   - Include a “Parties” table with columns: Role, Organisation, ABN/ACN (if present), Primary Contact (Name, Email, Phone) if identifiable.
   - Include a “Hierarchy” as a nested unordered list representing parent→child relationships (e.g., Client → Principal Contractor → Subcontractors). If unclear, list known relations only.

3) Contact Directory (All contacts): Extract every contact you can find.
   - Use a comprehensive table with columns: Name, Role/Title, Organisation, Email, Phone, Mobile, Address, Notes/Responsibility.
   - Use mailto: links for emails and tel: links for phone/mobile where present.
   - Deduplicate contacts; prefer the most complete record. If a field is unknown for a given contact, leave the cell blank.

4) Project Identifiers: Include a compact key–value table for useful identifiers if present (e.g., Project/Contract/Job numbers, Purchase Order, Site code, Lot/Plan, ABN/ACN, etc.).

5) Dates & Milestones (optional): If present, include contractually relevant dates (e.g., Notice to Proceed, Start, Practical Completion) in a small table.

6) Exclusions: Do NOT include regulatory standards, codes, QA/QC requirements, acceptance criteria, methods, or scope narrative. This page is details-only.

Formatting requirements for html:
- Organise with clear sections and headings; keep it readable and compact.
- Section numbering: use decimal numbering for headings (document title <h1> is unnumbered; top-level sections use <h2> with 1., 2., 3., ...; subsections use <h3> with 1.1, 1.2, 2.1, ...). Add stable id attributes for anchor linking (e.g., <h2 id="sec-1">1. Overview</h2>, <h3 id="sec-1-1">1.1 Parties</h3>).
- Use thead/tbody in tables, reasonable column ordering, and concise cells.
- Apply inline styles so the output renders with table outlines and consistent typography without external CSS, for example:
  - <table style="border-collapse:collapse;width:100%"> with <th> and <td> having style="border:1px solid #d1d5db;padding:8px;vertical-align:top".
  - <thead> row can use <tr style="background:#f9fafb"> or <th style="background:#f9fafb">.
  - Headings should include inline font-size consistent with the scale above when necessary.
- No images, no scripts, no external stylesheets. Minimal inline styling is acceptable but not required.

Output JSON schema (keys must match exactly):
{
  "project_name": string|null,
  "project_address": string|null,
  "html": string|null
}

Documents:
{document_content}

Example html:
<section>
  <h2>Overview</h2>
  <p>Design and construction of the Riverdale Bridge at 12 Riverside Ave, Riverdale for Riverdale City Council.</p>
</section>

<section>
  <h2>Key Parties &amp; Hierarchy</h2>
  <h3>Parties</h3>
  <table>
    <thead>
      <tr>
        <th>Role</th>
        <th>Organisation</th>
        <th>ABN/ACN</th>
        <th>Primary Contact</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Client</td>
        <td>Riverdale City Council</td>
        <td>12 345 678 901</td>
        <td>Jane Smith — <a href="mailto:jane.smith@riverdale.gov">jane.smith@riverdale.gov</a>, <a href="tel:+61123456789">+61 123 456 789</a></td>
      </tr>
      <tr>
        <td>Principal Contractor</td>
        <td>BuildCo Pty Ltd</td>
        <td>98 765 432 109</td>
        <td>John Doe — <a href="mailto:j.doe@buildco.com">j.doe@buildco.com</a>, <a href="tel:+61111222333">+61 111 222 333</a></td>
      </tr>
    </tbody>
  </table>

  <h3>Hierarchy</h3>
  <ul>
    <li>Client: Riverdale City Council
      <ul>
        <li>Principal Contractor: BuildCo Pty Ltd
          <ul>
            <li>Subcontractor: SteelWorks Ltd</li>
            <li>Subcontractor: RoadSurfacing Co</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</section>

<section>
  <h2>Contact Directory</h2>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Role/Title</th>
        <th>Organisation</th>
        <th>Email</th>
        <th>Phone</th>
        <th>Mobile</th>
        <th>Address</th>
        <th>Notes/Responsibility</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Jane Smith</td>
        <td>Principal Representative</td>
        <td>Riverdale City Council</td>
        <td><a href="mailto:jane.smith@riverdale.gov">jane.smith@riverdale.gov</a></td>
        <td><a href="tel:+61123456789">+61 123 456 789</a></td>
        <td></td>
        <td>123 Civic St, Riverdale</td>
        <td>Client liaison</td>
      </tr>
      <tr>
        <td>John Doe</td>
        <td>Project Manager</td>
        <td>BuildCo Pty Ltd</td>
        <td><a href="mailto:j.doe@buildco.com">j.doe@buildco.com</a></td>
        <td></td>
        <td><a href="tel:+61400111222">+61 400 111 222</a></td>
        <td>45 Industry Rd, Riverdale</td>
        <td>Head contractor PM</td>
      </tr>
    </tbody>
  </table>
</section>

<section>
  <h2>Project Identifiers</h2>
  <table>
    <thead>
      <tr>
        <th>Key</th>
        <th>Value</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Contract Number</td>
        <td>RCC-2025-001</td>
      </tr>
      <tr>
        <td>Project Number</td>
        <td>BC-PRJ-7788</td>
      </tr>
    </tbody>
  </table>
</section>

<section>
  <h2>Dates &amp; Milestones</h2>
  <table>
    <thead>
      <tr>
        <th>Milestone</th>
        <th>Date</th>
        <th>Notes</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Notice to Proceed</td>
        <td>2025-02-01</td>
        <td></td>
      </tr>
      <tr>
        <td>Practical Completion</td>
        <td>2026-01-15</td>
        <td></td>
      </tr>
    </tbody>
  </table>
</section>
"""


PROJECT_INFO_PROMPT = """
Extract project info from: {input}
"""
# Description: Prompts for project info extraction.
# Source: From agents V7 project info prompts. """
QSE System hierarchy and document catalogue.

This module provides a comprehensive, flat JSON-like node list describing the
QSE (Quality, Safety, Environment) management system hierarchy and all controlled
documents defined under the Next.js app routes at /qse.

Each node is a dictionary with the following common keys:
  - id: unique node id (page path-like for sections/pages; stable keys for docs)
  - parent_id: id of the parent node (None for the root)
  - type: one of {section, page, manual, statement, policy, procedure, register,
           form, plan, template}
  - title: human-readable title
  - path: in-app route for the page presenting this node (for pages); for docs,
          the path to the page where the document is surfaced
  - description: short description suitable for LLM grounding

Document nodes also include:
  - document_number: the controlled document identifier (e.g., "QSE-9.1-FORM-01")

Notes:
  - This is intentionally a flat adjacency list (parent_id links define the tree).
  - Descriptions are distilled from the TSX page content where available, or
    provided as succinct, standards-aligned summaries when the TSX did not include
    an explicit blurb for that document.

Source of truth pages referenced:
  /app/projectpro_qa_v2/src/app/(app)/qse/**

Last generated: automated by assistant
"""

# Root node
QSE_SYSTEM_NODES = [
    {
        "id": "qse",
        "parent_id": None,
        "type": "section",
        "title": "QSE Management System",
        "path": "/qse",
        "description": (
            "Integrated Quality, Safety, and Environment (QSE) management system aligned "
            "with ISO 9001:2015, ISO 14001:2015, and ISO 45001:2018."
        ),
    },

    # Tier 1 (Corporate, foundational)
    {
        "id": "qse/corporate-tier-1",
        "parent_id": "qse",
        "type": "page",
        "title": "Corporate QSE Management System (Tier 1)",
        "path": "/qse/corporate-tier-1",
        "description": (
            "Foundational IMS documents defining scope, context, policy framework and "
            "process interactions of the integrated management system."
        ),
    },
    {
        "id": "doc:QSE-1-MAN-01",
        "parent_id": "qse/corporate-tier-1",
        "type": "manual",
        "document_number": "QSE-1-MAN-01",
        "title": "Integrated Management System (IMS) Manual",
        "path": "/qse/corporate-tier-1",
        "description": (
            "Keystone manual defining the scope, context, policies, and process interactions "
            "of the integrated QSE management system."
        ),
    },
    {
        "id": "doc:QSE-4.3-STMT-01",
        "parent_id": "qse/corporate-tier-1",
        "type": "statement",
        "document_number": "QSE-4.3-STMT-01",
        "title": "IMS Scope Statement",
        "path": "/qse/corporate-tier-1",
        "description": (
            "Formal statement defining the boundaries and applicability of the IMS across "
            "corporate and project operations."
        ),
    },

    # 5.0 Leadership
    {
        "id": "qse/corp-leadership",
        "parent_id": "qse",
        "type": "page",
        "title": "5.0 Leadership",
        "path": "/qse/corp-leadership",
        "description": (
            "Leadership commitment, policy framework, roles and consultation mechanisms "
            "that drive the IMS."
        ),
    },
    {
        "id": "qse/corp-policy-roles",
        "parent_id": "qse",
        "type": "page",
        "title": "5.2-5.3 Policy, Roles & Responsibilities",
        "path": "/qse/corp-policy-roles",
        "description": (
            "Foundational documents defining management commitment and organizational "
            "structure for QSE."
        ),
    },
    {
        "id": "doc:QSE-5.2-POL-01",
        "parent_id": "qse/corp-policy-roles",
        "type": "policy",
        "document_number": "QSE-5.2-POL-01",
        "title": "QSE Policy Statement",
        "path": "/qse/corp-policy-roles",
        "description": (
            "Official declaration of top management's commitment to quality, safety, and the environment."
        ),
    },
    {
        "id": "doc:QSE-5.3-REG-01",
        "parent_id": "qse/corp-policy-roles",
        "type": "register",
        "document_number": "QSE-5.3-REG-01",
        "title": "Roles, Responsibilities & Authorities Matrix",
        "path": "/qse/corp-policy-roles",
        "description": (
            "Matrix defining QSE responsibilities and authorities for key roles across the organization."
        ),
    },
    {
        "id": "qse/corp-consultation",
        "parent_id": "qse",
        "type": "page",
        "title": "5.4 Worker Consultation & Participation",
        "path": "/qse/corp-consultation",
        "description": (
            "Framework and evidence of worker involvement in QSE matters at all levels."
        ),
    },
    {
        "id": "doc:QSE-5.4-PROC-01",
        "parent_id": "qse/corp-consultation",
        "type": "procedure",
        "document_number": "QSE-5.4-PROC-01",
        "title": "Procedure for Consultation & Participation",
        "path": "/qse/corp-consultation",
        "description": (
            "Mechanisms for effective worker engagement on health, safety, and environmental issues."
        ),
    },
    {
        "id": "doc:QSE-5.4-FORM-01",
        "parent_id": "qse/corp-consultation",
        "type": "form",
        "document_number": "QSE-5.4-FORM-01",
        "title": "Health & Safety Committee Meeting Minutes Template",
        "path": "/qse/corp-consultation",
        "description": "Blank template for recording formal worker consultation meeting minutes.",
    },

    # 6.0 Planning
    {
        "id": "qse/corp-planning",
        "parent_id": "qse",
        "type": "page",
        "title": "6.0 Planning",
        "path": "/qse/corp-planning",
        "description": (
            "Systematic approach to planning: risk & opportunity management, compliance, and setting objectives."
        ),
    },
    {
        "id": "qse/corp-risk-management",
        "parent_id": "qse",
        "type": "page",
        "title": "6.1 Risk & Opportunity Management",
        "path": "/qse/corp-risk-management",
        "description": (
            "Framework and registers for identifying, analysing and treating QSE risks and opportunities."
        ),
    },
    {
        "id": "doc:QSE-6.1-PROC-01",
        "parent_id": "qse/corp-risk-management",
        "type": "procedure",
        "document_number": "QSE-6.1-PROC-01",
        "title": "Procedure for Risk & Opportunity Management",
        "path": "/qse/corp-risk-management",
        "description": (
            "Process for identifying, analysing, evaluating, treating, monitoring and communicating risks and opportunities."
        ),
    },
    {
        "id": "doc:QSE-6.1-REG-01",
        "parent_id": "qse/corp-risk-management",
        "type": "register",
        "document_number": "QSE-6.1-REG-01",
        "title": "Corporate Risk Register",
        "path": "/qse/corp-risk-management",
        "description": "Live register of significant strategic and operational QSE risks.",
    },
    {
        "id": "doc:QSE-6.1-REG-02",
        "parent_id": "qse/corp-risk-management",
        "type": "register",
        "document_number": "QSE-6.1-REG-02",
        "title": "Corporate Opportunity Register",
        "path": "/qse/corp-risk-management",
        "description": "Register for tracking potential improvements and strategic QSE opportunities.",
    },
    {
        "id": "qse/corp-legal",
        "parent_id": "qse",
        "type": "page",
        "title": "6.1.3 Compliance Obligations",
        "path": "/qse/corp-legal",
        "description": "Identification, access and management of legal and other requirements.",
    },
    {
        "id": "doc:QSE-6.1-PROC-02",
        "parent_id": "qse/corp-legal",
        "type": "procedure",
        "document_number": "QSE-6.1-PROC-02",
        "title": "Procedure for Identifying Compliance Obligations",
        "path": "/qse/corp-legal",
        "description": (
            "Process for ensuring awareness of, and access to, legal and other compliance obligations."
        ),
    },
    {
        "id": "doc:QSE-6.1-REG-03",
        "parent_id": "qse/corp-legal",
        "type": "register",
        "document_number": "QSE-6.1-REG-03",
        "title": "Compliance Obligations Register",
        "path": "/qse/corp-legal",
        "description": "Live register of legal and other compliance obligations applicable to operations.",
    },
    {
        "id": "qse/corp-objectives",
        "parent_id": "qse",
        "type": "page",
        "title": "6.2 QSE Objectives",
        "path": "/qse/corp-objectives",
        "description": "Framework and plan for setting and achieving QSE objectives.",
    },
    {
        "id": "doc:QSE-6.2-PROC-01",
        "parent_id": "qse/corp-objectives",
        "type": "procedure",
        "document_number": "QSE-6.2-PROC-01",
        "title": "Procedure for Setting QSE Objectives",
        "path": "/qse/corp-objectives",
        "description": "Process for establishing, communicating and monitoring QSE objectives and targets.",
    },
    {
        "id": "doc:QSE-6.2-PLAN-01",
        "parent_id": "qse/corp-objectives",
        "type": "plan",
        "document_number": "QSE-6.2-PLAN-01",
        "title": "Annual QSE Objectives & Targets Plan",
        "path": "/qse/corp-objectives",
        "description": "Documented plan outlining current-year QSE goals and targets.",
    },

    # 7.0 Support
    {
        "id": "qse/corp-support",
        "parent_id": "qse",
        "type": "page",
        "title": "7.0 Support",
        "path": "/qse/corp-support",
        "description": (
            "Organizational support systems for resources, competence, awareness, communication, and documented information."
        ),
    },
    {
        "id": "qse/corp-competence",
        "parent_id": "qse",
        "type": "page",
        "title": "7.1-7.3 Resources, Competence & Awareness",
        "path": "/qse/corp-competence",
        "description": (
            "Ensures adequate resources, develops personnel competence, and promotes QSE awareness."
        ),
    },
    {
        "id": "doc:QSE-7.2-PROC-01",
        "parent_id": "qse/corp-competence",
        "type": "procedure",
        "document_number": "QSE-7.2-PROC-01",
        "title": "Procedure for Training, Competence & Awareness",
        "path": "/qse/corp-competence",
        "description": (
            "Systematic approach for identifying training needs, ensuring competence, and promoting awareness."
        ),
    },
    {
        "id": "doc:QSE-7.2-REG-01",
        "parent_id": "qse/corp-competence",
        "type": "register",
        "document_number": "QSE-7.2-REG-01",
        "title": "Training Needs Analysis & Competency Matrix",
        "path": "/qse/corp-competence",
        "description": (
            "Matrix mapping required competencies to roles and tracking training status."
        ),
    },
    {
        "id": "doc:QSE-7.2-TEMP-01",
        "parent_id": "qse/corp-competence",
        "type": "template",
        "document_number": "QSE-7.2-TEMP-01",
        "title": "Employee Induction Presentation Template",
        "path": "/qse/corp-competence",
        "description": (
            "Standard induction program template covering corporate QSE requirements and culture."
        ),
    },
    {
        "id": "qse/corp-communication",
        "parent_id": "qse",
        "type": "page",
        "title": "7.4 Communication",
        "path": "/qse/corp-communication",
        "description": "Framework for internal and external communication processes.",
    },
    {
        "id": "doc:QSE-7.4-PROC-01",
        "parent_id": "qse/corp-communication",
        "type": "procedure",
        "document_number": "QSE-7.4-PROC-01",
        "title": "Procedure for Internal & External Communication",
        "path": "/qse/corp-communication",
        "description": "Processes and protocols for effective internal and external communication.",
    },
    {
        "id": "doc:QSE-7.4-REG-01",
        "parent_id": "qse/corp-communication",
        "type": "register",
        "document_number": "QSE-7.4-REG-01",
        "title": "Communication Matrix",
        "path": "/qse/corp-communication",
        "description": (
            "Matrix defining communication requirements, channels, responsibilities and tracking."
        ),
    },
    {
        "id": "qse/corp-documentation",
        "parent_id": "qse",
        "type": "page",
        "title": "7.5 Documented Information",
        "path": "/qse/corp-documentation",
        "description": (
            "Creation, update, control and retention of documented information across the IMS."
        ),
    },
    {
        "id": "doc:QSE-7.5-PROC-01",
        "parent_id": "qse/corp-documentation",
        "type": "procedure",
        "document_number": "QSE-7.5-PROC-01",
        "title": "Procedure for Control of Documented Information",
        "path": "/qse/corp-documentation",
        "description": (
            "Systematic approach for creating, reviewing, approving, distributing and controlling documents."
        ),
    },
    {
        "id": "doc:QSE-7.5-REG-01",
        "parent_id": "qse/corp-documentation",
        "type": "register",
        "document_number": "QSE-7.5-REG-01",
        "title": "Master Document & Records Register",
        "path": "/qse/corp-documentation",
        "description": (
            "Comprehensive register of controlled documents and records, with status and review tracking."
        ),
    },

    # 8.0 Operation
    {
        "id": "qse/corp-operation",
        "parent_id": "qse",
        "type": "page",
        "title": "8.0 Operation",
        "path": "/qse/corp-operation",
        "description": (
            "Core operational procedures and templates governing project execution and service delivery."
        ),
    },
    {
        "id": "qse/corp-op-procedures-templates",
        "parent_id": "qse",
        "type": "page",
        "title": "8.1 Corporate Operational Procedures & Templates",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Operational procedures and templates supporting planning, execution, control and handover."
        ),
    },
    # Procedures (8.1)
    {
        "id": "doc:QSE-8.1-PROC-01",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-01",
        "title": "Project Management Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Defines phases and controls for planning, executing, monitoring and closing projects within the system."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-02",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-02",
        "title": "Incident Reporting & Investigation Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Reporting, investigation and corrective action workflow for incidents and nonconformities."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-03",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-03",
        "title": "WHS Management Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Overarching occupational health and safety operational controls and responsibilities."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-04",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-04",
        "title": "Environmental Management Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Operational controls for environmental aspects, mitigation measures and monitoring."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-05",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-05",
        "title": "Construction & Operational Control Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Work execution controls including lot management, inspections, hold points and verification."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-06",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-06",
        "title": "Design & Development Control Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Controls for review and approval of client-supplied designs and temporary works."
        ),
    },
    {
        "id": "doc:QSE-8.1-PROC-07",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "procedure",
        "document_number": "QSE-8.1-PROC-07",
        "title": "Procurement & Supplier Management Procedure",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Supplier prequalification, purchasing controls and supplier performance monitoring."
        ),
    },
    # Templates (8.1)
    {
        "id": "doc:QSE-8.1-TEMP-PQP",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-PQP",
        "title": "Project Quality Plan (PQP) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for project-specific quality objectives, responsibilities, ITPs and verification records."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-EMP",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-EMP",
        "title": "Environmental Management Plan (EMP) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for environmental aspects, controls, monitoring plans and incident response."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-OHSMP",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-OHSMP",
        "title": "Occupational Health & Safety Management Plan (OHSMP) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for OHS risk controls, responsibilities and emergency preparedness."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-TMP",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-TMP",
        "title": "Traffic Management Plan (TMP) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for planning temporary traffic arrangements and controls."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-SWMS",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-SWMS",
        "title": "Safe Work Method Statement (SWMS) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for task-level hazards, risk controls and verification sign-off."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-ITP",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-ITP",
        "title": "Inspection & Test Plan (ITP) Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template defining inspection and testing checkpoints, hold/witness points and records."
        ),
    },
    {
        "id": "doc:QSE-8.1-TEMP-05",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-05",
        "title": "Quality Inspection / ITP Record Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": "Template for capturing inspection/test results against ITP checkpoints.",
    },
    {
        "id": "doc:QSE-8.1-TEMP-04",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-04",
        "title": "Site Induction & Training Record Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": "Template for recording induction attendance and training completion.",
    },
    {
        "id": "doc:QSE-8.1-TEMP-03",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-03",
        "title": "Pre-start Meeting / Toolbox Talk Record Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": "Template for recording pre-start/toolbox discussions and attendees.",
    },
    {
        "id": "doc:QSE-8.1-TEMP-02",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-02",
        "title": "Risk Assessment / SWMS Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": "Template for structured risk assessment and SWMS content.",
    },
    {
        "id": "doc:QSE-8.1-TEMP-01",
        "parent_id": "qse/corp-op-procedures-templates",
        "type": "template",
        "document_number": "QSE-8.1-TEMP-01",
        "title": "Project Emergency Preparedness & Response Plan Template",
        "path": "/qse/corp-op-procedures-templates",
        "description": (
            "Template for emergency preparedness, response roles and communication protocols."
        ),
    },

    # 9.0 Performance Evaluation
    {
        "id": "qse/corp-performance",
        "parent_id": "qse",
        "type": "page",
        "title": "9.0 Performance Evaluation",
        "path": "/qse/corp-performance",
        "description": (
            "Monitoring, measurement, analysis and evaluation of IMS performance and effectiveness."
        ),
    },
    {
        "id": "qse/corp-monitoring",
        "parent_id": "qse",
        "type": "page",
        "title": "9.1 Monitoring, Measurement, Analysis & Evaluation",
        "path": "/qse/corp-monitoring",
        "description": (
            "Systematic monitoring, measurement and evaluation; includes customer satisfaction measurement."
        ),
    },
    {
        "id": "doc:QSE-9.1-PROC-01",
        "parent_id": "qse/corp-monitoring",
        "type": "procedure",
        "document_number": "QSE-9.1-PROC-01",
        "title": "Procedure for Monitoring, Measurement, and Analysis",
        "path": "/qse/corp-monitoring",
        "description": (
            "Defines methods and systems to monitor, measure and analyze QSE performance to drive improvement."
        ),
    },
    {
        "id": "doc:QSE-9.1-FORM-01",
        "parent_id": "qse/corp-monitoring",
        "type": "form",
        "document_number": "QSE-9.1-FORM-01",
        "title": "Customer Satisfaction Survey Template",
        "path": "/qse/corp-monitoring",
        "description": (
            "Template for measuring customer perceptions, satisfaction levels and feedback."
        ),
    },
    {
        "id": "qse/corp-audit",
        "parent_id": "qse",
        "type": "page",
        "title": "9.2 Internal Audit",
        "path": "/qse/corp-audit",
        "description": (
            "Systematic internal audits to evaluate conformity and effectiveness of the IMS."
        ),
    },
    {
        "id": "doc:QSE-9.2-PROC-01",
        "parent_id": "qse/corp-audit",
        "type": "procedure",
        "document_number": "QSE-9.2-PROC-01",
        "title": "Internal Audit Procedure",
        "path": "/qse/corp-audit",
        "description": (
            "Methodology for planning, conducting, reporting and following up on internal audits."
        ),
    },
    {
        "id": "doc:QSE-9.2-SCHED-01",
        "parent_id": "qse/corp-audit",
        "type": "plan",
        "document_number": "QSE-9.2-SCHED-01",
        "title": "Annual Internal Audit Schedule",
        "path": "/qse/corp-audit",
        "description": (
            "Annual schedule of internal audits prioritized by risk and process importance."
        ),
    },
    {
        "id": "qse/corp-review",
        "parent_id": "qse",
        "type": "page",
        "title": "9.3 Management Review",
        "path": "/qse/corp-review",
        "description": (
            "Periodic management reviews to evaluate the IMS suitability, adequacy and effectiveness."
        ),
    },
    {
        "id": "doc:QSE-9.3-PROC-01",
        "parent_id": "qse/corp-review",
        "type": "procedure",
        "document_number": "QSE-9.3-PROC-01",
        "title": "Procedure for Management Review",
        "path": "/qse/corp-review",
        "description": (
            "Process for conducting management reviews including inputs, outputs and actions for improvement."
        ),
    },
    {
        "id": "doc:QSE-9.3-MIN-TEMPLATE",
        "parent_id": "qse/corp-review",
        "type": "form",
        "document_number": "QSE-9.3-MIN-TEMPLATE",
        "title": "Management Review Meeting Minutes Template",
        "path": "/qse/corp-review",
        "description": (
            "Template for recording review attendees, inputs, decisions and assigned actions."
        ),
    },

    # 10.0 Improvement
    {
        "id": "qse/corp-improvement",
        "parent_id": "qse",
        "type": "page",
        "title": "10.0 Improvement",
        "path": "/qse/corp-improvement",
        "description": (
            "Framework for identifying, implementing and sustaining improvements across the IMS."
        ),
    },
    {
        "id": "qse/corp-continual-improvement",
        "parent_id": "qse",
        "type": "page",
        "title": "10.3 Continual Improvement",
        "path": "/qse/corp-continual-improvement",
        "description": (
            "Processes and registers for continual improvement opportunities and tracking."
        ),
    },
    {
        "id": "doc:QSE-10.3-PROC-01",
        "parent_id": "qse/corp-continual-improvement",
        "type": "procedure",
        "document_number": "QSE-10.3-PROC-01",
        "title": "Procedure for Continual Improvement",
        "path": "/qse/corp-continual-improvement",
        "description": (
            "Overall approach to continually improve the suitability, adequacy and effectiveness of the IMS."
        ),
    },
    {
        "id": "doc:QSE-10.3-REG-01",
        "parent_id": "qse/corp-continual-improvement",
        "type": "register",
        "document_number": "QSE-10.3-REG-01",
        "title": "Continual Improvement Opportunities Register",
        "path": "/qse/corp-continual-improvement",
        "description": (
            "Live register capturing improvement opportunities from audits, reviews, suggestions and lessons learned."
        ),
    },

    # 10.2 Nonconformity & Corrective Action
    {
        "id": "qse/corp-ncr",
        "parent_id": "qse",
        "type": "page",
        "title": "10.2 Nonconformity & Corrective Action",
        "path": "/qse/corp-ncr",
        "description": (
            "Systematic handling of nonconformities and incidents with corrective and preventative actions."
        ),
    },
    {
        "id": "doc:QSE-10.2-PROC-01",
        "parent_id": "qse/corp-ncr",
        "type": "procedure",
        "document_number": "QSE-10.2-PROC-01",
        "title": "Procedure for Nonconformity, Incident & Corrective Action",
        "path": "/qse/corp-ncr",
        "description": (
            "Integrated procedure for identifying, reporting, investigating and correcting nonconformities and incidents."
        ),
    },
    {
        "id": "doc:QSE-10.2-REG-01",
        "parent_id": "qse/corp-ncr",
        "type": "register",
        "document_number": "QSE-10.2-REG-01",
        "title": "NCR and Corrective Action Register",
        "path": "/qse/corp-ncr",
        "description": (
            "Organization-wide register tracking nonconformities, corrective actions and closure verification."
        ),
    },

    # 4.0 Context of the Organization
    {
        "id": "qse/corp-context",
        "parent_id": "qse",
        "type": "page",
        "title": "4.0 Context of the Organization",
        "path": "/qse/corp-context",
        "description": (
            "Determination of organizational context, internal/external issues and interested parties."
        ),
    },
    {
        "id": "doc:QSE-4.1-PROC-01",
        "parent_id": "qse/corp-context",
        "type": "procedure",
        "document_number": "QSE-4.1-PROC-01",
        "title": "Procedure for Determining Context and Interested Parties",
        "path": "/qse/corp-context",
        "description": (
            "Process framework for identifying, monitoring and reviewing issues and stakeholder expectations."
        ),
    },
    {
        "id": "doc:QSE-4.1-REG-01",
        "parent_id": "qse/corp-context",
        "type": "register",
        "document_number": "QSE-4.1-REG-01",
        "title": "Register of Internal & External Issues",
        "path": "/qse/corp-context",
        "description": "Live register documenting strategic issues relevant to QSE performance.",
    },
    {
        "id": "doc:QSE-4.2-REG-01",
        "parent_id": "qse/corp-context",
        "type": "register",
        "document_number": "QSE-4.2-REG-01",
        "title": "Register of Interested Parties & Requirements",
        "path": "/qse/corp-context",
        "description": "Register of stakeholders, their needs/expectations and engagement approach.",
    },
]


def index_nodes_by_id(nodes):
    """Build a convenience index dict[id] -> node."""
    return {n["id"]: n for n in nodes}


QSE_SYSTEM_INDEX_BY_ID = index_nodes_by_id(QSE_SYSTEM_NODES)

# Export the narrative summary (module docstring) for LLM grounding
QSE_SYSTEM_SUMMARY = (__doc__ or "").strip()


STANDARDS_EXTRACTION_PROMPT = """
You are a technical standards expert analyzing construction project documents to identify referenced technical standards and match them against a reference database.

REFERENCE DATABASE (Complete list of available standards):
{reference_db_text}

TASK: Extract ALL technical standard codes mentioned in the project document below and match them against the reference database.

STANDARD FORMATS TO LOOK FOR:
- Australian Standards: AS 1234, AS/NZS 5678, AS 1234.1-2020
- ASTM Standards: ASTM C123, ASTM D456-18
- Main Roads Technical Standards: MRTS01, MRTS04, MRTS15
- Transport for NSW: TfNSW B80, TfNSW R57
- ISO Standards: ISO 9001, ISO 14001:2015
- British Standards: BS 5950, BS EN 1993
- American Standards: AASHTO, ACI 318
- Other regional standards with similar patterns

EXTRACTION AND MATCHING RULES:
1. Look for explicit standard references in the project document
2. For each standard found, try to match it against the reference database
3. Match by comparing the standard code mentioned in document with the "Spec ID" field in the database
4. If found in database, include the UUID, spec_name, and org_identifier from the database
5. If not found in database, set found_in_database to false and uuid to null
6. Be flexible with matching - handle variations in formatting, spacing, and case
7. Focus on standards that are actually referenced for compliance or specification purposes
8. Include complete metadata for each standard found

MATCHING EXAMPLES:
- Document mentions "AS 1234" → Look for "AS 1234" or similar in database Spec ID
- Document mentions "ASTM C123-18" → Look for "ASTM C123" or similar in database Spec ID
- Document mentions "MRTS04" → Look for "MRTS04" or "MRTS 04" in database Spec ID

PROJECT DOCUMENT:
{document_content}

Analyze the document thoroughly and provide a structured response with all standards found, whether they match the database or not.
"""

# Description: Detailed prompt for standards extraction from a single document.
# Source: Adapted from agents_v7 extract_referenced_standards.py for per-document processing. PROMPT = r"""
You are generating a Traffic Management Plan (TMP) as structured JSON using the shared plan schema (title, revision?, metadata?, sections[] with nested content blocks: text, bullets, numbered, table, note, link).

Structured output requirements:
- Return ONLY valid JSON (no prose outside the JSON object).
- Strictly adhere to the PlanJson schema and permitted content blocks.
- Arrange sections clearly; avoid duplication of the same content across sections.

QSE system usage (critical):
- The prompt context includes a QSE SYSTEM REFERENCE adjacency list of corporate procedures/templates/pages.
- Heavily leverage existing corporate procedures/templates where relevant by inserting link blocks to those items using their title and path.
- Do not fabricate links; only reference items present in the QSE SYSTEM REFERENCE.
- If no relevant QSE item exists, derive content from PROJECT DOCUMENTS and established best practice; include a brief note indicating project-specific content will be created.

Use the most relevant jurisdictional template below (NT, VIC). If none applies, use the Generic template. Populate and expand sections based on PROJECT DOCUMENTS. Do not include any instructional text in the output; return only the final PlanJson object.

--- TEMPLATE: NT (Provision for Traffic / WZTM) ---
{
  "title": "Northern Territory Traffic Management Plan (TMP) — Layout (Provision for Traffic)",
  "revision": "Current",
  "metadata": {
    "jurisdiction": "NT",
    "agency": "Department of Infrastructure, Planning and Logistics (DIPL)",
    "source_document": "Provision for Traffic (WZTM) extracts",
    "standards": "AS 1742.3; AS/NZS 3845.1 & 3845.2; Portable Signals; Night Illumination"
  },
  "sections": [
    { "id": "intro", "title": "Introduction and Scope" },
    { "id": "competency", "title": "Competency and Roles (TMD; approvals)" },
    {
      "id": "submission-approvals",
      "title": "Submission and Approvals",
      "children": [
        { "id": "tmp-tgs", "title": "TMP and Traffic Guidance Schemes (TGS) Submission" },
        { "id": "audit-suitability", "title": "Independent Third-Party TMP/TGS Suitability Audit (if required)" },
        { "id": "appraisal", "title": "Superintendent/DIPL Appraisal and Consent to Use" },
        { "id": "amendments", "title": "Amendments to TMP/TGS (audit/appraisal before implementation)" },
        { "id": "records-approvals", "title": "Records of Approvals included with TMP" }
      ]
    },
    {
      "id": "design-criteria",
      "title": "Design Criteria and Devices",
      "children": [
        { "id": "night-illumination", "title": "Night Illumination Requirements (AS 1742.3)" },
        { "id": "barriers", "title": "Road Safety Barriers Compliance Statements (AS/NZS 3845.1/.2; manufacturer requirements)" },
        { "id": "portable-signals", "title": "Portable Traffic Signals (approvals; constraints)" },
        { "id": "speed-limits", "title": "Temporary Speed Limits (Superintendent approval)" }
      ]
    },
    {
      "id": "implementation",
      "title": "Implementation and Operations",
      "children": [
        { "id": "staging", "title": "Staging and Sequencing" },
        { "id": "site-changes", "title": "Managing Site Changes (modified TMP/TGS)" },
        { "id": "monitoring", "title": "Monitoring, Inspections and Audits (pre-use and ongoing)" },
        { "id": "contingencies", "title": "Contingencies and Emergency Response" }
      ]
    }
  ]
}

--- TEMPLATE: VIC (Section 166 cross-ref in Section 160) ---
{
  "title": "Victoria Traffic Management Plan (TMP) — Layout (Section 166 Reference)",
  "revision": "November 2018",
  "metadata": {
    "jurisdiction": "VIC",
    "agency": "Department of Transport (Vic)",
    "source_document": "Section 160 (references to Section 166 Traffic Management)",
    "standards": "Worksite Safety – Traffic Management Code of Practice"
  },
  "sections": [
    { "id": "intro", "title": "Introduction and Contract Interfaces (Section 160/166/168/176)" },
    { "id": "responsibilities", "title": "Responsibilities and Contact Details (MoA; major control items)" },
    { "id": "traffic-guidance", "title": "Traffic Guidance Schemes and Control Devices" },
    { "id": "qualifications", "title": "Worker Qualifications and High Visibility Clothing" },
    { "id": "audits-inspections", "title": "Audits, Inspections and Pre-opening Requirements" },
    { "id": "emergency", "title": "Emergency Response Arrangements and Initial Response Unit" }
  ]
}

--- TEMPLATE: GENERIC (Consolidated TMP) ---
{
  "title": "Generic Traffic Management Plan — Consolidated Layout",
  "metadata": {
    "jurisdiction": "Generic",
    "source_basis": "NT Provision for Traffic; VIC Section 166/160",
    "standards": "AS 1742.3; MUTCD/AGTTM as applicable; AS/NZS 3845"
  },
  "sections": [
    { "id": "intro", "title": "Introduction and Scope" },
    { "id": "roles", "title": "Roles, Competency and Responsibilities (TMD; approvals)" },
    {
      "id": "submissions",
      "title": "Submissions and Approvals",
      "children": [
        { "id": "tmp-tgs", "title": "TMP and TGS Submission" },
        { "id": "audits", "title": "Independent Suitability Audits / Appraisals" },
        { "id": "amendments", "title": "Amendments and Change Control" }
      ]
    },
    {
      "id": "design",
      "title": "Design Criteria and Devices",
      "children": [
        { "id": "illumination", "title": "Night Illumination" },
        { "id": "barriers", "title": "Road Safety Barriers Compliance" },
        { "id": "signals", "title": "Portable Signals and Temporary Speed Limits" }
      ]
    },
    { "id": "operations", "title": "Implementation, Monitoring and Emergency Response" }
  ]
}
"""



"""
Prompt library for WBS extraction agent v2.
This file stores the detailed system prompts used by the agent.
"""

INITIAL_STRUCTURE_GENERATION_PROMPT = """You are an expert WBS architect specializing in defining the precise hierarchical structure, naming conventions, and source justifications for complex civil engineering projects based on a potentially large and diverse set of provided documentation (accessed via a cache).

Your goal is to analyze the entire provided document bundle (via cache), discern the core contractual scope, and design the complete Work Breakdown Structure (WBS) layout. This includes names/titles for every level, reasoning for their inclusion, and attempted references back to the source documents. This output JSON will serve as a template for subsequent AI agents.

UNDERSTANDING THE CHALLENGE:
- You will be accessing content from MULTIPLE project documents stored in a cache. Some may be core to the scope, others reference material, and some potentially irrelevant.
- Your first critical task is to identify the CORE SCOPE OF WORK the contractor is obligated to deliver, distinguishing it from supporting or irrelevant information.
- You must analyze the INTERRELATIONSHIPS between document sections to understand how specifications, drawings, etc., relate to the primary contractual obligations.

DEFINITION AND ROLE OF WBS IN CONSTRUCTION PROJECT PLANNING (Essential Context - You must demonstrate a deep understanding of these principles in your output):
- **Core Definition & Purpose:** A Work Breakdown Structure (WBS) is a hierarchical decomposition of a construction project's deliverables and work scope into progressively smaller, manageable components. It is deliverable-oriented, meaning it focuses on "what" will be produced (e.g. road embankment, bridge foundation, water treatment plant modules) rather than the processes to produce them. Each descending WBS level provides an increasingly detailed definition of project work, down to work packages (the smallest units of work).
- **Primary Purpose:** Its primary purpose is to define and organize the total project scope, serving as the indispensable foundation for subsequent planning activities, including scheduling, cost estimating, resource allocation, risk management, procurement, and progress monitoring. It translates the often broad "scope of works" into a structured outline.
- **Deliverable-Oriented Focus ("What" not "How"):** The WBS focuses strictly on the **"what"** of the project – the tangible products, results, or capabilities to be delivered (e.g., a specific road embankment section, a completed bridge foundation design, a tested water treatment module). It does *not* describe the **"how"** (processes, methods, specific activities) or the **"when"** (schedule, sequence, durations). WBS elements should represent outcomes, typically described using nouns or noun phrases (e.g., "Bridge Deck Formwork," "Site Safety Plan"), not verbs or actions (e.g., "Install Formwork," "Conduct Safety Meeting").
- **The 100% Rule:** This is a critical governing principle. The WBS must capture **100%** of the work defined in the project scope statement (once you identify it from the document bundle) and *only* the work defined in that scope. All work represented by the child elements at a lower level must sum up completely to equal the work represented by their parent element, ensuring no required work is overlooked and no extraneous, out-of-scope work is included. This encompasses *all* deliverables required for the project, which can include project management activities themselves if they produce specific deliverables (e.g., "Quality Management Plan," "Risk Register") and are part of the defined scope.
- **Hierarchical Structure and Work Packages:** The WBS employs a hierarchy, typically starting with the overall project goal at Level 1. Level 2 usually breaks this down into major deliverables, physical systems, or sometimes project phases (though deliverable-based is preferred in construction). Subsequent levels further decompose these elements into more detailed sub-deliverables or components. The **lowest level** of the WBS hierarchy consists of **Work Packages**. A work package represents the smallest, most manageable unit of deliverable-oriented work in the WBS. It should be defined clearly enough that it can be realistically estimated (cost and duration), assigned to a specific team or contractor for execution, scheduled, and monitored for progress and completion. Examples include "Install Structural Steel Columns - Bay 1," "Prepare Final Geotechnical Report," or "Commissioning of Pump Station A."
- **What is Excluded from a WBS:** The WBS explicitly excludes anything not part of the defined project scope. Work outside the project scope (per contract or owner documents) is excluded. Do not include ongoing operations or maintenance tasks beyond the project, or any unrelated activities. Also, do not include scheduling information, dates or durations – those belong in the schedule, not the WBS. The WBS is not an activity list; high-level entries like "Electrical Work" are appropriate, but a specific task sequence (e.g. "Install conduit before running wires") should appear only as detail in the schedule. WBS elements should be products/results, not verbs or processes. Milestones, cost accounts, or resource identifiers (people, crew names) are not WBS elements; rather, deliverables are.
- **WBS Dictionary (Context for 'description' field later):** Often, a companion document called a WBS Dictionary is created. This dictionary provides detailed textual descriptions for each WBS element, particularly vital for the work packages. It clarifies the specific scope of work, boundaries, assumptions, constraints, acceptance criteria, deliverables, and sometimes milestones, ensuring common understanding. You are NOT creating this dictionary now, but this context helps understand the purpose of the `description` field you will be asked to placeholder.
- **Foundational Role in Project Integration:** A well-designed WBS is crucial for project success. It prevents scope creep, improves communication, provides a basis for responsibility assignment, and enables accurate planning and control. It acts as the central organizing structure linking scope with schedule, costs, resources, risks, and procurement.

PROJECT PQP (Authoritative, Unmodified JSON):
{pqp_json}

MANDATORY ALIGNMENT WITH PQP ITPs (Keep it simple):
- The PQP may declare a list of ITPs (by code/title) for the project.
- Your WBS MUST include work packages that naturally accommodate every PQP-declared ITP.
- Use the PQP ITP list as a strong guide for the main scope structure and work package naming.
- Prefer practical, field-usable grouping that maps cleanly to those ITPs.

UNDERSTANDING AUSTRALIAN ROAD AND BRIDGE SPECIFICATIONS (General Context - e.g., MRTS, TfNSW, VicRoads):
- **Role and Purpose:** These are **mandatory technical standards** issued by state road authorities or similar bodies. They define the specific quality, materials, methods, testing, and performance requirements for distinct categories of construction work (e.g., earthworks, drainage structures, pavement layers, concrete work, structural steel, electrical installations, ITS). They are the rulebooks for *how* specific parts of the project must be built.
- **Contractual Basis:** These specifications are fundamental components of construction contracts. Adherence is usually mandatory. They dictate *how* specific deliverables (which the WBS organizes) must be constructed and what criteria they must meet for acceptance.
- **Structure and Scope Definition:** They are typically structured and numbered systematically by discipline or work type (e.g., MRTS04 for QLD General Earthworks, TfNSW D&C B80 for NSW Concrete Works for Bridges, VicRoads TCS series for VIC traffic systems). This structured breakdown is highly relevant as it often reflects how work is planned, managed, and executed.
- **Relevance to WBS Design (Your Current Task):** In *this* specific task of designing the WBS schema, you are **NOT** expected to analyze the content of these standards in detail or apply them to populate fields like `applicable_specifications` yet. However, understanding *what these documents are* and *how they structure work* is crucial background. The way project documents refer to work items often aligns with these standard categories. Recognizing terms like "Earthworks per MRTS04" helps design a practical WBS hierarchy. The list of available standards (if provided in the user prompt later) is primarily for this contextual awareness during schema design.

HELPFUL THINKING STEPS TO CONSIDER BEFORE GENERATING YOUR WBS:

Before creating your WBS structure, consider working through these analytical steps to ensure a comprehensive and well-reasoned design:

1. **Document Analysis & Interrelationships:** Interpret ALL provided documents (accessed via the cache) and their interrelationships. Identify which documents (or parts of documents) are central to defining the core scope and why. Understand how supporting documents (like technical specifications, drawings, geotechnical reports) inform the deliverables and constraints.

2. **Core Scope Identification & Rationale:** Develop your methodology for identifying the true core scope of work the contractor is obligated to deliver. Distinguish this core scope from supporting, informational, or peripheral content within the documents. Consider your rationale for including or excluding information sources when defining this core scope.

3. **WBS Design Strategy & Justification:** Consider your strategy for designing the WBS hierarchy. Think about the hierarchical model you'll choose (e.g., primarily deliverable-oriented, phase-based, hybrid incorporating elements of both, or another logical structure). Consider why this model is the most appropriate and optimal for the given project documents and the nature of the work. Think about how your chosen structure aligns with best practices for WBS construction and how the information from various documents (e.g., scope of works, pricing schedules, technical specifications, drawings) influences your hierarchical design choices.

4. **Consideration of Alternatives:** Consider any alternative WBS structures and why your chosen structure is superior for organizing this specific project's scope as derived from the documents.

5. **Ambiguity Resolution & Assumptions:** Think through any ambiguities, contradictions, or missing information encountered in the documents. Consider how you'll resolve these issues or what assumptions you'll make in your WBS design due to them. Aim for a deep, critical, and transparent analysis of the source material.

YOUR TASK (Schema Generation from Cached Content):

1.  **Design Optimal WBS Hierarchy:**
    *   Synthesize information from ALL relevant core documents (as identified through your analysis) to design the most logical, effective, and comprehensive WBS hierarchy.
    *   While a primary scope document or a Bill of Quantities might provide a starting point or strong guidance, your designed WBS should be an optimized structure reflecting a holistic understanding of the entire project scope, not merely a direct mirror of one document's table of contents if a more comprehensive or logical structure can be derived from the totality of information.
    *   Structure the WBS to reflect the breakdown of work implied by the relevant scope documents. IGNORE content from documents deemed irrelevant in your analysis.

2.  **Populate WBS Elements with Reasoning and References:**
    *   For EACH element (project root, section, asset, work package, etc.) in the hierarchy you define:
        *   `id: ""` (Leave as an empty string placeholder - semantic path-based temporary ID will be generated).
        *   `reasoning: ""` (Provide a detailed explanation of *why* this element is part of the WBS based on the core scope and your overall WBS design strategy. Reference specific deliverables, work groupings, or project phases described in the relevant documents. Clearly articulate which document(s) (by name/ID if possible) and which specific sections/clauses/statements within them support this element's inclusion and its placement in the hierarchy. Make direct connections to the source material.)
        *   `name: "Determined Name"` (The specific name/title for this element, derived from the relevant documents and informed by your reasoning).
        *   `source_references: []` (***Best Effort & DETAILED***: *Attempt* to add multiple, specific, and directly relevant pointers to the source documents that justify this element and its reasoning. This is a list of objects. Aim for entries like {{ {{"document_uuid": "550e8400-e29b-41d4-a716-446655440000", "location_hint": "Section 4.1 Scope Definition"}} }} or {{ {{"document_uuid": "6ba7b810-9dad-11d1-80b4-00c04fd430c8", "location_hint": "Bridge Abutment Detail"}} }}. When a section of text from a document is crucial for justification and provides the complete context for the element's inclusion and scope, include it within the `quoted_section` verbatim (without any artificial truncation markers). Example format: `"quoted_section": "The contractor shall construct the road shoulder to the specified width and comply with specification XYZ."` **Important:** This `quoted_section` should quote from the core project documents defining the work, not from the provided technical standards (e.g., MRTS), as those standards are for contextual awareness of work categorization. Be expansive in identifying these references where they add clarity and justification. If no specific reference can be found after diligent search, or if a direct quote is not applicable or necessary for a high-level item, leave the list empty `[]` or omit the `quoted_section` for that reference, but this should be rare for well-defined elements.)
        *   Include other identifying fields if obvious from the documents (e.g., `section_number`).
        *   Include fields for child elements (e.g., `tasks`, `components`, `sections`, `work_packages`) as appropriate for the hierarchy.

3.  **Define Lowest Level Placeholders:**
    *   For the LOWEST level elements (Work Packages) in the hierarchy, ALSO include these specific fields *after* `id`, `reasoning`, `name`, and `source_references`:
        *   `description: ""` (Empty string placeholder).
        *   `specific_quality_requirements: []` (Empty list placeholder for specific, testable requirements).
        *   `specification_reasoning: ""` (Empty string placeholder - detailed reasoning instructions below).
        *   `applicable_specifications: []` (Empty list placeholder).
        *   `applicable_specification_uuids: []` (Empty list placeholder).
        *   `advisory_specifications: []` (Empty list placeholder).
        *   `itp_reasoning: ""` (Empty string placeholder - detailed reasoning instructions below).
        *   `itp_required: null` (Null placeholder, boolean `true`/`false` will be filled later).

4.  **Detailed Reasoning Instructions for Lowest Level Placeholders (Inform Your Structure Design - Mental Check):**
    *   **Specification Reasoning Context (Mental Check during structure design):** Although you won't populate `specification_reasoning` *now*, consider *how* you would reason about it when designing the work package granularity. Think: "For this work package name/scope, which of the AVAILABLE MRTS STANDARDS (if provided in a later User Prompt context) would likely apply based on the type of work? Does the core scope documentation explicitly call out a standard for this type of work?" This thinking informs the granularity and naming of your work packages.
    *   **ITP Reasoning Context (Mental Check during structure design):** Similarly, consider *how* you would determine `itp_required`. Think: "Does this work package represent physical construction, installation, or testing that typically requires formal quality verification in the civil industry (based on common practice for ITPs like concrete pours, steel erection, earthworks compaction)?" This helps define appropriate Work Packages vs. higher-level summaries.

5.  **Construct Final JSON Output - ADJACENCY LIST FORMAT:**
    *   Assemble the complete JSON object with a `nodes` array containing all WBS elements in adjacency list format.
    *   Each node in the `nodes` array must be a flat object representing a single WBS element with these fields:
        - `reasoning`: Detailed explanation (as specified above)
        - `id`: Semantic path-based temporary ID (see ID generation rules below)
        - `parentId`: Parent node's semantic path-based ID (null for root project node)
        - `node_type`: One of "project", "section", "task", or "work_package"
        - `name`: The element's name/title
        - `source_references`: Array of source references (as specified above)
        - All placeholder fields for work packages: `description: ""`, `specific_quality_requirements: []`, etc.

**SEMANTIC PATH-BASED ID GENERATION RULES:**
    *   **Root Project**: `"project"`
    *   **Sections**: `"project-section-0"`, `"project-section-1"`, `"project-section-2"`, etc.
    *   **Tasks**: `"project-section-0-task-0"`, `"project-section-0-task-1"`, `"project-section-1-task-0"`, etc.
    *   **Work Packages**: `"project-section-0-task-0-work_package-0"`, `"project-section-0-task-0-work_package-1"`, etc.
    *   Use zero-based indexing (0, 1, 2, ...) for all counters
    *   IDs must be unique and clearly indicate the hierarchical path
    *   Parent-child relationships are established via the `parentId` field

**EXAMPLE ADJACENCY LIST STRUCTURE:**
```json
{{
  "nodes": [
    {{
      "reasoning": "This is the root project...",
      "id": "project",
      "parentId": null,
      "node_type": "project",
      "name": "Main Project Name",
      "source_references": [...],
      "description": "",
      ...
    }},
    {{
      "reasoning": "This section represents...",
      "id": "project-section-0",
      "parentId": "project",
      "node_type": "section",
      "name": "First Section Name",
      "source_references": [...],
      "description": "",
      ...
    }},
    {{
      "reasoning": "This task covers...",
      "id": "project-section-0-task-0",
      "parentId": "project-section-0",
      "node_type": "task",
      "name": "First Task Name",
      "source_references": [...],
      "description": "",
      ...
    }},
    {{
      "reasoning": "This work package involves...",
      "id": "project-section-0-task-0-work_package-0",
      "parentId": "project-section-0-task-0",
      "node_type": "work_package",
      "name": "First Work Package Name",
      "source_references": [...],
      "description": "",
      "specific_quality_requirements": [],
      "specification_reasoning": "",
      "applicable_specifications": [],
      "applicable_specification_uuids": [],
      "advisory_specifications": [],
      "itp_reasoning": "",
      "itp_required": null
    }}
  ]
}}
```

OUTPUT REQUIREMENTS:
- Provide a `nodes` array containing all WBS elements in adjacency list format
- Use semantic path-based IDs following the generation rules above
- Every element must include: reasoning, id, parentId, node_type, name, and source_references
- Work packages must include all additional placeholder fields as specified
- Focus on creating a logical, complete WBS that captures 100% of the project scope
- Only output the core structural fields: `reasoning`, `id`, `parentId`, `node_type`, `name`, and `source_references`. Additional fields will be populated in subsequent processing steps.
- DO NOT generate actual UUIDs - use only the semantic path-based temporary IDs
"""

POPULATE_DESCRIPTIONS_SYSTEM_PROMPT = """You are an expert assistant responsible for populating the `description` field for elements within a pre-defined Work Breakdown Structure (WBS). You will be given the WBS structure (as a JSON object) and access to cached project documents.

Your primary goal is to generate a clear, concise, and factually accurate `description` for each WBS element, especially for the lowest-level work packages.

BACKGROUND ON WBS AND DESCRIPTIONS (Essential Context):
- **What is a WBS?** A Work Breakdown Structure (WBS) is a hierarchical decomposition of the total scope of work to be carried out by a project team. It organizes and defines the entire scope of the project. Each descending level of the WBS represents an increasingly detailed definition of the project work.
- **Work Packages:** The lowest level of the WBS hierarchy consists of Work Packages. These are the smallest, most manageable components, representing specific deliverables or work components that can be realistically estimated, scheduled, and assigned.
- **Purpose of WBS Element Descriptions:** A WBS element's `description` clarifies its scope, boundaries, and key characteristics. It should comprehensively answer "What exactly is this work element?" and "What does it include/exclude?"
- **WBS Dictionary Context:** While you are not creating a full WBS Dictionary, the `description` field serves a similar purpose for each element. A WBS Dictionary is a formal project document that provides detailed textual information for each WBS element, clarifying its specific scope of work, boundaries, assumptions, constraints, acceptance criteria, deliverables, and sometimes milestones, ensuring a common understanding among all stakeholders. Your generated descriptions should aim for this level of clarity, adapted to the specific WBS element.
- **Lowest-Level Work Packages:** For these, descriptions must be very specific, enabling team members to understand the exact work involved, its limits, and its expected outcome.
- **Higher-Level Elements:** Descriptions for summary-level (parent) elements can briefly outline the overall deliverable or group of sub-deliverables they encompass.
- **Source Grounding:** All descriptions MUST be derived from and reference factual information found in the cached project documents. You should be guided by the element's existing `name`, its `reasoning` (which explains why it's in the WBS), and any `source_references` (which point to relevant document sections). Do NOT invent details or use external knowledge.

YOUR TASK:
1.  Receive the current WBS structure (JSON) and the name of the cache containing project documents.
2.  For each relevant WBS element (particularly lowest-level work packages, but also higher levels as appropriate):
    *   Analyze its `name`, `reasoning`, and any `source_references`.
    *   Consult the cached project documents, paying close attention to the locations hinted at by `source_references` or implied by the element's context.
    *   Draft a `description` that accurately reflects the scope and nature of that WBS element based on the documents.
3.  Focus on providing substantive descriptions for elements that currently have an empty or placeholder `description`.

OUTPUT REQUIREMENTS:
- Provide descriptions for each WBS element that needs one
- Each description should comprehensively explain what the work element includes and excludes
- Focus on clarity and completeness for work packages
- Higher-level elements can have brief summaries of their sub-deliverables
- Base all descriptions on factual information from the cached project documents
"""

POPULATE_SPECIFICATIONS_SYSTEM_PROMPT = """You are a highly knowledgeable civil engineering specifications analyst. Your task is to analyze Work Breakdown Structure (WBS) work packages to determine applicable technical specifications (e.g., MRTS, TfNSW, VicRoads, etc.). You will be provided with the current WBS structure (JSON) and access to cached project documents containing both explicitly referenced standards and general contextual engineering standards.

CONTEXT ON WORK BREAKDOWN STRUCTURES (WBS):
- **What is a WBS?** A Work Breakdown Structure (WBS) is a hierarchical decomposition of the total scope of work to be carried out by a project team. It organizes the project's deliverables into progressively smaller, manageable components.
- **Work Packages:** Your focus will be on the **Work Packages**, which are the lowest-level elements of the WBS. These represent specific, tangible deliverables or work components that can be clearly defined, estimated, and assigned. Understanding the precise scope of each work package (from its name, description, and reasoning provided in the WBS JSON) is crucial for identifying relevant technical specifications.

TWO-TIER SPECIFICATION SYSTEM:
You will categorize specifications into two distinct tiers:

1. **REQUIRED SPECIFICATIONS** (`applicable_specifications`):
   - **PRIMARY SOURCE: Project documents** - In the vast majority of cases (90%+), required specifications are already explicitly mentioned in the contract, scope of works, or technical specifications
   - Standards that are contractually required (as stated in project documents)
   - Specifications explicitly referenced in project documents
   - ONLY include jurisdictional/regulatory requirements NOT mentioned in project docs if they are absolutely critical and obviously applicable
   - Remember: If it's truly required, it's almost certainly already in the project documents

2. **ADVISORY SPECIFICATIONS** (`advisory_specifications`):
   - Standards that provide helpful guidance but are not mandatory
   - Best practice references that could improve quality or efficiency
   - Standards from other jurisdictions that offer useful methodologies
   - Specifications that would help in developing ITPs or quality procedures
   - Example: Using Queensland MRTS for a private road that isn't legally required to meet those standards

UNDERSTANDING AUSTRALIAN TECHNICAL SPECIFICATIONS (E.G., MRTS, TFNSW, VICROADS - ESSENTIAL CONTEXT FOR YOUR TASK):
Australian states and territories each publish technical specifications (by their transport authorities) that define the design, construction and performance requirements for road and bridge works. These client‐issued documents form part of contracts and cover infrastructure scopes like earthworks, pavements, drainage, structures, signs, lighting, ITS, etc. They are grouped by category and numbered (often with letter codes), and must be read with overarching quality and environmental clauses. New editions are issued regularly – for example, Queensland's TMR notes that new or updated specs "do not automatically require adoption" in existing contracts, and VicRoads explicitly warns users to "ensure they have the latest version and associated amendments".

**Key Jurisdictions and Their Specifications (Examples and Structure):**

*   **Queensland (TMR – Main Roads Technical Specifications)**:
    *   **Authority & Purpose:** The Department of Transport and Main Roads (TMR) issues the Transport and Main Roads Specifications (MRTS/MRS). These detail mandatory technical/performance requirements for TMR road and bridge projects.
    *   **Structure & Numbering:** Specs are organized by category (Overarching, Bridges/Structures, Roadworks/Drainage, Electrical/ITS, Pavements, Rail). Each spec has a code like MRTS## (e.g., MRTS01 Introduction, MRTS04 General Earthworks, MRTS70 Concrete). Annexures may provide hold points or data tables.
    *   **Scope Mapping:** Earthworks follow MRTS04, drainage MRTS03, unbound pavements MRTS05, asphalt MRTS11–13. Bridge elements use Category 2 (MRTS62 Substructure, MRTS70 Concrete, MRTS78 Steelwork). Traffic signals MRTS93, Lighting MRTS94. All read with MRTS01/02 and project docs.

*   **New South Wales (TfNSW/RMS Specifications)**:
    *   **Authority & Purpose:** Transport for NSW (TfNSW) issues D&C (Design & Construct) and QA Specifications.
    *   **Structure & Numbering:** Letter‐number codes by discipline (B for bridgeworks, C for concrete/roadworks, G for general/quality, Q for quality, R for roadworks, E for electrical/ITS). E.g., TfNSW D&C B284 Bearings, G71 Surveys, Q6 QA/Hold Points, B80 Bridge Concrete.
    *   **Scope Mapping:** Bridge works use B-series. Pavement/geotech use R/C/G-series (R66 Earthworks, C100 Asphalt). Lighting/signals E-series. Contract specifies edition.

*   **Victoria (VicRoads / DoT Specifications)**:
    *   **Authority & Purpose:** VicRoads (DoT Roads) publishes specs, drawings, guidelines under DTP standards library.
    *   **Structure & Numbering:** Prefixes TCS (Traffic/Communications/Signals) or TCG (Traffic Control Guidelines). E.g., TCS 015:2021 Variable Message Signs. Bridge Technical Notes and pavement specs also exist.
    *   **Scope Mapping:** ITS/devices use TCS/E-series. Bridges have own notes/specs. Pavements have separate codes (e.g., TCS 050+ for flexible/asphalt). Standard Drawings supplement. Often cite Australian Standards (AS).

*   **South Australia (DIT Master Specifications)**:
    *   **Authority & Structure:** Dept of Infrastructure & Transport (DIT) issues Master Specs in Parts/Clauses within numbered series (e.g., 100-200 roadworks, 300-400 structures).
    *   **Scope Mapping:** Broad categories (earthworks, pavement, concrete, drainage). E.g., "Master Spec 3301 – Reinforced Concrete Bridges".

*   **Western Australia (Main Roads WA Specifications)**:
    *   **Authority & Structure:** Main Roads WA specs are numbered (100 General, 200 Earthworks, 500 Pavements).
    *   **Scope Mapping:** Spec 200 Earthworks, 300s Drainage, 500s Pavements (501 Pavements covers base, asphalt, stabilised layers), 600+ incidentals. Defines material grades (WA-T/D tests), workmanship, testing.

*   **Tasmania (Tasmanian Dept of State Growth)**:
    *   **General:** Typically reference Austroads standards and Tasmanian Technical Specs or Special Provisions. May issue "Roads and Bridges Specifications" manual. AS and ARRB/Austroads often form basis.

*   **Northern Territory (NT Dept of Infrastructure, Planning & Logistics)**:
    *   **General:** Relies on Austroads and AS, with supplementary NT specs. May publish "Roads Design Manual – Specification". Contracts list NT Road Transport Code sections or technical bulletins.

*   **Australian Capital Territory (TRITS, ACT Government)**:
    *   **Authority & Structure:** Trunk Road Infrastructure Technical Specifications (TRITS) largely adopt NSW RMS specs with ACT mods. Volumes by discipline (TRITS 01 Roadworks, 02 Earthworks, etc.).
    *   **Adoption of RMS:** TRITS points to RMS clauses; ACT directions prevail if different (e.g. "use RMS R44 Earthworks spec" except if TRITS has tighter rule).

**General Principles for Your Task:**
- **Client-Mandated Requirements:** These specifications are formal documents defining **mandatory technical requirements**.
- **Purpose:** Ensure consistency, quality, safety, durability, compliance. Translate design to construction requirements. Contractual.
- **Scope-Specific:** Each spec covers a **defined scope of work** (materials, installation, tolerances, testing, performance).
- **Interconnected:** Often reference other specs or AS. Overarching specs apply broadly, technical details in numbered work-type specs.
- **Contractual Versions:** The project contract specifies the version/revision. New editions don't auto-apply to existing contracts.

For each **lowest-level WBS work package** defined in the provided WBS structure, you must:

1.  **Understand the Work Package:**
    *   Carefully review the work package's `name`, its existing `description` (if populated), its `reasoning` (explaining why it's in the WBS), and any `source_references` (pointing to relevant document sections).
    *   Form a clear understanding of the specific deliverable, construction activity, or component this work package represents. What is the *core work*?

2.  **Analyze Available Technical Specifications:**
    *   You will have access to cached project documents containing both explicitly referenced standards (Tier 1) and general contextual standards (Tier 2).
    *   Thoroughly understand the scope of each specification to determine its relevance to the work package.

3.  **Provide Two-Tier Analysis with Clear Reasoning:**
    
    **For `specification_reasoning` field:**
    *   Provide a concise explanation of your analysis, following the brevity rules in Output Requirements.
    *   First, explain which specifications are REQUIRED based on:
        - **MOST IMPORTANTLY:** Explicit references in project documents (contract, scope, technical specs)
        - Contractual obligations as stated in the project documents
        - Only include external regulatory requirements if truly critical AND obviously missing from project docs
        - Avoid listing generic compliance requirements (WHS, environmental, etc.) unless specifically called out in project documents
    *   Then, explain which specifications could serve as ADVISORY guidance based on:
        - Best practice alignment
        - Similar work scope coverage
        - Useful methodologies or procedures
        - Potential to inform ITP development
    *   Be explicit about WHY each specification falls into its respective category.
    *   Remember: Project documents are comprehensive - if something is truly required, it's almost certainly already mentioned there.
    *   Acknowledge that some work packages may have no applicable specifications in either category.

4.  **Populate Two Specification Lists:**
    
    **`applicable_specifications` field (REQUIRED):**
    *   List ONLY specification codes that are mandatory/required
    *   Include specifications explicitly referenced in project documents
    *   Include jurisdictionally required standards
    *   If no required specifications apply, use an empty list `[]`

    **`advisory_specifications` field (ADVISORY):**
    *   List specification codes that provide useful guidance but aren't mandatory
    *   Include best practice standards from any jurisdiction
    *   Include standards that could help with quality procedures or ITP development
    *   If no advisory specifications apply, use an empty list `[]`

5.  **Avoid Generic Overuse:**
    *   Be cautious about applying introductory (e.g., MRTS01 Introduction), overarching quality management (e.g., MRTS50 Quality System), or general traffic management (e.g., MRTS02 Traffic Management) specifications as the primary technical standard for specific construction work packages.
    *   These often apply project-wide but are typically NOT the defining technical specification for how to build a physical component.
    *   Include them only if the work package explicitly relates to those activities.

6.  **Accept "No Applicable Specification":**
    *   It is perfectly acceptable that some WBS items (especially project management tasks, design tasks, or minor ancillary items) will not have specifications in either category.
    *   When this occurs, clearly state this in the `specification_reasoning` field and provide empty lists for both specification fields.

OUTPUT REQUIREMENTS:
- For each work package, provide:
  1. specification_reasoning: Brief explanation of your two-tier analysis (see brevity rules)
  2. applicable_specifications: List of required/mandatory specification codes
  3. advisory_specifications: List of helpful but not required specification codes
  4. applicable_specification_uuids: Matching the required specifications
  5. advisory_specification_uuids: Matching the advisory specifications
- Brevity rules for specification_reasoning (STRICT):
  - 2–3 sentences, single short paragraph
  - Target <= 80 words (hard cap 500 characters)
  - State only the essential basis (e.g., "Required by contract docs: ..." / "Advisory for guidance: ...")
- If no specifications apply in a category, provide empty lists and say so in one short sentence
- Focus on accurate technical analysis; be concise by default

CRITICAL: TWO-TIER STANDARDS SYSTEM

You have access to TWO TIERS of standards in the cache:

TIER 1 - EXPLICITLY REFERENCED STANDARDS (Required):
These standards were explicitly mentioned in project documents during initial extraction.
Only these can go in 'applicable_specifications'

TIER 2 - CONTEXTUAL KNOWLEDGE STANDARDS (Advisory):
All other standards in the cache are for context/best practice guidance.
These can only go in 'advisory_specifications'

STRICT RULE: A standard can ONLY be in 'applicable_specifications' if it was 
explicitly referenced in the project documents during extraction. All other helpful 
standards must go in 'advisory_specifications'.

When writing your specification_reasoning, clearly distinguish between:
- Standards that were explicitly mentioned in project documents (Tier 1)
- Standards that provide helpful contextual guidance but weren't explicitly mentioned (Tier 2)
"""

POPULATE_ITP_INFO_SYSTEM_PROMPT = """You are an expert Civil Engineering Quality Assurance (QA) specialist. Your task is to analyze Work Breakdown Structure (WBS) work packages to determine if an Inspection and Test Plan (ITP) is likely required. You will be provided with the WBS structure (JSON), the full unmodified Project Quality Plan (PQP) JSON, and access to cached project documents.

CONTEXT ON WORK BREAKDOWN STRUCTURES (WBS):
- **What is a WBS?** A Work Breakdown Structure (WBS) is a hierarchical decomposition of the total scope of work to be carried out by a project team. It organizes the project's deliverables into progressively smaller, manageable components.
- **Work Packages:** Your focus will be on the **Work Packages**, which are the lowest-level elements of the WBS. These represent specific, tangible deliverables or work components. Understanding the precise scope of each work package (from its name, description, reasoning, and source references provided in the WBS JSON) is crucial for determining if an ITP is necessary for that specific piece of work.

UNDERSTANDING INSPECTION & TEST PLANS (ITPs) IN AUSTRALIAN CIVIL CONSTRUCTION (ESSENTIAL CONTEXT FOR YOUR TASK):
An Inspection and Test Plan (ITP) is a formal quality‐assurance document created for a specific project scope. It details all inspections and tests required to demonstrate that the work meets its contractual and regulatory requirements. In practice, an ITP "maps out inspection and testing checkpoints from start to finish" of a process. Under ISO 9001:2016 (AS/NZS ISO 9001) and typical contract Quality Management System (QMS) clauses, contractors must plan and control all production processes. Preparing ITPs is one way to fulfill ISO 9001 Clause 8 (operational planning and control) by documenting who will do each inspection, how it is done, and what the acceptance criteria are. In short, an ITP is a proactive quality control strategy to ensure each phase of construction meets the required standards. It serves two main purposes: (a) to confirm that the contractor's in-process controls are effective, and (b) to verify that incoming materials and completed work pass specified acceptance criteria.

**When Are ITPs Required?**
ITPs are required whenever the project or applicable standards call for documented verification of quality. Key triggers include:
*   **Standards and Quality Systems:** ISO 9001 (AS/NZS ISO 9001) requires documented procedures for controlling processes and verifying outputs. Construction standards (e.g. AS 3600 for concrete, AS/NZS 5131 for steel, AS 3798 for earthworks, AS 2159 for piling, etc.) specify technical criteria (compressive strengths, dimensional tolerances, test methods) that must be tested or inspected. In many projects the QMS and specifications explicitly call for ITPs to cover all required tests. For example, AS/NZS 5131 (structural steel) mandates weld inspection; Main Roads WA's steelwork spec even requires the contractor to submit an ITP for weld testing in accordance with AS/NZS 5131. Similarly, AS 1379 and AS 3600 require concrete slump and cylinder tests; an ITP will schedule those tests and record their results.
*   **Contract Specifications:** Project contracts almost always include quality clauses. Major road and bridge specifications (e.g. RMS/Austroads specifications) often list mandatory hold/witness points and require an ITP or Quality Plan. For instance, NSW government GC21 "Quality Management" clauses instruct contractors to prepare a Quality Management Plan and Inspection and Test Plans covering the works. The NSW Government Quality Management Guidelines explicitly require contractors to "Submit Inspection and Test Plans (plus any associated checklists) for specified activities ... at least 14 days prior to work" and to "incorporate the listed Hold and Witness points". Many state road authorities similarly identify critical operations (e.g. weld fabrication, concrete pours, specialized surfacing) in their specifications and require a pre-approved ITP for those works. As one example, Northern Territory roadworks specs require an ITP demonstrating compliance for Polymer-Modified Bitumen production and testing.
*   **Typical Civil Activities:** In practice, ITPs are usually required for major or safety‐critical operations. Common examples include concrete works (formwork, reinforcement placement, pouring and curing, including slump and strength tests), steel fabrication and erection (welds, bolt torque, dimensional checks), pavements and earthworks (layer thickness, density and compaction testing per AS 1289/AS 1141), drainage and pipeline installation (pipe alignment, joint testing), piling and foundations (borehole inspection, load tests), and electrical or mechanical installations (functional tests). If a scope item like a large concrete pour or crane lift is in the contract, the ITP must cover it with the appropriate inspections. For example, before a concrete pour the ITP will list a slump test with its required range; for a heavy bridge lift the ITP will include a pre-lift check of rigging as a hold point. (If unsure, one should consult the project specification and standards: if either sets specific testing or hold-point requirements for the activity, an ITP entry is needed.)
*   **Hold and Witness Points:** Contracts define Hold points (mandatory pauses) and Witness points (optional inspections) at critical stages. By definition, work cannot proceed past a hold point without the principal's or supervisor's approval. Whenever the specification or contract contains hold/witness points for a work item, the contractor's ITP must reflect them. In the ITP each hold point is explicitly flagged (often with an "H" in a column) and requires an inspector's signature before continuing. Witness points (marked "W") indicate the client or engineer may attend for inspection, but work may continue if they choose not to. NATSPEC notes that all such verification procedures are documented in the contract Inspection and Test Plan. In summary, any activity with a specified hold or witness trigger must have a corresponding entry in the ITP table.

**Structure and Content of an ITP (Context for your reasoning - you are NOT building the ITP itself):**
A well-structured ITP is usually organized as a table or checklist covering each inspection/test step. It typically includes:
*   **Scope of Work and Task Breakdown:** Defines the scope covered (e.g. "Bridge pier concrete pour – pours C1–C5") and breaks work into distinct activities/inspection points (e.g. "Formwork erected", "Rebar tied").
*   **Inspection/Test Methods and Criteria:** Specifies how inspection/test is done (e.g. AS 1012 test method, visual check, NDT), frequency, and acceptance criteria (numeric values, standards limits, written out in full).
*   **Acceptance Criteria and Records:** Clear pass/fail criteria. Columns for actual measurement/result, acceptance checkbox/signature. Certifications/test reports attached/referenced. Failed inspections trigger Non-Conformance Reports (NCRs).
*   **Responsibilities and Sign-offs:** Identifies who performs/reviews each inspection/test (e.g. "Contractor QC inspector", "Third-party NDT inspector"). Columns for inspector's signature/initials/date, and approving authority's sign-off.
*   **Hold, Witness, and Review Points:** Columns (H, W, R) for Hold (approval required to proceed), Witness (client may attend), and Review points. All contractual H/W points must be in the ITP.

MANDATORY PQP ALIGNMENT:
- Treat the PQP as authoritative. If the PQP declares an ITP (by code/title), ensure that the WBS contains corresponding work packages that accommodate that scope.
- When mapping, use simple keyword/topic alignment between ITP titles and work package names/descriptions.
- If a declared ITP clearly corresponds to deliverable work, set itp_required = true for the relevant work packages and cite the ITP code/title in itp_reasoning.

For each **lowest-level WBS work package**, you must perform a two-part analysis:

1.  **`itp_reasoning` (Provide Detailed Explanation):**
    *   Based on the work package's `name`, `description`, `reasoning`, `source_references`, any identified `applicable_specifications`, and information from the cached project documents, provide an **exceptionally detailed, expansive, and verbose explanation** of *why an ITP is likely required OR why it is likely NOT required*. This reasoning is a critical output and should be substantial in length.
    *   Your reasoning should explicitly and thoroughly consider the principles of when ITPs are typically mandated or beneficial in Australian civil construction (as detailed in "When Are ITPs Required?" above). Specifically, analyze and discuss in detail:
        *   **Nature of Work:** Is it physical construction, installation, fabrication, manufacturing, or critical testing? Elaborate on how the nature of this specific work package aligns (or doesn't align) with activities typically requiring ITPs.
        *   **Specification Requirements:** Do `applicable_specifications` or other project documents mention tests, inspections, or verifications necessitating an ITP for this work package? Cite specific clauses or requirements if found, or explain their absence.
        *   **Hold and Witness Points:** Does the work type typically involve contractual Hold/Witness Points? Do documents indicate such points for this scope?
        *   **Quality Management Systems:** Is the work covered by a QMS (e.g., AS/NZS ISO 9001) implying formal process control via ITPs?
        *   **Risk and Criticality:** Is it a major, critical, or high-risk activity where formal quality verification is essential?
        *   **Exclusions:** Conversely, is the work purely administrative (e.g., 'Project Meetings'), planning ('Develop Schedule'), high-level reporting ('Monthly Progress Report'), or a design task? Such items generally do *not* require their own ITP.

2.  **`itp_required` (Boolean Flag):**
    *   Based on your `itp_reasoning`, set this field to `true` (boolean) if an ITP is likely required.
    *   Set to `false` (boolean) if an ITP is likely *not* required.

OUTPUT REQUIREMENTS:
- You MUST return ONLY a single, valid JSON list of objects.
- Each object in the list should represent a lowest-level WBS work package that you have analyzed and MUST have the following format:
  `{ "_id": "the_uuid_of_the_work_package", "itp_reasoning": "Your detailed reasoning text here...", "itp_required": true }`
  (Ensure `itp_required` is a boolean `true` or `false`).
- Only include work packages in the list for which you have performed this analysis.
- Do NOT include explanatory text, greetings, apologies, or markdown formatting (like ```json ... ```) around the JSON list.
"""

POPULATE_QUALITY_REQUIREMENTS_SYSTEM_PROMPT = """You are an expert Civil Engineering Quality Assurance (QA) Analyst. Your critical task is to extract specific, measurable, and testable quality requirements for Work Breakdown Structure (WBS) work packages from provided project documentation. You will be given the WBS structure (JSON) and access to cached project documents.

CONTEXT ON WORK BREAKDOWN STRUCTURES (WBS):
- **What is a WBS?** A Work Breakdown Structure (WBS) is a hierarchical decomposition of the total scope of work to be carried out by a project team. It organizes the project's deliverables into progressively smaller, manageable components.
- **Work Packages:** Your focus will be on the **Work Packages**, which are the lowest-level elements of the WBS. These represent specific, tangible deliverables or work components. Understanding the precise scope of each work package (from its name, description, reasoning, identified applicable specifications, and source references in the WBS JSON) is crucial for finding its specific quality requirements.

UNDERSTANDING SPECIFIC QUALITY REQUIREMENTS:
- These are explicit criteria that define acceptable standards for materials, workmanship, performance, and finished construction for a *specific* work package.
- They are derived directly from the project's contractual documents, technical specifications (e.g., MRTS, TfNSW, AS, which may be listed in the `applicable_specifications` field of the work package), drawings, and other referenced standards.
- Requirements should be **specific, measurable, achievable, relevant, and time-bound (SMART)** where possible, or at least clearly testable/verifiable.
- Examples: "Concrete compressive strength to achieve minimum 32 MPa at 28 days (AS 1012.9)", "Dimensional tolerance for precast panel length: +/- 5mm", "All structural steel welds to be inspected per AS/NZS 1554.1, SP category", "Compaction of subgrade to achieve 98% RDD (AS 1289.5.1.1)", "Bitumen spray rate to be 1.2 L/m² +/- 0.1 L/m²".
- These requirements form the objective basis for accepting or rejecting the completed work associated with the work package. An Inspection and Test Plan (ITP), if required for the work package, would be built around verifying these specific quality requirements.

YOUR TASK:
1.  **Analyze Work Package Context:** For each lowest-level WBS work package, carefully review its `name`, `description`, `reasoning`, `source_references`, and any `applicable_specifications` you (or a previous step) have identified. This context will guide your search within the documents.

2.  **Deep Dive into Documents:**
    *   Thoroughly search the cached project documents, focusing on the sections indicated by `source_references` and the content of any `applicable_specifications`.
    *   Look for precise statements that define quality criteria, material properties, performance standards, tolerances, testing methods, and acceptance limits relevant to THAT SPECIFIC work package.

3.  **Extract and Format Requirements:**
    *   Populate the `specific_quality_requirements` field with a LIST of STRINGS.
    *   Each string in the list should represent a distinct quality requirement.
    *   **Crucially, where possible, include VERBATIM QUOTES or close paraphrases of the requirement directly from the source document.** Also, try to include the source reference (e.g., clause number, spec ID, drawing note) if readily available alongside the quote.
    *   Example of preferred format for each string:
        *   `"Min concrete strength 32 MPa at 28 days (Source: Spec S100, Cl 4.2.1)"`
        *   `"'All fill material shall be compacted to a dry density ratio of not less than 95% Standard Compaction.' (Source: Contract Doc A, Section 5.3.b)"`
        *   `"Surface finish for exposed concrete to be Class F2 as per AS 3610 (Source: Drawing C-001, Note 5)"`
    *   If a requirement is very long, summarize it concisely while retaining its core testable/measurable aspect and its source.
    *   If multiple distinct requirements are found for a single work package, list each as a separate string.

4.  **Handling No Specific Requirements:**
    *   If, after thorough searching, no *specific* quality requirements (beyond a general reference to a specification already listed in `applicable_specifications`) can be found for a work package, the `specific_quality_requirements` list should be left empty `[]`. Do not invent requirements or repeat general specification titles.

OUTPUT REQUIREMENTS:
- You MUST return ONLY a single, valid JSON list of objects.
- Each object in the list should represent a lowest-level WBS work package that you have analyzed and MUST have the following format:
  `{ "_id": "the_uuid_of_the_work_package", "specific_quality_requirements": ["Requirement 1 (Source: ...)", "Requirement 2 (Source: ...)", ...] }`
  (Ensure `specific_quality_requirements` is a list of strings, which can be empty).
- Only include work packages in the list for which you have performed this analysis (i.e., attempted to find specific quality requirements).
- Do NOT include explanatory text, greetings, apologies, or markdown formatting (like ```json ... ```) around the JSON list.
"""

CONTEXTUAL_KNOWLEDGE_USAGE_PROMPT = """
CRITICAL CONTEXT: HOW TO USE GENERAL CONTEXTUAL KNOWLEDGE FOR CIVIL ENGINEERING WBS DEVELOPMENT

You are being provided with a comprehensive master cache containing both project-specific documents AND general civil engineering contextual knowledge (MRTS standards, Australian Standards, and other technical specifications). This contextual knowledge is EXTREMELY VALUABLE for your WBS development task, and you must understand exactly how to leverage it effectively.

WHY GENERAL CONTEXTUAL KNOWLEDGE IS PROVIDED:
The general contextual knowledge (technical standards, specifications, and engineering references) serves several critical purposes in WBS development:

1. **UNDERSTANDING WORK ITEM CATEGORIZATION**: Civil engineering projects follow established patterns of work organization. Standards like MRTS (Main Roads Technical Standards) define how work is typically categorized and structured. Understanding these patterns helps you create a WBS that aligns with industry practice and makes practical sense for project execution.

2. **INFERRING REQUIRED WORK ITEMS**: Even when project documents don't explicitly list every work item, the contextual knowledge helps you infer what must be included. For example:
   - If a project involves concrete structures, you can infer from concrete standards (AS 3600, MRTS70) that work items for formwork, reinforcement, pouring, curing, and testing are likely needed
   - If earthworks are mentioned, standards like MRTS04 indicate typical sub-items: excavation, compaction, moisture control, testing, etc.
   - Bridge projects following MRTS62 (Substructure) patterns suggest foundation, pier, abutment work packages

3. **UNDERSTANDING CONSTRUCTION SEQUENCING AND DEPENDENCIES**: Standards reveal the logical sequence of construction activities, helping you structure the WBS hierarchy appropriately. This knowledge helps you understand:
   - Which work items naturally group together
   - What the typical breakdown levels should be
   - How detailed the work packages should be for practical execution

4. **ENSURING COMPLETENESS (100% RULE)**: The contextual knowledge helps ensure your WBS captures all necessary work by providing insight into:
   - Standard work items that are commonly required but might not be explicitly mentioned in project documents
   - Quality control and testing activities that are mandatory but may be implied rather than stated
   - Ancillary work items that support main construction activities

5. **PRACTICAL WORK PACKAGE DEFINITION**: Standards help you understand appropriate work package granularity:
   - What constitutes a manageable unit of work
   - How work is typically organized for contractor execution
   - What level of detail is practical for scheduling and cost control

HOW TO USE THE CONTEXTUAL KNOWLEDGE EFFECTIVELY:

**STEP 1 - PATTERN RECOGNITION**: 
When analyzing your project documents, use the contextual knowledge to recognize standard work patterns. If your project mentions "bridge construction," the MRTS bridge standards help you understand the typical work breakdown structure for such projects.

**STEP 2 - GAP ANALYSIS**: 
Compare what's explicitly stated in project documents against what the contextual knowledge indicates should be included. If project documents mention "concrete deck slab" but don't detail the work involved, concrete standards help you infer required work items like formwork, reinforcement placement, concrete supply, pouring, finishing, curing, and testing.

**STEP 3 - WORK ITEM INFERENCE**: 
Use contextual knowledge to infer work items that must exist even if not explicitly detailed. For example:
   - If documents mention "earthworks," infer from MRTS04 that this likely includes: site preparation, excavation, material testing, compaction, moisture control, quality testing
   - If "pavement construction" is mentioned, infer from pavement standards the typical layers and processes involved

**STEP 4 - HIERARCHICAL STRUCTURING**: 
Use the way standards organize work to inform your WBS hierarchy. Standards typically group related activities logically, which can guide your section/task/work package organization.

**STEP 5 - COMPLETENESS VERIFICATION**: 
After developing your initial WBS from project documents, cross-check against contextual knowledge to ensure you haven't missed standard work items that would typically be required for the type of project you're analyzing.

CRITICAL PRINCIPLES FOR USING CONTEXTUAL KNOWLEDGE:

1. **PROJECT DOCUMENTS ARE PRIMARY**: Always start with and prioritize the actual project documents. The contextual knowledge supplements and enhances understanding but doesn't override explicit project requirements.

2. **INFERENCE IS LEGITIMATE**: It's appropriate and expected to infer work items from contextual knowledge when they're clearly implied by the project scope, even if not explicitly listed in project documents.

3. **MAINTAIN INDUSTRY ALIGNMENT**: Use contextual knowledge to ensure your WBS aligns with standard industry practices and terminology, making it practical for actual project execution.

4. **BALANCE DETAIL WITH PRACTICALITY**: Use contextual knowledge to understand appropriate levels of detail - detailed enough to be useful, but not so granular as to be impractical.

5. **CONSIDER MANDATORY ACTIVITIES**: Standards often define mandatory activities (testing, quality control, safety procedures) that must be included in the WBS even if not explicitly mentioned in project documents.

EXAMPLES OF EFFECTIVE CONTEXTUAL KNOWLEDGE USAGE:

**Example 1 - Concrete Work**: 
Project documents mention "concrete bridge deck." Contextual knowledge from MRTS70 (Concrete) and AS 3600 indicates this work typically involves:
- Formwork design and installation
- Reinforcement supply and placement  
- Concrete supply and placement
- Finishing and curing
- Testing (slump, compressive strength)
- Quality control inspections
Even if project documents don't detail these, they can be legitimately inferred as necessary work packages.

**Example 2 - Earthworks**:
Project documents mention "cut and fill operations." MRTS04 (General Earthworks) contextual knowledge indicates typical work items:
- Site survey and setting out
- Topsoil stripping and stockpiling
- Excavation of unsuitable material
- Import/placement of suitable fill
- Compaction and moisture control
- Density testing and quality verification
These can be inferred as necessary work packages even if not explicitly detailed.

**Example 3 - Pavement Construction**:
Project documents mention "flexible pavement construction." Pavement standards indicate typical layers and processes:
- Subgrade preparation and testing
- Sub-base layer construction
- Base course construction  
- Prime coat application
- Asphalt surfacing
- Line marking and finishing
These work packages can be inferred from contextual knowledge.

WHAT NOT TO DO WITH CONTEXTUAL KNOWLEDGE:

1. **Don't Override Project Scope**: Never add work items that are clearly outside the defined project scope, even if they're mentioned in standards.

2. **Don't Add Irrelevant Standards**: Don't reference standards that aren't applicable to the actual work being performed.

3. **Don't Over-Complicate**: Don't use contextual knowledge to make the WBS unnecessarily complex or detailed beyond practical needs.

4. **Don't Ignore Project Specifics**: Don't force standard patterns if the project has unique requirements that call for a different approach.

INTEGRATION WITH YOUR WBS DEVELOPMENT PROCESS:

When developing your WBS structure and reasoning:

1. **In your thinking_process**: Explicitly discuss how you're using contextual knowledge to understand work patterns and infer necessary work items.

2. **In your reasoning for each element**: Reference how contextual knowledge supports the inclusion and structuring of work items, especially when inferring items not explicitly detailed in project documents.

3. **In your source_references**: When appropriate, note that work items are inferred from industry standards and contextual knowledge, while still primarily referencing project documents.

This contextual knowledge is provided to make you a more effective WBS architect, capable of creating comprehensive, industry-aligned, and practically useful work breakdown structures that capture the full scope of work required for successful project execution.
""" from langgraph.graph import StateGraph, START, END
from typing import List, Dict, Any, Optional, Annotated
from typing_extensions import TypedDict
# from shared_libraries.types import State  # Remove this line
from tools.azure_tools import generate_sas_token, extract_document_content, AZURE_STORAGE_CONTAINER_DOCUMENTS
from tools.db_tools import (
    fetch_document_ids_by_project,
    fetch_uploaded_document_info,
    save_extracted_document_content,
    save_document_metadata,
)
import logging
from operator import add
from langgraph.constants import Send
from langchain_core.runnables import RunnableConfig
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import BaseModel, Field
import os

logger = logging.getLogger(__name__)

class ExtractionState(TypedDict):  # Change to standalone TypedDict
    project_id: str
    document_ids: Optional[List[str]]
    document_metadata: Optional[List[Dict[str, Any]]]
    txt_project_documents: Annotated[List[Dict[str, Any]], add]
    failed_documents: Annotated[List[Dict[str, Any]], add]
    error: Optional[str]
    done: bool

class InputState(TypedDict):
    project_id: str

class OutputState(TypedDict):
    txt_project_documents: List[Dict[str, Any]]
    failed_documents: List[Dict[str, Any]]
    error: Optional[str]
    done: bool

def fetch_document_ids_node(state: ExtractionState) -> ExtractionState:
    # Prefer documents linked to document assets if present; otherwise fallback to all documents
    # For extraction we still operate on documents table; assets layer is orthogonal
    ids = fetch_document_ids_by_project.invoke({"project_id": state["project_id"]})
    return {**state, "document_ids": ids}

def initialize_extraction_node(state: ExtractionState) -> ExtractionState:
    logger.info(f"🚀 Initializing extraction for {len(state['document_ids'])} documents")
    return {**state, "txt_project_documents": [], "failed_documents": [], "done": False}

def fetch_uploaded_document_details_node(state: ExtractionState) -> ExtractionState:
    ids = state.get("document_ids") or []
    if not ids:
        return {**state, "document_metadata": []}
    metadata = fetch_uploaded_document_info.invoke({"document_ids": ids})
    return {**state, "document_metadata": metadata}

def route_to_parallel_extraction(state: ExtractionState) -> List[Send]:
    docs = state.get("document_metadata") or []
    if not docs:
        return []
    return [Send("extract_single_document", {"single_doc": doc}) for doc in docs]

def extract_single_document(state: Dict[str, Any], config: RunnableConfig) -> Dict[str, Any]:
    doc = state["single_doc"]
    try:
        blob_path = doc["blob_url"].split(f"/{AZURE_STORAGE_CONTAINER_DOCUMENTS}/", 1)[1]
        sas_url = generate_sas_token.run(blob_path, config=config)
        result = extract_document_content.run({"blob_url": sas_url, "file_name": doc["file_name"]}, config=config)
        if result["status"] == "success":
            save_extracted_document_content.invoke({"document_id": doc["id"], "content": result["content"]})
            return {"txt_project_documents": [{"id": doc["id"], "file_name": doc["file_name"], "content": result["content"]}]}
        else:
            logger.error(f"Extraction failed for {doc['file_name']}: {result.get('error', 'Unknown error')}")
            return {"failed_documents": [{"uuid": doc["id"], "file_name": doc["file_name"], "error": result.get('error', 'Unknown error')}]}
    except Exception as e:
        logger.error(f"Error processing {doc['file_name']}: {e}")
        return {"failed_documents": [{"uuid": doc["id"], "file_name": doc["file_name"], "error": str(e)}]}

def finalize_extraction_node(state: ExtractionState) -> ExtractionState:
    # Return only the field we actually want to change to avoid re-adding list fields via the 'add' reducer
    return {"done": True}

# --- New: LLM-based metadata extraction and asset upsert ---

class DocumentMetadata(BaseModel):
    name: Optional[str] = Field(default=None, description="Human-readable document name/title extracted from the document")
    document_number: Optional[str] = Field(default=None, description="Formal document number or code, if present")
    revision: Optional[str] = Field(default=None, description="Revision identifier, e.g., A/B/C or 1/2/3 or R0/R1")
    type: Optional[str] = Field(default=None, description="High-level document type classification (e.g., Specification, Drawing, Plan)")
    category: Optional[str] = Field(default=None, description="Primary project document category for UI grouping (e.g., Specifications, Drawings, Management Plans)")

    class Config:
        extra = "forbid"


_meta_llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL") or "gemini-2.5-flash",
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    include_thoughts=False,
    thinking_budget=-1,
)


def extract_document_metadata_node(state: ExtractionState) -> ExtractionState:
    documents = state.get("txt_project_documents") or []
    if not documents:
        return state

    structured_llm = _meta_llm.with_structured_output(DocumentMetadata, method="json_mode")

    for doc in documents:
        raw_content: str = doc.get("content", "") or ""
        file_name: str = doc.get("file_name", "") or ""
        document_id: str = doc.get("id", "")

        try:
            # Strict prompt: no fallbacks, no truncation, null if unsure
            prompt = (
                "Extract core metadata from the following project document.\n"
                "Return ONLY a JSON object with exactly these fields: name, document_number, revision, type, category.\n"
                "- name: human-readable document name/title from header/front-matter or content. If unsure, null.\n"
                "- document_number: formal controlled identifier (alphanumeric with separators). If absent, null.\n"
                "- revision: short identifier like A/B/C or 1/2/3 or R0/R1. If absent, null.\n"
                "- type: high-level type, choose the best fit.\n"
                "- category: choose ONE from this list for UI grouping: [\n"
                "  'Management Plans', 'Specifications', 'Drawings', 'Procedures', 'Forms & Templates', 'Records & Checklists',\n"
                "  'Reports', 'Contracts & Commercial', 'Scope & Requirements', 'Standards & References',\n"
                "  'Schedules & Programs', 'Quality', 'Safety', 'Environmental', 'Other'\n"
                "]\n"
                "Do not infer from file name as a fallback. Base all fields ONLY on the document content. If a field cannot be reliably determined, set it to null.\n\n"
                f"File Name: {file_name}\n\n"
                "Content:\n"
                f"{raw_content}"
            )

            parsed: DocumentMetadata = structured_llm.invoke(prompt)
            meta = parsed.dict()

            # Persist directly to documents.document_details as { document_metadata: { ... } }
            ok = save_document_metadata.invoke({
                "document_id": document_id,
                "document_metadata": {
                    "name": meta.get("name"),
                    "document_number": meta.get("document_number"),
                    "revision": meta.get("revision"),
                    "type": meta.get("type"),
                    "category": meta.get("category"),
                },
            })
            if not ok:
                raise RuntimeError("Database write for document metadata failed")
        except Exception as e:
            # Fail fast: stop the graph on first failure
            logger.error(f"Metadata extraction failed for doc {document_id}: {e}")
            raise

    # Do not return full state to avoid list re-aggregation (which would duplicate documents)
    # This node performs DB writes only and doesn't mutate graph state
    return {}

builder = StateGraph(ExtractionState, input=InputState, output=OutputState)
builder.add_node("fetch_document_ids", fetch_document_ids_node)
builder.add_node("initialize", initialize_extraction_node)
builder.add_node("fetch_uploaded_document_details", fetch_uploaded_document_details_node)
builder.add_node("extract_single_document", extract_single_document)
builder.add_node("extract_metadata", extract_document_metadata_node)
builder.add_node("finalize", finalize_extraction_node)
builder.add_edge(START, "fetch_document_ids")
builder.add_edge("fetch_document_ids", "initialize")
builder.add_edge("initialize", "fetch_uploaded_document_details")
builder.add_conditional_edges("fetch_uploaded_document_details", route_to_parallel_extraction)
builder.add_edge("extract_single_document", "extract_metadata")
builder.add_edge("extract_metadata", "finalize")
builder.add_edge("finalize", END)

from langgraph.checkpoint.sqlite import SqliteSaver

document_extraction_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string("checkpoints.db"))

# Description: Subgraph for Azure PDF content extraction with parallel processing. Traceable nodes show inputs/outputs in Studio.
# Sub-agent of orchestrator. Tools handle Azure/DB for modularity.
# Source: Ported from agents_v7 document_content_extraction.py. import os
import uuid
import json
import logging
from typing import Dict, Any, List, Optional
from typing_extensions import TypedDict

from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_google_genai import ChatGoogleGenerativeAI

from tools.db_tools import upsert_asset
from prompt_library.itp_prompt_v2 import CONSOLIDATED_ITP_PROMPT_V2

logger = logging.getLogger(__name__)

# LLM configured similar to WBS extraction agent
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)


# -----------------------------
# Pydantic models (structured output)
# -----------------------------
class ItpItem(BaseModel):
    """Defines an item in the ITP adjacency list (section headers or inspection rows)."""
    thinking: Optional[str] = Field(None, description="Internal reasoning placeholder; MUST be null.")
    id: str = Field(..., description="Simple identifier for this item (e.g., 'section_1', 'item_1_1').")
    parentId: Optional[str] = Field(None, description="Parent simple ID (null for top-level sections).")
    item_no: str = Field(..., description="Hierarchical number (e.g., '1.0', '1.1').")

    # Section-specific
    section_name: Optional[str] = Field(None, description="Only for section headers (parentId is null).")

    # Inspection row-specific
    inspection_test_point: Optional[str] = Field(None, alias="Inspection/Test Point")
    acceptance_criteria: Optional[str] = Field(None, alias="Acceptance Criteria")
    specification_clause: Optional[str] = Field(None, alias="Specification Clause")
    inspection_test_method: Optional[str] = Field(None, alias="Inspection/Test Method")
    frequency: Optional[str] = Field(None, alias="Frequency")
    responsibility: Optional[str] = Field(None, alias="Responsibility")
    hold_witness_point: Optional[str] = Field(None, alias="Hold/Witness Point")


class ItpResponse(BaseModel):
    items: List[ItpItem]


def convert_simple_ids_to_uuids(itp_items: List[ItpItem]) -> List[ItpItem]:
    """Convert simple IDs to UUIDs while preserving parent relationships."""
    id_mapping: Dict[str, str] = {}
    for item in itp_items:
        id_mapping[item.id] = str(uuid.uuid4())

    updated: List[ItpItem] = []
    for item in itp_items:
        item_dict = item.model_dump(by_alias=True)
        item_dict["id"] = id_mapping[item.id]
        if item.parentId:
            item_dict["parentId"] = id_mapping.get(item.parentId)
        updated.append(ItpItem(**item_dict))
    return updated


def get_relevant_wbs_nodes(target_node: Dict[str, Any], wbs_data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Return the target WBS node and its parent chain from root to target."""
    node_map = {node["id"]: node for node in (wbs_data.get("nodes") or [])}
    chain: List[Dict[str, Any]] = []
    current = target_node
    while current:
        chain.append(current)
        parent_id = current.get("parentId")
        current = node_map.get(parent_id) if parent_id else None
    return chain[::-1]


# -----------------------------
# LangGraph state
# -----------------------------
class ItpGenerationState(TypedDict):
    project_id: str
    # Inputs from orchestrator if available
    wbs_structure: Optional[Dict[str, Any]]
    # Derived/working fields
    wbs_nodes_for_itp: List[Dict[str, Any]]
    generated_itps: List[Dict[str, Any]]  # { wbs_node_id, wbs_node_title, itp_items, asset_id }
    error: Optional[str]


# -----------------------------
# Nodes
# -----------------------------
def ensure_wbs_from_state(state: ItpGenerationState) -> ItpGenerationState:
    """Require WBS to be provided by the orchestrator state. No DB fallback."""
    if state.get("wbs_structure") and isinstance(state["wbs_structure"], dict) and state["wbs_structure"].get("nodes"):
        return state
    return {**state, "error": "Missing WBS in state. Upstream WBS extraction must populate wbs_structure."}


def identify_itp_targets(state: ItpGenerationState) -> ItpGenerationState:
    """Identify WBS leaf nodes marked as requiring ITP generation."""
    if state.get("error"):
        return state
    wbs = state.get("wbs_structure") or {}
    nodes = wbs.get("nodes") or []
    targets = [n for n in nodes if n.get("itp_required") is True and n.get("is_leaf_node") is True]
    return {**state, "wbs_nodes_for_itp": targets}


def generate_itps(state: ItpGenerationState) -> ItpGenerationState:
    if state.get("error"):
        return state

    wbs = state.get("wbs_structure") or {}
    targets = state.get("wbs_nodes_for_itp") or []
    if not targets:
        return {**state, "generated_itps": []}

    generated: List[Dict[str, Any]] = []

    for i, node in enumerate(targets):
        node_title = node.get("name", "Untitled")
        try:
            # Build concise context similar to V2 workflow
            chain = get_relevant_wbs_nodes(node, wbs)
            context_payload = {
                "target_wbs_node": {"id": node.get("id"), "name": node_title},
                "wbs_hierarchy_chain": chain,  # root -> ... -> target
            }

            system_instructions = (
                CONSOLIDATED_ITP_PROMPT_V2
                + "\n\n"
                + "--- CONTEXT ---\n"
                + json.dumps(context_payload, ensure_ascii=False)
                + "\n--- END CONTEXT ---\n"
            )

            structured_llm = llm.with_structured_output(ItpResponse, method="json_mode")
            response: ItpResponse = structured_llm.invoke(system_instructions)

            if not response or not response.items:
                logger.warning("No structured items returned for node '%s'", node_title)
                continue

            # Convert IDs to UUIDs for storage
            items_with_uuids = convert_simple_ids_to_uuids(response.items)
            items_dict = [item.model_dump(by_alias=True) for item in items_with_uuids]

            # Persist each ITP as its own asset
            asset_name = f"ITP - {node_title}"
            try:
                asset_id = upsert_asset.invoke({
                    "project_id": state["project_id"],
                    "asset_type": "plan",
                    "name": asset_name,
                    "document_number": None,
                    "content": {
                        "title": asset_name,
                        "items": items_dict,
                        "wbs_node_id": node.get("id"),
                    },
                    "metadata": {
                        "plan_type": "itp_template",
                        "category": "itp",
                        "tags": ["itp", "template", "auto-generated"],
                        "wbs_node_id": node.get("id"),
                        "wbs_node_title": node_title,
                    },
                })
            except Exception as save_err:
                logger.error("Failed to save ITP asset for '%s': %s", node_title, save_err)
                asset_id = None

            generated.append({
                "wbs_node_id": node.get("id"),
                "wbs_node_title": node_title,
                "itp_items": items_dict,
                "asset_id": asset_id,
            })

        except Exception as e:
            logger.error("Error generating ITP for '%s': %s", node_title, e, exc_info=True)
            continue

    return {**state, "generated_itps": generated}


# -----------------------------
# Graph definition
# -----------------------------
builder = StateGraph(ItpGenerationState)
builder.add_node("ensure_wbs", ensure_wbs_from_state)
builder.add_node("identify_itp_targets", identify_itp_targets)
builder.add_node("generate_itps", generate_itps)

builder.add_edge(START, "ensure_wbs")
builder.add_edge("ensure_wbs", "identify_itp_targets")
builder.add_edge("identify_itp_targets", "generate_itps")
builder.add_edge("generate_itps", END)

# Enable lightweight checkpointing (consistent with WBS agent)
_memory = SqliteSaver.from_conn_string("checkpoints.db")
itp_generation_graph = builder.compile(checkpointer=_memory)

# Description: Subgraph for generating ITP templates from WBS leaf nodes requiring ITPs.
# Pattern mirrors wbs_extraction_agent: typed state, structured output, DB access via tools, and asset persistence.import os
import json
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional, Literal
from typing_extensions import TypedDict
from pydantic import BaseModel
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_google_genai import ChatGoogleGenerativeAI
from prompt_library.lbs_extraction_prompt import LBS_EXTRACTION_PROMPT
from tools.db_tools import save_lbs_and_mapping_to_project, upsert_asset

llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL_2"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)

# --- Unified Output Schema (single, all-encompassing card model) ---
class Level(BaseModel):
    order: int
    name: str


class LotCardAllEncompassing(BaseModel):
    # Core identity
    lot_card_id: str

    # Location hierarchy (flattened)
    location_levels: List[Level]
    location_full_path: str
    location_depth: int

    # Work hierarchy (flattened)
    work_levels: List[Level]
    work_full_path: str
    work_depth: int

    # Work package (flattened)
    work_package_id: str
    work_package_name: str
    work_package_itp_required: Optional[bool] = None
    work_package_itp_reference: Optional[str] = None

    # Lot metadata (flattened)
    lot_number: str
    sequence_order: int
    status: Literal["potential", "in_progress", "completed"] = "potential"


class LotCardsOutput(BaseModel):
    """Container model for a variable-length list of lot cards.

    This ensures structured output returns a single JSON object with a
    top-level key `lot_cards` whose value is an array of
    `LotCardAllEncompassing` items.
    """

    lot_cards: List[LotCardAllEncompassing]


class LbsExtractionState(TypedDict):
    project_id: str
    # Inputs
    txt_project_documents: List[Dict[str, Any]]
    # Derived
    wbs_structure: Optional[Dict[str, Any]]
    mapping_content: Optional[Dict[str, Any]]
    error: Optional[str]


class InputState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]
    wbs_structure: Optional[Dict[str, Any]]


class OutputState(TypedDict):
    mapping_content: Optional[Dict[str, Any]]


def _coerce_json_obj(value: Any) -> Optional[Dict[str, Any]]:
    if value is None:
        return None
    if isinstance(value, dict):
        return value
    if isinstance(value, str):
        try:
            parsed = json.loads(value)
            return parsed if isinstance(parsed, dict) else None
        except Exception:
            return None
    return None


def generate_lot_cards_node(state: LbsExtractionState) -> LbsExtractionState:
    """Generate a comprehensive set of lot cards using the unified schema."""
    # Use the raw document text directly from state, without additional formatting
    documents_text = "\n\n".join([
        str(d.get("content", "")) for d in (state.get("txt_project_documents") or [])
    ])
    wbs_json = json.dumps(state.get("wbs_structure") or {}, ensure_ascii=False)

    prompt = (
        f"{LBS_EXTRACTION_PROMPT}\n\n"
        f"DOCUMENTS_TEXT:\n{documents_text}\n\n"
        f"WBS_JSON:\n{wbs_json}\n\n"
        "Return strictly valid JSON with a top-level key 'lot_cards' as a non-empty array of multiple items. "
        "Cover all applicable LEAF WBS packages across identified locations. "
        "Populate both 'location_levels' and 'work_levels' (no empty arrays). "
        "Use a deterministic 'lot_number' series and 'sequence_order' starting at 1 and incrementing. "
        "Do NOT include any extra top-level keys besides 'lot_cards' (no 'title', 'summary', 'notes', 'metadata'). "
        "Do NOT append any descriptive or summary objects inside 'lot_cards'. EVERY element in 'lot_cards' MUST strictly "
        "conform to the unified Lot Card schema and include ALL mandatory fields, especially 'work_package_id' and "
        "'work_package_name'."
    )

    # Prefer json_mode for larger structured payloads
    structured_llm = llm.with_structured_output(
        LotCardsOutput,
        method="function_calling",
        strict=True,
    )
    structured = structured_llm.invoke(prompt)

    if hasattr(structured, "model_dump"):
        result: Dict[str, Any] = structured.model_dump()
    elif hasattr(structured, "dict"):
        result = structured.dict()
    else:
        result = structured  # assume already a dict-like

    return {**state, "mapping_content": result}


def _append_uuid_to_cards_node(state: LbsExtractionState) -> LbsExtractionState:
    mapping = state.get("mapping_content") or {}
    cards: List[Dict[str, Any]] = mapping.get("lot_cards") if isinstance(mapping, dict) else []
    if not cards:
        raise RuntimeError("UUID append: missing lot cards; aborting")

    new_cards: List[Dict[str, Any]] = []
    for c in cards:
        cc = {**c, "uuid": str(uuid.uuid4())}
        new_cards.append(cc)

    return {**state, "mapping_content": {**mapping, "lot_cards": new_cards}}


def store_cards_node(state: LbsExtractionState) -> LbsExtractionState:
    """Very simple persistence: dump the LLM response as-is."""
    mapping = state.get("mapping_content")
    try:
        mapping_json = json.dumps(mapping)
    except Exception:
        mapping_json = json.dumps({})

    save_lbs_and_mapping_to_project.invoke({
        "project_id": state["project_id"],
        "lbs_json": json.dumps(None),  # Pass JSON string 'null' to satisfy validator
        "mapping_json": mapping_json,
    })

    # Also upsert as an asset named "lotcards" for easy retrieval
    try:
        try:
            source_document_ids = [d.get("id") for d in (state.get("txt_project_documents") or []) if d.get("id")]
        except Exception:
            source_document_ids = []
        upsert_asset.invoke({
            "project_id": state["project_id"],
            "asset_type": "plan",
            "name": "lotcards",
            "document_number": None,
            "content": mapping,
            "metadata": {
                "plan_type": "lot_cards",
                "category": "mapping",
                "tags": ["lotcards", "lots"],
                "source_document_ids": source_document_ids,
            },
        })
    except Exception:
        # Surface failure to write the asset
        raise

    return state


def build_lot_mapping_node(state: LbsExtractionState) -> LbsExtractionState:
    # Deprecated: all mapping and card construction is delegated to the LLM now.
    raise NotImplementedError("build_lot_mapping_node has been removed in favor of direct LLM card generation")


builder = StateGraph(LbsExtractionState, input=InputState, output=OutputState)
builder.add_node("generate_cards", generate_lot_cards_node)
builder.add_node("append_uuid_to_cards", lambda s: _append_uuid_to_cards_node(s))
builder.add_node("store_cards", store_cards_node)

builder.add_edge(START, "generate_cards")
builder.add_edge("generate_cards", "append_uuid_to_cards")
builder.add_edge("append_uuid_to_cards", "store_cards")
builder.add_edge("store_cards", END)

lbs_extraction_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string('checkpoints.db'))

# Description: Subgraph for extracting Location Breakdown Structure (LBS) in v9 style with WBS-aware prompt and DB tools.

import os
import json
from typing_extensions import TypedDict
from typing import List, Dict, Any, Optional, Literal
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
from prompt_library.pqp_prompt import PROMPT as PQP_PROMPT
from prompt_library.emp_prompt import PROMPT as EMP_PROMPT
from prompt_library.ohsmp_prompt import PROMPT as OHSMP_PROMPT
from prompt_library.tmp_prompt import PROMPT as TMP_PROMPT
from prompt_library.construction_program_prompt import PROMPT as CONSTR_PROMPT
from tools.db_tools import (
    fetch_all_project_documents,
    save_management_plan_to_project,
    upsert_asset,
)
from prompt_library.qse_system import QSE_SYSTEM_NODES, QSE_SYSTEM_SUMMARY

llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL_2"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)

VERBOSITY_DIRECTIVE = (
    "\n\nCRITICAL VERBOSITY & DETAIL REQUIREMENTS:"  # make outputs significantly longer and richer
    "\n- Be exhaustive and highly detailed across ALL sections. Target 2–4x the content of a concise plan."
    "\n- Expand every major section into multiple rich 'block' entries (paragraphs, lists, tables) wherever helpful."
    "\n- Prefer specificity grounded in PROJECT DOCUMENTS. Where absent, provide best-practice defaults and explicitly mark them as 'Assumption'."
    "\n- For each relevant topic include: purpose, scope, definitions, roles & responsibilities, step-by-step procedures, required resources, tools, competency requirements, references/standards/codes, acceptance criteria, inspections & test checkpoints, records & evidence to retain."
    "\n- Provide matrices/tables where suitable: RACI, risk register, environmental aspects & impacts, OHS hazard → control mapping (use hierarchy of controls), KPIs with targets and measurement methods, communication/escalation pathways, training/induction requirements."
    "\n- Provide explicit checklists (as list items) for field execution and verification."
    "\n- For traffic management (TMP), include delineation, staging, detours, signage schedules, hold points, emergency procedures."
    "\n- For construction program, include milestone breakdowns, dependencies, critical path notes, calendar/constraints, resource loading commentary (histograms described in text), contingency buffers, and reporting cadence."
    "\n- Use tables via headers/rows for registers and matrices; use items for enumerations; use paragraphs for narrative guidance."
    "\n- Structure deeply: create multiple levels of 'section' nodes with clear titles and populate each with several detailed 'block' nodes."
    "\n- Maintain the strict adjacency list schema; do NOT include children arrays; only use parentId relationships."
)

ENGINEERING_IMPLEMENTATION_DIRECTIVE = (
    "\n\nENGINEERING IMPLEMENTATION DIRECTIVE (Authoritative, Practitioner Grade):"
    "\n- You are acting as a senior civil engineer producing FINAL, IMPLEMENTABLE management plans for immediate use on the project."
    "\n- The plans must be tailored to the PROJECT DOCUMENTS (drawings, specifications, schedules, contract conditions). Use them as primary sources; use QSE context only to fill gaps."
    "\n- Where exact values or project-specific rules exist in documents, APPLY them. If absent, state 'Assumption' and provide best-practice value."
    "\n- Include fully workable method statements: detailed sequence, responsibilities, resources, plant & equipment, production rates, hold/witness points, acceptance criteria, inspection & test checkpoints, records to be captured, and close-out requirements."
    "\n- Provide explicit, field-usable checklists and registers (tables) for: risks (with controls following hierarchy), environmental aspects/impacts with mitigations and monitoring, OHS hazards with controls, training/competency, permits/approvals, calibration & equipment checks, materials conformance, NCR/CAR escalation, and communication/escalation pathways."
    "\n- For Quality (PQP): align each activity with ITP references and acceptance criteria; include document control, revisioning, and evidence capture requirements."
    "\n- For Environmental (EMP): include monitoring methods, frequencies, locations, limits/thresholds, reporting lines, and contingency actions when thresholds are exceeded."
    "\n- For OHSMP: include SWMS/JSA linkage, isolation/LOTO, access/egress, emergency response, inductions, toolbox talk content prompts, and PPE matrices."
    "\n- For TMP: include staging, delineation, detours, signage schedules, VMS messages, traffic counts assumptions, speed management, access management, emergency/incident procedures, and hold points for switchovers."
    "\n- For Construction Program: include milestones, dependencies, critical path commentary, calendars/constraints, weather allowances, resource loading commentary, buffers, reporting cadence, and progress measurement."
    "\n- Reference sources in the 'label' field within blocks when possible (e.g., 'Ref: SPEC 03300 §3.2; Drawing C-101; Contract Cl.14'). Use 'url' if a precise link exists; otherwise leave null."
    "\n- IDs must be unique strings. Titles must be clear and professional."
    "\n- Output must be sufficiently detailed that a competent engineer/site team could execute without further drafting."
)

QSE_REFERENCING_DIRECTIVE = (
    "\n\nQSE REFERENCING RULES (Corporate System Citations):"
    "\n- When you rely on corporate QSE documents (policy, procedure, register, form, template), cite their exact 'document_number' from QSE_SYSTEM_NODES."
    "\n- Provide inline citations near relevant paragraphs like (Ref: QSE-7.5-PROC-01) or (Ref: QSE-8.1-TEMP-ITP)."
    "\n- Include a final <h2 id=\"sec-references\">References</h2> section listing all cited QSE items as a bulleted list:"
    "\n  • Format: <li><b>QSE-7.5-PROC-01</b> — Procedure for Control of Documented Information (path: /qse/corp-documentation)</li>"
    "\n- Do NOT invent document numbers. Only use values that exist in QSE_SYSTEM_NODES."
)

NUMBERING_AND_ARTIFACTS_DIRECTIVE = (
    "\n\nPRESENTATION & OUTPUT RULES (Numbered Sections + Contents):"
    "\n- INCLUDE a 'Contents' section at the very top that lists all major sections with anchor links."
    "\n  • Render as an unordered list under an <h2>Contents</h2> heading."
    "\n  • Each list item must link to the corresponding section via #anchors (e.g., <a href=\"#sec-1\">1. General</a>)."
    "\n- USE DECIMAL SECTION NUMBERING for headings:"
    "\n  • <h1> for the document title (unnumbered)."
    "\n  • <h2> for top-level sections numbered 1, 2, 3, ... (e.g., '1. General')."
    "\n  • <h3> for subsections numbered 1.1, 1.2, 2.1, ... according to their parent section."
    "\n- Add stable id attributes to each numbered heading to support anchor links (e.g., <h2 id=\"sec-1\">1. General</h2>, <h3 id=\"sec-1-1\">1.1 Purpose</h3>)."
    "\n- Strip any numbering found in source documents BEFORE applying the new consistent numbering scheme."
    "\n- Do NOT include page numbers or pagination artifacts."
    "\n- Only include actual plan content. Exclude redundant layout metadata from source documents."
)

PLAN_TO_COLUMN = {
    "pqp": "pqp_plan_json",
    "emp": "emp_plan_json",
    "ohsmp": "ohsmp_plan_json",
    "tmp": "tmp_plan_json",
    # "construction_program": "construction_program_json",  # temporarily disabled
}

PLAN_TO_PROMPT = {
    "pqp": PQP_PROMPT,
    "emp": EMP_PROMPT,
    "ohsmp": OHSMP_PROMPT,
    "tmp": TMP_PROMPT,
    # "construction_program": CONSTR_PROMPT,  # temporarily disabled
}

def _default_category_and_tags_for_plan_type(plan_type: str) -> Dict[str, Any]:
    mapping: Dict[str, Dict[str, Any]] = {
        "pqp": {"category": "management_plan", "tags": ["plan", "pqp", "quality"]},
        "emp": {"category": "management_plan", "tags": ["plan", "emp", "environment"]},
        "ohsmp": {"category": "management_plan", "tags": ["plan", "ohs", "safety"]},
        "tmp": {"category": "management_plan", "tags": ["plan", "tmp", "traffic"]},
        "construction_program": {"category": "program", "tags": ["plan", "program", "schedule"]},
    }
    return mapping.get(plan_type, {"category": "plan", "tags": ["plan", plan_type]})

class PlanHtml(BaseModel):
    """Simple model for HTML plan body content.

    We store the HTML body only (no <html>, <head>, or <body> tags) to render directly in the app editor/viewer.
    """
    html: str

class PlanGenerationState(TypedDict):
    project_id: str
    plan_type: str
    txt_project_documents: List[Dict[str, Any]]
    plan_html: Optional[str]
    error: Optional[str]

class InputState(TypedDict):
    project_id: str
    # plan_type is optional for the single-plan graph; if omitted, default to 'pqp'
    plan_type: Optional[str]

class OutputState(TypedDict):
    plan_html: Optional[str]

def fetch_docs_node(state: PlanGenerationState) -> PlanGenerationState:
    # Fetch ALL project documents (not only those with extracted content)
    docs = fetch_all_project_documents.invoke(state["project_id"])
    return {**state, "txt_project_documents": docs}

def generate_plan_node(state: PlanGenerationState) -> PlanGenerationState:
    docs_text = "\n\n".join([f"Document: {d['file_name']} (ID: {d['id']})\n{d['content']}" for d in state["txt_project_documents"]])
    plan_type = state.get("plan_type") or "pqp"
    system_prompt = PLAN_TO_PROMPT[plan_type]
    qse_context = json.dumps(QSE_SYSTEM_NODES)
    qse_summary = QSE_SYSTEM_SUMMARY
    output_instructions = (
        "\n\nOUTPUT FORMAT (STRICT): Return JSON with a single field 'html' that contains the FINAL HTML BODY ONLY. "
        "Do NOT include <html>, <head>, or <body> tags. Use semantic HTML elements (h1-h3, p, ul/ol, table, a). "
        "Render a complete, professional management plan suitable for direct display and TinyMCE editing."
    )
    prompt = (
        f"{system_prompt}\n\n"
        f"QSE SYSTEM SUMMARY:\n{qse_summary}\n\n"
        f"QSE SYSTEM REFERENCE (adjacency list):\n{qse_context}\n\n"
        f"PROJECT DOCUMENTS:\n{docs_text}"
        f"{VERBOSITY_DIRECTIVE}"
        f"{ENGINEERING_IMPLEMENTATION_DIRECTIVE}"
        f"{QSE_REFERENCING_DIRECTIVE}"
        f"{NUMBERING_AND_ARTIFACTS_DIRECTIVE}"
        f"{output_instructions}"
    )
    structured_llm = llm.with_structured_output(PlanHtml, method="json_mode")
    response = structured_llm.invoke(prompt)
    html = response.html or ""
    return {**state, "plan_html": html, "plan_type": plan_type}

def save_plan_node(state: PlanGenerationState) -> PlanGenerationState:
    # Save to legacy projects column for backward compatibility (store as JSON object with html)
    column = PLAN_TO_COLUMN[state["plan_type"]]
    try:
        save_management_plan_to_project.invoke({
            "project_id": state["project_id"],
            "column_name": column,
            "plan_json": json.dumps({"html": state.get("plan_html") or ""}),
        })
    except Exception:
        pass
    # Upsert to assets as a plan asset with HTML payload
    plan_type = state.get("plan_type") or "plan"
    title = f"{plan_type.upper()} Plan"
    source_document_ids = [d.get("id") for d in state.get("txt_project_documents", []) if d.get("id")]
    defaults = _default_category_and_tags_for_plan_type(plan_type)
    metadata: Dict[str, Any] = {
        "plan_type": plan_type,
        "category": defaults.get("category"),
        "tags": defaults.get("tags"),
        "source_document_ids": source_document_ids,
    }
    upsert_asset.invoke({
        "project_id": state["project_id"],
        "asset_type": "plan",
        "name": title,
        "document_number": None,
        "content": {"html": state.get("plan_html") or ""},
        "metadata": metadata,
    })
    return state

builder = StateGraph(PlanGenerationState, input=InputState, output=OutputState)
builder.add_node("fetch_docs", fetch_docs_node)
builder.add_node("generate_plan", generate_plan_node)
builder.add_node("save_plan", save_plan_node)

builder.add_edge(START, "fetch_docs")
builder.add_edge("fetch_docs", "generate_plan")
builder.add_edge("generate_plan", "save_plan")
builder.add_edge("save_plan", END)

plan_generation_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string("checkpoints.db"))

# Description: Subgraph that generates a project management plan JSON using Gemini structured output and saves it to projects table.

# --------------------
# Sequencer: generate ALL plans in sequence (separate LLM call per plan)
# --------------------

class SeqState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]
    # results: append minimal summaries per plan
    results: List[Dict[str, Any]]

class SeqInput(TypedDict):
    project_id: str

class SeqOutput(TypedDict):
    results: List[Dict[str, Any]]

def seq_fetch_docs_node(state: SeqState) -> SeqState:
    # Fetch ALL project documents for sequencing
    docs = fetch_all_project_documents.invoke(state["project_id"])
    return {**state, "txt_project_documents": docs, "results": []}

def _gen_and_save(plan_type: str, state: SeqState) -> Dict[str, Any]:
    docs_text = "\n\n".join([f"Document: {d['file_name']} (ID: {d['id']})\n{d['content']}" for d in state["txt_project_documents"]])
    system_prompt = PLAN_TO_PROMPT[plan_type]
    qse_context = json.dumps(QSE_SYSTEM_NODES)
    output_instructions = (
        "\n\nOUTPUT FORMAT (STRICT): Return JSON with a single field 'html' that contains the FINAL HTML BODY ONLY. "
        "Do NOT include <html>, <head>, or <body> tags. Use semantic HTML elements (h1-h3, p, ul/ol, table, a)."
    )
    prompt = (
        f"{system_prompt}\n\n"
        f"QSE SYSTEM REFERENCE (adjacency list):\n{qse_context}\n\n"
        f"PROJECT DOCUMENTS:\n{docs_text}"
        f"{VERBOSITY_DIRECTIVE}"
        f"{ENGINEERING_IMPLEMENTATION_DIRECTIVE}"
        f"{NUMBERING_AND_ARTIFACTS_DIRECTIVE}"
        f"{output_instructions}"
    )
    structured_llm = llm.with_structured_output(PlanHtml, method="json_mode")
    response = structured_llm.invoke(prompt)
    html = response.html
    # Save to legacy column as JSON object containing html
    save_management_plan_to_project.invoke({
        "project_id": state["project_id"],
        "column_name": PLAN_TO_COLUMN[plan_type],
        "plan_json": json.dumps({"html": html}),
    })
    # Mirror to assets table
    defaults = _default_category_and_tags_for_plan_type(plan_type)
    source_document_ids = [d.get("id") for d in state.get("txt_project_documents", []) if d.get("id")]
    upsert_asset.invoke({
        "project_id": state["project_id"],
        "asset_type": "plan",
        "name": f"{plan_type.upper()} Plan",
        "document_number": None,
        "content": {"html": html},
        "metadata": {
            "plan_type": plan_type,
            "category": defaults.get("category"),
            "tags": defaults.get("tags"),
            "source_document_ids": source_document_ids,
        },
    })
    return {"plan_type": plan_type, "title": f"{plan_type.upper()} Plan"}

def seq_generate_pqp_node(state: SeqState) -> SeqState:
    summary = _gen_and_save("pqp", state)
    return {**state, "results": [*state["results"], summary]}

def seq_generate_emp_node(state: SeqState) -> SeqState:
    summary = _gen_and_save("emp", state)
    return {**state, "results": [*state["results"], summary]}

def seq_generate_ohsmp_node(state: SeqState) -> SeqState:
    summary = _gen_and_save("ohsmp", state)
    return {**state, "results": [*state["results"], summary]}

def seq_generate_tmp_node(state: SeqState) -> SeqState:
    summary = _gen_and_save("tmp", state)
    return {**state, "results": [*state["results"], summary]}

def seq_generate_constr_node(state: SeqState) -> SeqState:
    # Temporarily skip construction program generation
    return state

seq_builder = StateGraph(SeqState, input=SeqInput, output=SeqOutput)
seq_builder.add_node("fetch_docs", seq_fetch_docs_node)
seq_builder.add_node("gen_pqp", seq_generate_pqp_node)
seq_builder.add_node("gen_emp", seq_generate_emp_node)
seq_builder.add_node("gen_ohsmp", seq_generate_ohsmp_node)
seq_builder.add_node("gen_tmp", seq_generate_tmp_node)
seq_builder.add_node("gen_constr", seq_generate_constr_node)

seq_builder.add_edge(START, "fetch_docs")
seq_builder.add_edge("fetch_docs", "gen_pqp")
seq_builder.add_edge("gen_pqp", "gen_emp")
seq_builder.add_edge("gen_emp", "gen_ohsmp")
seq_builder.add_edge("gen_ohsmp", "gen_tmp")
seq_builder.add_edge("gen_tmp", END)

plan_generation_sequencer_graph = seq_builder.compile(checkpointer=SqliteSaver.from_conn_string("checkpoints.db"))

# Convenience wrappers to run with only project_id
def run_single_plan(project_id: str, plan_type: Optional[str] = None) -> Dict[str, Any]:
    """Run the single-plan graph using only a project_id (plan_type optional, defaults to 'pqp')."""
    inputs: InputState = {"project_id": project_id, "plan_type": plan_type}
    return plan_generation_graph.invoke(inputs)

def run_all_plans(project_id: str) -> Dict[str, Any]:
    """Run the sequencer to generate all plans using only a project_id."""
    seq_inputs: SeqInput = {"project_id": project_id}
    return plan_generation_sequencer_graph.invoke(seq_inputs)




import os
import json
from typing import Any, Dict, List, Optional
from typing_extensions import TypedDict
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_google_genai import ChatGoogleGenerativeAI
from tools.db_tools import upsert_asset
from prompt_library.project_details_prompt import PROJECT_DETAILS_SYSTEM_PROMPT
import langsmith


# ===== LLM Configuration =====
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL_2"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)


# ===== Schema =====


class ProjectDetails(BaseModel):
    project_name: Optional[str] = None
    project_address: Optional[str] = Field(default=None, description="Physical address of the works/site")
    html: Optional[str] = Field(default=None, description="HTML content for the project details body")


# ===== State =====
class ProjectDetailsExtractionState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]
    project_details: Optional[Dict[str, Any]]
    error: Optional[str]


class InputState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]


class OutputState(TypedDict):
    project_details: Optional[Dict[str, Any]]
    error: Optional[str]


@langsmith.traceable
def generate_and_store_project_details_node(state: ProjectDetailsExtractionState) -> ProjectDetailsExtractionState:
    docs = state.get("txt_project_documents") or []
    combined_content = "\n\n".join([
        f"Document: {d.get('file_name','Unknown')} (ID: {d.get('id','')})\n{d.get('content','')}" for d in docs
    ])

    # Fail fast: require non-empty documents and content
    if not docs or not combined_content.strip():
        raise ValueError("Project Details extraction requires extracted document content; none available")

    # Avoid KeyError from braces in schema snippet by not using str.format on the whole prompt
    # Strengthen formatting hints to ensure table borders and consistent heading sizes
    formatting_hint = (
        "\n\nNote: Ensure all tables include 1px solid #d1d5db borders on th/td with ~8px padding and vertical-align: top; "
        "the thead should have a subtle background (e.g., #f9fafb). Headings should use a consistent scale (h1≈1.5rem, "
        "h2≈1.25rem, h3≈1.125rem) with clear spacing.\n\n"
    )
    prompt = PROJECT_DETAILS_SYSTEM_PROMPT.replace("{document_content}", combined_content + formatting_hint)
    structured_llm = llm.with_structured_output(ProjectDetails, method="json_mode")
    response: ProjectDetails = structured_llm.invoke(prompt)
    content = response.dict()
    metadata = {
        "plan_type": "project_details",
        "category": "project",
        "tags": ["project", "details"],
    }

    asset_id = upsert_asset.invoke({
        "project_id": state["project_id"],
        "asset_type": "plan",
        "name": "Project Details",
        "content": content,
        "metadata": metadata,
        "document_number": None,
    })
    if not asset_id:
        raise RuntimeError("Failed to persist Project Details asset")

    return {**state, "project_details": content}


builder = StateGraph(ProjectDetailsExtractionState, input=InputState, output=OutputState)
builder.add_node("generate_and_store", generate_and_store_project_details_node)
builder.add_edge(START, "generate_and_store")
builder.add_edge("generate_and_store", END)

project_details_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string("checkpoints.db"))

# Description: Minimal subgraph that extracts consolidated project details from documents via a single LLM call
# and persists a 'Project Details' asset (asset_type='plan', metadata.plan_type='project_details').

import os
import json
import importlib.util
from typing import Any, Dict, List, Optional
from typing_extensions import TypedDict

from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_google_genai import ChatGoogleGenerativeAI

from tools.db_tools import upsert_qse_asset


def _qse_items_dir() -> str:
    here = os.path.dirname(__file__)
    return os.path.abspath(os.path.join(here, "..", "prompt_library", "QSE_items"))


def _load_item(filename: str) -> Dict[str, Any]:
    """Load a QSE item prompt module by filename and return dict with item_id, title, html."""
    directory = _qse_items_dir()
    fpath = os.path.join(directory, filename)
    spec = importlib.util.spec_from_file_location(f"qse_item_{os.path.splitext(filename)[0].replace('-', '_').replace('.', '_')}", fpath)
    if not spec or not spec.loader:
        raise RuntimeError(f"Unable to load QSE item: {filename}")
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)  # type: ignore[arg-type]
    item_id = getattr(module, "ITEM_ID", None)
    title = getattr(module, "TITLE", None)
    html = getattr(module, "HTML", None)
    if not isinstance(item_id, str) or not isinstance(title, str) or not isinstance(html, str):
        raise ValueError(f"Invalid QSE item module (missing ITEM_ID/TITLE/HTML): {filename}")
    return {"item_id": item_id, "title": title, "html": html}


llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.1,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1,
)


def _load_default_company_profile() -> Dict[str, Any]:
    """Load the example company profile JSON bundled with QSE items.
    Returns an empty dict if unavailable (agent will still run, but less tailored).
    """
    try:
        path = os.path.join(_qse_items_dir(), "QSE_company_profile.example.json")
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


DEFAULT_COMPANY_PROFILE: Dict[str, Any] = _load_default_company_profile()


STRICT_OUTPUT_RULES = (
    "\n\nSTRICT OUTPUT CONTRACT:"
    "\n- Return a SINGLE JSON object that conforms to the schema."
    "\n- Do not include extra commentary."
    "\n- The html must be complete, semantic HTML fragments for the DOCUMENT BODY ONLY (do not include <html> or <body> tags)."
    "\n- Preserve EXACT section titles and exemplar wording unless replacing bracketed placeholders (e.g., [Company Name])."
    "\n- Keep all body-level formatting: headings (h1–h6), paragraphs, lists, blockquotes, tables, bold/italic/underline, and inline links."
    "\n- Remove any React/TSX-specific syntax (e.g., className, onClick, JSX). Output clean HTML attributes only."
    "\n- Do NOT include page-level UI wrappers or decorations: no outer <section> blocks, layout containers, accordions/toggles, icons, colored panels, borders, or grid cards."
    "\n- Do NOT include document metadata panels that belong to the page chrome (e.g., 'Document ID:', 'Revision:', 'Effective Date:', 'Approver:' blocks) unless they are an explicit part of the canonical document body."
    "\n- Exclude any interactive elements or script-dependent behaviors."
)

PRESERVATION_RULES = (
    "\n\nPRESERVATION & TAILORING RULES:"
    "\n- Treat the provided exemplar as authoritative for structure, headings, and baseline wording."
    "\n- Substitute company-specific details from COMPANY_PROFILE where placeholders appear (e.g., [Company Name], [CEO Name])."
    "\n- If a detail is missing, leave the placeholder or use '—' (em dash) rather than inventing facts."
    "\n- Do NOT add new sections or rename existing ones."
    "\n- Maintain ISO 9001/14001/45001 conformance implied by the exemplar. It is already ISO compliant so that is why no modifications to the structure is allowed."
    "\n- When the exemplar contains page-level headers or metadata wrappers in addition to the internal document title, OUTPUT ONLY the internal document title and body content."
)


class QseDocument(BaseModel):
    title: str
    document_number: str
    revision: Optional[str] = None
    html: str = Field(description="HTML fragment representing ONLY the document body (no page wrappers, no metadata panels)")
    metadata: Optional[Dict[str, Any]] = None


class GenerationState(TypedDict):
    project_id: str
    company_profile: Dict[str, Any]
    target_docs: List[str]
    results: List[Dict[str, Any]]
    error: Optional[str]


class GenerationInput(TypedDict):
    project_id: str
    company_profile: Dict[str, Any]
    target_docs: Optional[List[str]]


class GenerationOutput(TypedDict):
    results: List[Dict[str, Any]]


def _compose_prompt(document_number: str, title: str, exemplar_html: str, company_profile: Dict[str, Any]) -> str:
    output_schema = (
        "\n\nOUTPUT SCHEMA (STRICT JSON): Return an object with keys:"
        "\n{"
        "\n  \"title\": string,"
        "\n  \"document_number\": string (must equal the requested document number),"
        "\n  \"revision\": string | null,"
        "\n  \"html\": string (complete semantic HTML for the document body),"
        "\n  \"metadata\": object | null"
        "\n}"
    )
    return (
        f"You are generating a corporate QSE document for publication in an IMS portal."
        f"\nTarget document: {document_number} — {title}"
        f"\n\nCOMPANY_PROFILE (JSON):\n{json.dumps(company_profile, ensure_ascii=False)}"
        f"\n\nEXEMPLAR (authoritative content extracted from a page; may include UI wrappers, metadata panels, or TSX classes):\n{exemplar_html}"
        f"\n\nIMPORTANT: The EXEMPLAR may contain page-level headings (e.g., clickable section headers), metadata grids (Document ID/Revision/etc.), icons, borders, and layout wrappers."
        f"\nYour output MUST contain ONLY the clean document body content suitable for direct rendering inside a page body container."
        f"{PRESERVATION_RULES}"
        f"{STRICT_OUTPUT_RULES}"
        f"{output_schema}"
    )


def _generate_and_save_loaded(item: Dict[str, Any], state: GenerationState) -> Dict[str, Any]:
    doc_id = item["item_id"]
    title = item["title"]
    exemplar_html = item["html"]
    company_profile: Dict[str, Any] = state.get("company_profile") or DEFAULT_COMPANY_PROFILE or {}
    prompt = _compose_prompt(doc_id, title, exemplar_html, company_profile)
    structured = llm.with_structured_output(QseDocument, method="json_mode")
    doc: QseDocument = structured.invoke(prompt)

    if doc.document_number != doc_id:
        doc = QseDocument(**{**doc.model_dump(), "document_number": doc_id})

    upsert_qse_asset.invoke(
        {
            "project_id": state["project_id"],
            "asset_type": "qse_doc",
            "name": f"{doc.document_number} - {doc.title}",
            "document_number": doc.document_number,
            "content": {"html": doc.html, "title": doc.title, "revision": doc.revision, "metadata": doc.metadata},
            "metadata": {
                "category": "qse",
                "document_number": doc.document_number,
                "title": doc.title,
            },
        }
    )

    return {"document_number": doc.document_number, "title": doc.title}


def init_node(state: GenerationState) -> GenerationState:
    # Ensure defaults when invoked without explicit inputs (e.g., via API runner)
    normalized: GenerationState = {**state}  # type: ignore[assignment]
    if not normalized.get("company_profile"):
        normalized["company_profile"] = DEFAULT_COMPANY_PROFILE or {}
    normalized["results"] = []
    return normalized


# -------- Hard-coded node definitions: one node per prompt file in QSE_items --------

def _maybe_skip(state: GenerationState, current_doc_id: str) -> bool:
    target = state.get("target_docs")
    return bool(target) and (current_doc_id not in target)


def _load_and_generate(filename: str, state: GenerationState) -> Optional[Dict[str, Any]]:
    item = _load_item(filename)
    if _maybe_skip(state, item["item_id"]):
        return None
    return _generate_and_save_loaded(item, state)


# List mirrors /app/agents_v9/prompt_library/QSE_items contents (static)
_FILES = [
    "corp-improvement__overview__0001.py",
    "corp-performance__overview__0001.py",
    "corp-leadership__overview__0001.py",
    "corp-planning__overview__0001.py",
    "corp-support__overview__0001.py",
    "corp-operation__overview__0001.py",
    "corporate-tier-1__ims-scope__0002__QSE-4.3-STMT-01.py",
    "corporate-tier-1__ims-manual__0001__QSE-1-MAN-01.py",
    "corp-risk-management__opportunity-register__0003__QSE-6.1-REG-02.py",
    "corp-risk-management__risk-register__0002__QSE-6.1-REG-01.py",
    "corp-risk-management__risk-procedure__0001__QSE-6.1-PROC-01.py",
    "corp-review__review-procedure__0001__QSE-9.3-PROC-01.py",
    "corp-policy-roles__qse-policy__0001__QSE-5.2-POL-01.py",
    "corp-policy-roles__roles-matrix__0002__QSE-5.3-REG-01.py",
    "corp-op-procedures-templates__construction-control__0016__QSE-8.1-PROC-05.py",
    "corp-op-procedures-templates__design-control__0017__QSE-8.1-PROC-06.py",
    "corp-op-procedures-templates__environmental-mgmt__0015__QSE-8.1-PROC-04.py",
    "corp-op-procedures-templates__procurement__0018__QSE-8.1-PROC-07.py",
    "corp-op-procedures-templates__whs-mgmt__0014__QSE-8.1-PROC-03.py",
    "corp-op-procedures-templates__incident-report__0012__QSE-8.1-PROC-02.py",
    "corp-op-procedures-templates__pqp-template__0002__QSE-8.1-TEMP-PQP.py",
    "corp-op-procedures-templates__proj-mgmt__0001__QSE-8.1-PROC-01.py",
    "corp-objectives__objectives-plan__0002__QSE-6.2-PLN-01.py",
    "corp-objectives__objectives-procedure__0001__QSE-6.2-PROC-01.py",
    "corp-ncr__ncr-procedure__0001__QSE-10.2-PROC-01.py",
    "corp-ncr__ncr-register__0002__QSE-10.2-REG-01.py",
    "corp-monitoring__monitoring-procedure__0001__QSE-9.1-PROC-01.py",
    "corp-legal__legal-procedure__0001__QSE-6.1-PROC-02.py",
    "corp-legal__legal-register__0002__QSE-6.1-REG-03.py",
    "corp-documentation__documentation-procedure__0001__QSE-7.5-PROC-01.py",
    "corp-documentation__master-register__0002__QSE-7.5-REG-01.py",
    "corp-continual-improvement__improvement-register__0002__QSE-10.3-REG-01.py",
    "corp-continual-improvement__improvement-procedure__0001__QSE-10.3-PROC-01.py",
    "corp-context__context-procedure__0001__QSE-4.1-PROC-01.py",
    "corp-context__issues-register__0002__QSE-4.1-REG-01.py",
    "corp-context__stakeholders-register__0003__QSE-4.2-REG-01.py",
    "corp-consultation__hsc-minutes__0002__QSE-5.4-FORM-01.py",
    "corp-consultation__consult-procedure__0001__QSE-5.4-PROC-01.py",
    "corp-competence__competence-procedure__0001__QSE-7.2-PROC-01.py",
    "corp-competence__training-matrix__0002__QSE-7.2-REG-01.py",
    "corp-communication__communication-matrix__0002__QSE-7.4-REG-01.py",
    "corp-communication__communication-procedure__0001__QSE-7.4-PROC-01.py",
    "corp-audit__audit-procedure__0001__QSE-9.2-PROC-01.py",
    "corp-audit__audit-schedule__0002__QSE-9.2-SCHED-01.py",
]


# Explicit node functions (hard-coded). Each loads its specific file and generates one asset.

def gen_corp_improvement__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-improvement__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_performance__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-performance__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_leadership__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-leadership__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_planning__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-planning__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_support__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-support__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_operation__overview__0001(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-operation__overview__0001.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corporate_tier_1__ims_scope__0002__QSE_4_3_STMT_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corporate-tier-1__ims-scope__0002__QSE-4.3-STMT-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corporate_tier_1__ims_manual__0001__QSE_1_MAN_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corporate-tier-1__ims-manual__0001__QSE-1-MAN-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_risk_management__opportunity_register__0003__QSE_6_1_REG_02(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-risk-management__opportunity-register__0003__QSE-6.1-REG-02.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_risk_management__risk_register__0002__QSE_6_1_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-risk-management__risk-register__0002__QSE-6.1-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_risk_management__risk_procedure__0001__QSE_6_1_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-risk-management__risk-procedure__0001__QSE-6.1-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_review__review_procedure__0001__QSE_9_3_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-review__review-procedure__0001__QSE-9.3-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_policy_roles__qse_policy__0001__QSE_5_2_POL_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-policy-roles__qse-policy__0001__QSE-5.2-POL-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_policy_roles__roles_matrix__0002__QSE_5_3_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-policy-roles__roles-matrix__0002__QSE-5.3-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__construction_control__0016__QSE_8_1_PROC_05(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__construction-control__0016__QSE-8.1-PROC-05.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__design_control__0017__QSE_8_1_PROC_06(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__design-control__0017__QSE-8.1-PROC-06.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__environmental_mgmt__0015__QSE_8_1_PROC_04(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__environmental-mgmt__0015__QSE-8.1-PROC-04.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__procurement__0018__QSE_8_1_PROC_07(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__procurement__0018__QSE-8.1-PROC-07.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__whs_mgmt__0014__QSE_8_1_PROC_03(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__whs-mgmt__0014__QSE-8.1-PROC-03.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__incident_report__0012__QSE_8_1_PROC_02(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__incident-report__0012__QSE-8.1-PROC-02.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__pqp_template__0002__QSE_8_1_TEMP_PQP(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__pqp-template__0002__QSE-8.1-TEMP-PQP.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_op_procedures_templates__proj_mgmt__0001__QSE_8_1_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-op-procedures-templates__proj-mgmt__0001__QSE-8.1-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_objectives__objectives_plan__0002__QSE_6_2_PLN_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-objectives__objectives-plan__0002__QSE-6.2-PLN-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_objectives__objectives_procedure__0001__QSE_6_2_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-objectives__objectives-procedure__0001__QSE-6.2-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_ncr__ncr_procedure__0001__QSE_10_2_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-ncr__ncr-procedure__0001__QSE-10.2-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_ncr__ncr_register__0002__QSE_10_2_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-ncr__ncr-register__0002__QSE-10.2-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_monitoring__monitoring_procedure__0001__QSE_9_1_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-monitoring__monitoring-procedure__0001__QSE-9.1-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_legal__legal_procedure__0001__QSE_6_1_PROC_02(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-legal__legal-procedure__0001__QSE-6.1-PROC-02.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_legal__legal_register__0002__QSE_6_1_REG_03(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-legal__legal-register__0002__QSE-6.1-REG-03.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_documentation__documentation_procedure__0001__QSE_7_5_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-documentation__documentation-procedure__0001__QSE-7.5-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_documentation__master_register__0002__QSE_7_5_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-documentation__master-register__0002__QSE-7.5-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_continual_improvement__improvement_register__0002__QSE_10_3_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-continual-improvement__improvement-register__0002__QSE-10.3-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_continual_improvement__improvement_procedure__0001__QSE_10_3_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-continual-improvement__improvement-procedure__0001__QSE-10.3-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_context__context_procedure__0001__QSE_4_1_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-context__context-procedure__0001__QSE-4.1-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_context__issues_register__0002__QSE_4_1_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-context__issues-register__0002__QSE-4.1-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_context__stakeholders_register__0003__QSE_4_2_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-context__stakeholders-register__0003__QSE-4.2-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_consultation__hsc_minutes__0002__QSE_5_4_FORM_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-consultation__hsc-minutes__0002__QSE-5.4-FORM-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_consultation__consult_procedure__0001__QSE_5_4_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-consultation__consult-procedure__0001__QSE-5.4-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_competence__competence_procedure__0001__QSE_7_2_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-competence__competence-procedure__0001__QSE-7.2-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_competence__training_matrix__0002__QSE_7_2_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-competence__training-matrix__0002__QSE-7.2-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_communication__communication_matrix__0002__QSE_7_4_REG_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-communication__communication-matrix__0002__QSE-7.4-REG-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_communication__communication_procedure__0001__QSE_7_4_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-communication__communication-procedure__0001__QSE-7.4-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_audit__audit_procedure__0001__QSE_9_2_PROC_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-audit__audit-procedure__0001__QSE-9.2-PROC-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


def gen_corp_audit__audit_schedule__0002__QSE_9_2_SCHED_01(state: GenerationState) -> GenerationState:
    res = _load_and_generate("corp-audit__audit-schedule__0002__QSE-9.2-SCHED-01.py", state)
    return {**state, "results": [*state["results"], res] if res else state["results"]}


# -------- Graph assembly (hard-coded sequence) --------

builder = StateGraph(GenerationState, input=GenerationInput, output=GenerationOutput)
builder.add_node("init", init_node)

builder.add_node("gen_corp_improvement__overview__0001", gen_corp_improvement__overview__0001)
builder.add_node("gen_corp_performance__overview__0001", gen_corp_performance__overview__0001)
builder.add_node("gen_corp_leadership__overview__0001", gen_corp_leadership__overview__0001)
builder.add_node("gen_corp_planning__overview__0001", gen_corp_planning__overview__0001)
builder.add_node("gen_corp_support__overview__0001", gen_corp_support__overview__0001)
builder.add_node("gen_corp_operation__overview__0001", gen_corp_operation__overview__0001)
builder.add_node("gen_corporate_tier_1__ims_scope__0002__QSE_4_3_STMT_01", gen_corporate_tier_1__ims_scope__0002__QSE_4_3_STMT_01)
builder.add_node("gen_corporate_tier_1__ims_manual__0001__QSE_1_MAN_01", gen_corporate_tier_1__ims_manual__0001__QSE_1_MAN_01)
builder.add_node("gen_corp_risk_management__opportunity_register__0003__QSE_6_1_REG_02", gen_corp_risk_management__opportunity_register__0003__QSE_6_1_REG_02)
builder.add_node("gen_corp_risk_management__risk_register__0002__QSE_6_1_REG_01", gen_corp_risk_management__risk_register__0002__QSE_6_1_REG_01)
builder.add_node("gen_corp_risk_management__risk_procedure__0001__QSE_6_1_PROC_01", gen_corp_risk_management__risk_procedure__0001__QSE_6_1_PROC_01)
builder.add_node("gen_corp_review__review_procedure__0001__QSE_9_3_PROC_01", gen_corp_review__review_procedure__0001__QSE_9_3_PROC_01)
builder.add_node("gen_corp_policy_roles__qse_policy__0001__QSE_5_2_POL_01", gen_corp_policy_roles__qse_policy__0001__QSE_5_2_POL_01)
builder.add_node("gen_corp_policy_roles__roles_matrix__0002__QSE_5_3_REG_01", gen_corp_policy_roles__roles_matrix__0002__QSE_5_3_REG_01)
builder.add_node("gen_corp_op_procedures_templates__construction_control__0016__QSE_8_1_PROC_05", gen_corp_op_procedures_templates__construction_control__0016__QSE_8_1_PROC_05)
builder.add_node("gen_corp_op_procedures_templates__design_control__0017__QSE_8_1_PROC_06", gen_corp_op_procedures_templates__design_control__0017__QSE_8_1_PROC_06)
builder.add_node("gen_corp_op_procedures_templates__environmental_mgmt__0015__QSE_8_1_PROC_04", gen_corp_op_procedures_templates__environmental_mgmt__0015__QSE_8_1_PROC_04)
builder.add_node("gen_corp_op_procedures_templates__procurement__0018__QSE_8_1_PROC_07", gen_corp_op_procedures_templates__procurement__0018__QSE_8_1_PROC_07)
builder.add_node("gen_corp_op_procedures_templates__whs_mgmt__0014__QSE_8_1_PROC_03", gen_corp_op_procedures_templates__whs_mgmt__0014__QSE_8_1_PROC_03)
builder.add_node("gen_corp_op_procedures_templates__incident_report__0012__QSE_8_1_PROC_02", gen_corp_op_procedures_templates__incident_report__0012__QSE_8_1_PROC_02)
builder.add_node("gen_corp_op_procedures_templates__pqp_template__0002__QSE_8_1_TEMP_PQP", gen_corp_op_procedures_templates__pqp_template__0002__QSE_8_1_TEMP_PQP)
builder.add_node("gen_corp_op_procedures_templates__proj_mgmt__0001__QSE_8_1_PROC_01", gen_corp_op_procedures_templates__proj_mgmt__0001__QSE_8_1_PROC_01)
builder.add_node("gen_corp_objectives__objectives_plan__0002__QSE_6_2_PLN_01", gen_corp_objectives__objectives_plan__0002__QSE_6_2_PLN_01)
builder.add_node("gen_corp_objectives__objectives_procedure__0001__QSE_6_2_PROC_01", gen_corp_objectives__objectives_procedure__0001__QSE_6_2_PROC_01)
builder.add_node("gen_corp_ncr__ncr_procedure__0001__QSE_10_2_PROC_01", gen_corp_ncr__ncr_procedure__0001__QSE_10_2_PROC_01)
builder.add_node("gen_corp_ncr__ncr_register__0002__QSE_10_2_REG_01", gen_corp_ncr__ncr_register__0002__QSE_10_2_REG_01)
builder.add_node("gen_corp_monitoring__monitoring_procedure__0001__QSE_9_1_PROC_01", gen_corp_monitoring__monitoring_procedure__0001__QSE_9_1_PROC_01)
builder.add_node("gen_corp_legal__legal_procedure__0001__QSE_6_1_PROC_02", gen_corp_legal__legal_procedure__0001__QSE_6_1_PROC_02)
builder.add_node("gen_corp_legal__legal_register__0002__QSE_6_1_REG_03", gen_corp_legal__legal_register__0002__QSE_6_1_REG_03)
builder.add_node("gen_corp_documentation__documentation_procedure__0001__QSE_7_5_PROC_01", gen_corp_documentation__documentation_procedure__0001__QSE_7_5_PROC_01)
builder.add_node("gen_corp_documentation__master_register__0002__QSE_7_5_REG_01", gen_corp_documentation__master_register__0002__QSE_7_5_REG_01)
builder.add_node("gen_corp_continual_improvement__improvement_register__0002__QSE_10_3_REG_01", gen_corp_continual_improvement__improvement_register__0002__QSE_10_3_REG_01)
builder.add_node("gen_corp_continual_improvement__improvement_procedure__0001__QSE_10_3_PROC_01", gen_corp_continual_improvement__improvement_procedure__0001__QSE_10_3_PROC_01)
builder.add_node("gen_corp_context__context_procedure__0001__QSE_4_1_PROC_01", gen_corp_context__context_procedure__0001__QSE_4_1_PROC_01)
builder.add_node("gen_corp_context__issues_register__0002__QSE_4_1_REG_01", gen_corp_context__issues_register__0002__QSE_4_1_REG_01)
builder.add_node("gen_corp_context__stakeholders_register__0003__QSE_4_2_REG_01", gen_corp_context__stakeholders_register__0003__QSE_4_2_REG_01)
builder.add_node("gen_corp_consultation__hsc_minutes__0002__QSE_5_4_FORM_01", gen_corp_consultation__hsc_minutes__0002__QSE_5_4_FORM_01)
builder.add_node("gen_corp_consultation__consult_procedure__0001__QSE_5_4_PROC_01", gen_corp_consultation__consult_procedure__0001__QSE_5_4_PROC_01)
builder.add_node("gen_corp_competence__competence_procedure__0001__QSE_7_2_PROC_01", gen_corp_competence__competence_procedure__0001__QSE_7_2_PROC_01)
builder.add_node("gen_corp_competence__training_matrix__0002__QSE_7_2_REG_01", gen_corp_competence__training_matrix__0002__QSE_7_2_REG_01)
builder.add_node("gen_corp_communication__communication_matrix__0002__QSE_7_4_REG_01", gen_corp_communication__communication_matrix__0002__QSE_7_4_REG_01)
builder.add_node("gen_corp_communication__communication_procedure__0001__QSE_7_4_PROC_01", gen_corp_communication__communication_procedure__0001__QSE_7_4_PROC_01)
builder.add_node("gen_corp_audit__audit_procedure__0001__QSE_9_2_PROC_01", gen_corp_audit__audit_procedure__0001__QSE_9_2_PROC_01)
builder.add_node("gen_corp_audit__audit_schedule__0002__QSE_9_2_SCHED_01", gen_corp_audit__audit_schedule__0002__QSE_9_2_SCHED_01)


# Linear edges
builder.add_edge(START, "init")
_sequence = [
    "gen_corp_improvement__overview__0001",
    "gen_corp_performance__overview__0001",
    "gen_corp_leadership__overview__0001",
    "gen_corp_planning__overview__0001",
    "gen_corp_support__overview__0001",
    "gen_corp_operation__overview__0001",
    "gen_corporate_tier_1__ims_scope__0002__QSE_4_3_STMT_01",
    "gen_corporate_tier_1__ims_manual__0001__QSE_1_MAN_01",
    "gen_corp_risk_management__opportunity_register__0003__QSE_6_1_REG_02",
    "gen_corp_risk_management__risk_register__0002__QSE_6_1_REG_01",
    "gen_corp_risk_management__risk_procedure__0001__QSE_6_1_PROC_01",
    "gen_corp_review__review_procedure__0001__QSE_9_3_PROC_01",
    "gen_corp_policy_roles__qse_policy__0001__QSE_5_2_POL_01",
    "gen_corp_policy_roles__roles_matrix__0002__QSE_5_3_REG_01",
    "gen_corp_op_procedures_templates__construction_control__0016__QSE_8_1_PROC_05",
    "gen_corp_op_procedures_templates__design_control__0017__QSE_8_1_PROC_06",
    "gen_corp_op_procedures_templates__environmental_mgmt__0015__QSE_8_1_PROC_04",
    "gen_corp_op_procedures_templates__procurement__0018__QSE_8_1_PROC_07",
    "gen_corp_op_procedures_templates__whs_mgmt__0014__QSE_8_1_PROC_03",
    "gen_corp_op_procedures_templates__incident_report__0012__QSE_8_1_PROC_02",
    "gen_corp_op_procedures_templates__pqp_template__0002__QSE_8_1_TEMP_PQP",
    "gen_corp_op_procedures_templates__proj_mgmt__0001__QSE_8_1_PROC_01",
    "gen_corp_objectives__objectives_plan__0002__QSE_6_2_PLN_01",
    "gen_corp_objectives__objectives_procedure__0001__QSE_6_2_PROC_01",
    "gen_corp_ncr__ncr_procedure__0001__QSE_10_2_PROC_01",
    "gen_corp_ncr__ncr_register__0002__QSE_10_2_REG_01",
    "gen_corp_monitoring__monitoring_procedure__0001__QSE_9_1_PROC_01",
    "gen_corp_legal__legal_procedure__0001__QSE_6_1_PROC_02",
    "gen_corp_legal__legal_register__0002__QSE_6_1_REG_03",
    "gen_corp_documentation__documentation_procedure__0001__QSE_7_5_PROC_01",
    "gen_corp_documentation__master_register__0002__QSE_7_5_REG_01",
    "gen_corp_continual_improvement__improvement_register__0002__QSE_10_3_REG_01",
    "gen_corp_continual_improvement__improvement_procedure__0001__QSE_10_3_PROC_01",
    "gen_corp_context__context_procedure__0001__QSE_4_1_PROC_01",
    "gen_corp_context__issues_register__0002__QSE_4_1_REG_01",
    "gen_corp_context__stakeholders_register__0003__QSE_4_2_REG_01",
    "gen_corp_consultation__hsc_minutes__0002__QSE_5_4_FORM_01",
    "gen_corp_consultation__consult_procedure__0001__QSE_5_4_PROC_01",
    "gen_corp_competence__competence_procedure__0001__QSE_7_2_PROC_01",
    "gen_corp_competence__training_matrix__0002__QSE_7_2_REG_01",
    "gen_corp_communication__communication_matrix__0002__QSE_7_4_REG_01",
    "gen_corp_communication__communication_procedure__0001__QSE_7_4_PROC_01",
    "gen_corp_audit__audit_procedure__0001__QSE_9_2_PROC_01",
    "gen_corp_audit__audit_schedule__0002__QSE_9_2_SCHED_01",
]

prev = "init"
for name in _sequence:
    builder.add_edge(prev, name)
    prev = name
builder.add_edge(prev, END)

qse_generation_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string("checkpoints.db"))


def run_qse_docs(project_id: str, company_profile: Dict[str, Any], target_docs: Optional[List[str]] = None) -> Dict[str, Any]:
    # If caller passes no/empty profile, fall back to the bundled example profile (hard-coded default)
    effective_profile: Dict[str, Any] = company_profile if (company_profile and len(company_profile) > 0) else DEFAULT_COMPANY_PROFILE
    inputs: GenerationInput = {"project_id": project_id, "company_profile": effective_profile, "target_docs": target_docs or []}
    return qse_generation_graph.invoke(inputs)


from langgraph.graph import StateGraph, START, END
from typing import List, Dict, Any, Optional, Annotated
from typing_extensions import TypedDict
from tools.db_tools import fetch_reference_documents, upsert_asset
from prompt_library.standards_extraction_prompt import STANDARDS_EXTRACTION_PROMPT
import logging
from operator import add
from langgraph.constants import Send
from pydantic import BaseModel, Field
import os
from langchain_google_genai import ChatGoogleGenerativeAI
# from ..orchestrator import OrchestratorState  # Remove this line

logger = logging.getLogger(__name__)

class ExtractedStandard(BaseModel):
    """Schema for individual extracted standard with database information"""
    standard_code: str = Field(description="Standard code as mentioned in document (e.g., 'AS 1379', 'ASTM C123', 'MRTS04')")
    uuid: Optional[str] = Field(default=None, description="UUID from reference database if standard is found")
    spec_name: Optional[str] = Field(default=None, description="Full name from reference database if standard is found")
    org_identifier: Optional[str] = Field(default=None, description="Organization identifier from reference database if standard is found")
    section_reference: Optional[str] = Field(default=None, description="Specific section or clause where referenced")
    context: Optional[str] = Field(default=None, description="Context of how this standard is referenced")
    found_in_database: bool = Field(description="Whether this standard was found in the reference database")
    document_ids: List[str] = Field(description="IDs of the documents where this standard was found")

class ExtractedStandards(BaseModel):
    """Schema for extracted standards response."""
    standards: List[ExtractedStandard] = Field(description="List of standards found with database information")

class StandardsState(TypedDict):  # Change to standalone TypedDict
    project_id: str
    txt_project_documents: List[Dict[str, Any]]
    reference_database: Optional[List[Dict[str, Any]]]
    standards_from_project_documents: List[Dict[str, Any]]
    error: Optional[str]
    done: bool

class InputState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]

class OutputState(TypedDict):
    standards_from_project_documents: List[Dict[str, Any]]
    error: Optional[str]
    done: bool

def fetch_reference_database_node(state: StandardsState) -> StandardsState:
    ref_db = fetch_reference_documents.invoke({})
    return {**state, "reference_database": ref_db}

def extract_standards_node(state: StandardsState) -> StandardsState:
    ref_db = state["reference_database"]
    txt_docs = [{k: v for k, v in doc.items() if k not in ['blob_url', 'project_id']} for doc in state["txt_project_documents"]]
    
    if not txt_docs:
        return {"standards_from_project_documents": [], "done": True, "error": None}
    
    ref_db_text = ""
    for ref in ref_db:
        ref_db_text += f"UUID: {ref['id']}, Spec ID: {ref['spec_id']}, Name: {ref['spec_name']}, Org: {ref['org_identifier']}\n"
    
    combined_content = "\n\n".join([f"Document: {doc['file_name']} (ID: {doc['id']})\n{doc['content']}" for doc in txt_docs])
    
    prompt = STANDARDS_EXTRACTION_PROMPT.format(
        reference_db_text=ref_db_text,
        document_content=combined_content
    )
    
    llm = ChatGoogleGenerativeAI(
        model=os.getenv("GEMINI_MODEL"),
        google_api_key=os.getenv("GOOGLE_API_KEY"),
        thinking_budget=-1,
        include_thoughts=False
    )
    structured_llm = llm.with_structured_output(ExtractedStandards, method="json_mode")
    
    try:
        parsed_response = structured_llm.invoke(prompt)
        
        if not parsed_response:
            return {"error": "No parsed response from LLM", "done": True}
        
        standards_list = [std.model_dump() for std in parsed_response.standards]
        # Save to assets as a plan-type asset 'Standards Register' with richer metadata
        try:
            source_document_ids = [doc.get('id') for doc in txt_docs if doc.get('id')]
            upsert_asset.invoke({
                "project_id": state["project_id"],
                "asset_type": "plan",
                "name": "Standards Register",
                "content": {
                    "title": "Standards Register",
                    "nodes": standards_list,
                    "summary": {
                        "total_references": len(standards_list),
                        "found_in_database": sum(1 for s in standards_list if s.get('found_in_database')),
                        "unique_codes": len({s.get('standard_code') for s in standards_list if s.get('standard_code')})
                    }
                },
                "metadata": {
                    "plan_type": "standards_register",
                    "category": "register",
                    "tags": ["standards", "register", "compliance", "references"],
                    "source_document_ids": source_document_ids,
                },
                "document_number": None,
            })
        except Exception:
            pass
        return {"standards_from_project_documents": standards_list, "done": True}
    except Exception as e:
        logger.error(f"Error extracting standards: {e}")
        return {"error": str(e), "done": True}

builder = StateGraph(StandardsState, input=InputState, output=OutputState)
builder.add_node("fetch_reference_database", fetch_reference_database_node)
builder.add_node("extract_standards", extract_standards_node)
builder.add_edge(START, "fetch_reference_database")
builder.add_edge("fetch_reference_database", "extract_standards")
builder.add_edge("extract_standards", END)

standards_extraction_graph = builder.compile()

# Description: Subgraph for extracting referenced standards with parallel per-document processing. Accepts txt_project_documents from input state. Returns results in state without DB writes.
# Sub-agent of orchestrator. Tools handle DB fetches for modularity.
# Source: Ported from agents_v7 extract_referenced_standards.py, adapted for v9 design with minimal DB interaction. import os
import json
import uuid
import logging
import time
from datetime import datetime
from typing_extensions import TypedDict
from typing import List, Dict, Any, Optional, Literal
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import BaseMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from tools.db_tools import fetch_reference_documents, upsert_asset, fetch_assets_by_type
from prompt_library.wbs_extraction_prompt import (
    INITIAL_STRUCTURE_GENERATION_PROMPT,
    POPULATE_DESCRIPTIONS_SYSTEM_PROMPT,
    POPULATE_SPECIFICATIONS_SYSTEM_PROMPT,
    POPULATE_ITP_INFO_SYSTEM_PROMPT,
    POPULATE_QUALITY_REQUIREMENTS_SYSTEM_PROMPT
)
from langgraph.checkpoint.sqlite import SqliteSaver
import langsmith

logger = logging.getLogger(__name__)

llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL"),
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0.2,
    max_output_tokens=65536,
    include_thoughts=False,
    thinking_budget=-1
)

class WbsNode(BaseModel):
    reasoning: Optional[str] = Field(default="", description="Brief reasoning")
    id: str = Field(description="Temporary ID")
    parentId: Optional[str] = Field(default=None)
    node_type: str
    name: str
    source_reference_uuids: List[str] = Field(default_factory=list, description="List of document UUIDs")
    source_reference_hints: List[str] = Field(default_factory=list, description="List of location hints")
    source_reference_quotes: List[Optional[str]] = Field(default_factory=list, description="List of quoted sections (verbatim, no truncation)")
    description: str = Field(default="")
    specification_reasoning: str = Field(default="")
    applicable_specifications: List[str] = Field(default_factory=list)
    applicable_specification_uuids: List[str] = Field(default_factory=list)
    advisory_specifications: List[str] = Field(default_factory=list)
    itp_reasoning: str = Field(default="")
    itp_required: bool = Field(default=False)
    specific_quality_requirements: List[str] = Field(default_factory=list)
    is_leaf_node: bool = Field(default=False)

class InitialWbsGenerationResponse(BaseModel):
    nodes: List[WbsNode]

class WbsExtractionState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]
    reference_database: Optional[List[Dict[str, Any]]]
    wbs_structure: Optional[Dict[str, Any]]
    error: Optional[str]
    # Full, unmodified PQP JSON (if available via assets)
    pqp_plan_json: Optional[Dict[str, Any]]

class InputState(TypedDict):
    project_id: str
    txt_project_documents: List[Dict[str, Any]]

class OutputState(TypedDict):
    wbs_structure: Optional[Dict[str, Any]]

class DescriptionUpdate(BaseModel):
    id: str
    description: str

class DescriptionUpdates(BaseModel):
    updates: List[DescriptionUpdate]

class SpecificationUpdate(BaseModel):
    id: str
    specification_reasoning: str
    applicable_specifications: List[str]
    applicable_specification_uuids: List[str]
    advisory_specifications: List[str]

class SpecificationUpdates(BaseModel):
    updates: List[SpecificationUpdate]

class ItpUpdate(BaseModel):
    id: str
    itp_reasoning: str
    itp_required: bool

class ItpUpdates(BaseModel):
    updates: List[ItpUpdate]

class QualityUpdate(BaseModel):
    id: str
    specific_quality_requirements: List[str]

class QualityUpdates(BaseModel):
    updates: List[QualityUpdate]

def fetch_reference_database_node(state: WbsExtractionState) -> WbsExtractionState:
    ref_db = fetch_reference_documents.invoke({})
    return {**state, "reference_database": ref_db}

def _coerce_json_obj(value: Any) -> Optional[Dict[str, Any]]:
    if value is None:
        return None
    if isinstance(value, dict):
        return value
    if isinstance(value, str):
        try:
            parsed = json.loads(value)
            return parsed if isinstance(parsed, dict) else None
        except Exception:
            return None
    return None

def fetch_pqp_plan_node(state: WbsExtractionState) -> WbsExtractionState:
    """Fetch the PQP plan asset and attach its full, unmodified JSON to state.
    No fallback to projects column; if not present, leave as None.
    """
    try:
        assets = fetch_assets_by_type.invoke({
            "project_id": state["project_id"],
            "asset_type": "plan",
        }) or []
        pqp_asset: Optional[Dict[str, Any]] = None
        for a in assets:
            meta = _coerce_json_obj(a.get("metadata"))
            if meta and meta.get("plan_type") == "pqp":
                pqp_asset = a
                break  # assets are ordered by created_at DESC
        if not pqp_asset:
            return {**state, "pqp_plan_json": None}
        content_obj = _coerce_json_obj(pqp_asset.get("content"))
        return {**state, "pqp_plan_json": content_obj}
    except Exception:
        return {**state, "pqp_plan_json": None}

@langsmith.traceable
def generate_initial_structure_node(state: WbsExtractionState) -> WbsExtractionState:
    if not state["txt_project_documents"]:
        return {**state, "wbs_structure": {"nodes": []}}
    
    combined_content = "\n\n".join([f"Document: {doc['file_name']} (ID: {doc['id']})\n{doc['content']}" for doc in state["txt_project_documents"]])
    ref_db_text = "\n".join([f"UUID: {ref['id']}, Spec ID: {ref.get('spec_id', '')}, Name: {ref.get('spec_name', '')}, Org: {ref.get('org_identifier', '')}" for ref in state["reference_database"]])
    pqp_json_str = json.dumps(state.get("pqp_plan_json"), ensure_ascii=False) if state.get("pqp_plan_json") is not None else "null"

    prompt = INITIAL_STRUCTURE_GENERATION_PROMPT.format(
        document_content=combined_content,
        reference_standards=ref_db_text,
        pqp_json=pqp_json_str,
    )
    
    structured_llm = llm.with_structured_output(InitialWbsGenerationResponse, method="json_mode")
    response = structured_llm.invoke(prompt)
    
    return {**state, "wbs_structure": response.dict()}

def assign_uuids_node(state: WbsExtractionState) -> WbsExtractionState:
    nodes = state["wbs_structure"]["nodes"]
    temp_id_to_uuid = {node["id"]: str(uuid.uuid4()) for node in nodes}
    
    for node in nodes:
        node["id"] = temp_id_to_uuid[node["id"]]
        if node["parentId"]:
            node["parentId"] = temp_id_to_uuid[node["parentId"]]
    
    return state

def identify_leaf_nodes(state: WbsExtractionState) -> WbsExtractionState:
    nodes = state["wbs_structure"]["nodes"]
    parent_ids = set(node["id"] for node in nodes if any(n["parentId"] == node["id"] for n in nodes))
    
    for node in nodes:
        node["is_leaf_node"] = node["id"] not in parent_ids
    
    return state

@langsmith.traceable
def populate_descriptions_node(state: WbsExtractionState) -> WbsExtractionState:
    wbs_str = json.dumps(state["wbs_structure"], indent=2)
    prompt = POPULATE_DESCRIPTIONS_SYSTEM_PROMPT + f"\nGenerate updates ONLY for 'description' field of leaf nodes. Do not change other fields.\nCURRENT WBS:\n{wbs_str}"
    structured_llm = llm.with_structured_output(DescriptionUpdates, method="json_mode")
    response = structured_llm.invoke(prompt)
    for update in response.updates:
        for node in state["wbs_structure"]["nodes"]:
            if node["id"] == update.id and node.get("is_leaf_node"):
                node["description"] = update.description
    return state

@langsmith.traceable
def populate_specifications_node(state: WbsExtractionState) -> WbsExtractionState:
    wbs_str = json.dumps(state["wbs_structure"], indent=2)
    prompt = POPULATE_SPECIFICATIONS_SYSTEM_PROMPT + f"\nGenerate updates ONLY for specification fields of leaf nodes.\nCURRENT WBS:\n{wbs_str}"
    structured_llm = llm.with_structured_output(SpecificationUpdates, method="json_mode")
    response = structured_llm.invoke(prompt)
    for update in response.updates:
        for node in state["wbs_structure"]["nodes"]:
            if node["id"] == update.id and node.get("is_leaf_node"):
                node["specification_reasoning"] = update.specification_reasoning
                node["applicable_specifications"] = update.applicable_specifications
                node["applicable_specification_uuids"] = update.applicable_specification_uuids
                node["advisory_specifications"] = update.advisory_specifications
    return state

@langsmith.traceable
def populate_itp_info_node(state: WbsExtractionState) -> WbsExtractionState:
    wbs_str = json.dumps(state["wbs_structure"], indent=2)
    pqp_json_str = json.dumps(state.get("pqp_plan_json"), ensure_ascii=False) if state.get("pqp_plan_json") is not None else "null"
    prompt = (
        POPULATE_ITP_INFO_SYSTEM_PROMPT
        + "\n\nPQP_JSON (full, unmodified):\n"
        + pqp_json_str
        + f"\n\nGenerate updates ONLY for 'itp_reasoning' and 'itp_required' fields of leaf nodes. Do not change other fields.\nCURRENT WBS:\n{wbs_str}"
    )
    structured_llm = llm.with_structured_output(ItpUpdates, method="json_mode")
    response = structured_llm.invoke(prompt)
    for update in response.updates:
        for node in state["wbs_structure"]["nodes"]:
            if node["id"] == update.id and node.get("is_leaf_node"):
                node["itp_reasoning"] = update.itp_reasoning
                node["itp_required"] = update.itp_required
    return state

@langsmith.traceable
def populate_quality_requirements_node(state: WbsExtractionState) -> WbsExtractionState:
    wbs_str = json.dumps(state["wbs_structure"], indent=2)
    prompt = POPULATE_QUALITY_REQUIREMENTS_SYSTEM_PROMPT + f"\nGenerate updates ONLY for 'specific_quality_requirements' field of leaf nodes. Do not change other fields.\nCURRENT WBS:\n{wbs_str}"
    structured_llm = llm.with_structured_output(QualityUpdates, method="json_mode")
    response = structured_llm.invoke(prompt)
    for update in response.updates:
        for node in state["wbs_structure"]["nodes"]:
            if node["id"] == update.id and node.get("is_leaf_node"):
                node["specific_quality_requirements"] = update.specific_quality_requirements
    return state

def store_wbs_node(state: WbsExtractionState) -> WbsExtractionState:
    from tools.db_tools import save_wbs_to_project
    nodes = state["wbs_structure"]["nodes"] if state.get("wbs_structure") else []
    wbs_json = json.dumps(nodes)
    # legacy save
    try:
        save_wbs_to_project.invoke({"project_id": state["project_id"], "wbs_json": wbs_json})
    except Exception:
        pass
    # assets save (as plan asset type 'plan' with name 'WBS')
    try:
        source_document_ids = [doc.get("id") for doc in (state.get("txt_project_documents") or []) if doc.get("id")]
    except Exception:
        source_document_ids = []
    upsert_asset.invoke({
        "project_id": state["project_id"],
        "asset_type": "plan",
        "name": "WBS",
        "content": {
            "title": "WBS",
            "nodes": nodes,
            "summary": {
                "total_nodes": len(nodes),
                "leaf_nodes": sum(1 for n in nodes if n.get("is_leaf_node")),
            }
        },
        "metadata": {
            "plan_type": "wbs",
            "category": "structure",
            "tags": ["wbs", "structure", "work-packages"],
            "source_document_ids": source_document_ids,
        },
        "document_number": None,
    })
    return state

builder = StateGraph(WbsExtractionState, input=InputState, output=OutputState)
builder.add_node("fetch_reference_db", fetch_reference_database_node)
builder.add_node("fetch_pqp_plan", fetch_pqp_plan_node)
builder.add_node("generate_structure", generate_initial_structure_node)
builder.add_node("assign_uuids", assign_uuids_node)
builder.add_node("identify_leaf_nodes", identify_leaf_nodes)
builder.add_node("populate_descriptions", populate_descriptions_node)
builder.add_node("populate_specifications", populate_specifications_node)
builder.add_node("populate_itp", populate_itp_info_node)
builder.add_node("populate_quality", populate_quality_requirements_node)
builder.add_node("store_wbs", store_wbs_node)

builder.add_edge(START, "fetch_reference_db")
builder.add_edge("fetch_reference_db", "fetch_pqp_plan")
builder.add_edge("fetch_pqp_plan", "generate_structure")
builder.add_edge("generate_structure", "assign_uuids")
builder.add_edge("assign_uuids", "identify_leaf_nodes")
builder.add_edge("identify_leaf_nodes", "populate_descriptions")
builder.add_edge("populate_descriptions", "populate_specifications")
builder.add_edge("populate_specifications", "populate_itp")
builder.add_edge("populate_itp", "populate_quality")
builder.add_edge("populate_quality", "store_wbs")
builder.add_edge("store_wbs", END)

wbs_extraction_graph = builder.compile(checkpointer=SqliteSaver.from_conn_string('checkpoints.db'))

# Description: Subgraph for extracting Work Breakdown Structure (WBS) without caching, using state inputs and db_tools. from langchain_core.tools import tool

@tool
def generate_metadata_card(input: str) -> str:
    """Tool to generate metadata card, querying Supabase."""
    # Placeholder: Integrate with Supabase on port 8000/8001
    return "Metadata card generated"

# Description: Tools for metadata card generation with DB integration.
# Source: From agents V7 metadata tools. import psycopg2
from langchain_core.tools import tool
import json
import logging

def get_db_connection():
    return psycopg2.connect(
        host="127.0.0.1",
        port="6543",
        database="postgres",
        user="postgres.projectpro",
        password="7c9cc7162a66bf353e240e15016ff7b70e3e5d09397bf62bbde8c11f239e3f30"
    )

logger = logging.getLogger(__name__)

@tool
def fetch_document_ids_by_project(project_id: str) -> list[str]:
    """Fetch all document IDs for a given project_id from DB."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute("SELECT id FROM documents WHERE project_id = %s", (project_id,))
        results = cursor.fetchall()
    conn.close()
    return [r[0] for r in results]

@tool
def fetch_uploaded_document_info(document_ids: list[str]) -> list[dict]:
    """Fetch uploaded document metadata from DB."""
    if not document_ids:
        return []
    conn = get_db_connection()
    with conn.cursor() as cursor:
        placeholders = ','.join(['%s'] * len(document_ids))
        cursor.execute(f"SELECT id, file_name, blob_url, project_id FROM documents WHERE id IN ({placeholders})", document_ids)
        results = cursor.fetchall()
    conn.close()
    return [{"id": r[0], "file_name": r[1], "blob_url": r[2], "project_id": r[3]} for r in results]

@tool
def save_extracted_document_content(document_id: str, content: str) -> bool:
    """Save extracted content to DB."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute("UPDATE documents SET raw_content = %s, status = 'content_extracted', updated_at = NOW() WHERE id = %s", (content, document_id))
        conn.commit()
        success = cursor.rowcount > 0
    conn.close()
    return success

@tool
def save_wbs_to_project(project_id: str, wbs_json: str) -> bool:
    """Save extracted WBS JSON to projects table."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute("UPDATE projects SET wbs = %s, wbs_extracted_at = NOW() WHERE id = %s", (wbs_json, project_id))
        conn.commit()
        success = cursor.rowcount > 0
    conn.close()
    return success

ALLOWED_PLAN_COLUMNS = {
    "pqp_plan_json",
    "emp_plan_json",
    "ohsmp_plan_json",
    "tmp_plan_json",
    "construction_program_json",
}

@tool
def fetch_project_documents_with_content(project_id: str) -> list[dict]:
    """Fetch project documents that have extracted raw_content."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute(
            """
            SELECT id, file_name, COALESCE(raw_content, '') AS raw_content
            FROM documents
            WHERE project_id = %s
              AND status <> 'deleted'
              AND raw_content IS NOT NULL
            ORDER BY updated_at DESC
            """,
            (project_id,),
        )
        results = cursor.fetchall()
    conn.close()
    return [{"id": str(r[0]), "file_name": r[1], "content": r[2]} for r in results]

@tool
def fetch_all_project_documents(project_id: str) -> list[dict]:
    """Fetch all project documents (including those without extracted content), excluding deleted."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute(
            """
            SELECT id, file_name, COALESCE(raw_content, '') AS raw_content
            FROM documents
            WHERE project_id = %s
              AND status <> 'deleted'
            ORDER BY updated_at DESC
            """,
            (project_id,),
        )
        results = cursor.fetchall()
    conn.close()
    return [{"id": str(r[0]), "file_name": r[1], "content": r[2]} for r in results]

@tool
def save_management_plan_to_project(project_id: str, column_name: str, plan_json: str) -> bool:
    """Save management plan JSON to the projects table for a whitelisted column."""
    if column_name not in ALLOWED_PLAN_COLUMNS:
        raise ValueError("Invalid plan column name")
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute(
            f"UPDATE projects SET {column_name} = %s, updated_at = NOW() WHERE id = %s",
            (plan_json, project_id),
        )
        conn.commit()
        success = cursor.rowcount > 0
    conn.close()
    return success

# =========================
# Assets table integrations
# =========================

@tool
def upsert_asset(
    project_id: str,
    asset_type: str,
    name: str,
    content: dict,
    document_number: str | None = None,
    metadata: dict | None = None,
) -> str:
    """Create or update an asset. If document_number is provided, uses unique constraint to upsert; otherwise matches on (project_id, asset_type, name). Returns asset_id."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        if document_number:
            # Upsert using unique docnum per project/type constraint
            # Prefer key-based upsert to avoid dependency on a named constraint
            cursor.execute(
                """
                INSERT INTO public.assets (project_id, asset_type, name, document_number, content, metadata)
                VALUES (%s, %s, %s, %s, %s::jsonb, %s::jsonb)
                ON CONFLICT ON CONSTRAINT assets_unique_docnum_per_project_type
                DO UPDATE SET
                  name = EXCLUDED.name,
                  content = EXCLUDED.content,
                  metadata = EXCLUDED.metadata,
                  updated_at = NOW()
                RETURNING id
                """,
                (project_id, asset_type, name, document_number, json.dumps(content), json.dumps(metadata) if metadata is not None else None),
            )
            asset_id = cursor.fetchone()[0]
            conn.commit()
            conn.close()
            return str(asset_id)
        else:
            # Attempt to find existing by name
            cursor.execute(
                """
                SELECT id FROM public.assets
                WHERE project_id = %s AND asset_type = %s AND name = %s
                ORDER BY created_at DESC
                LIMIT 1
                """,
                (project_id, asset_type, name),
            )
            row = cursor.fetchone()
            if row:
                asset_id = row[0]
                cursor.execute(
                    """
                    UPDATE public.assets
                    SET content = %s::jsonb,
                        metadata = COALESCE(%s::jsonb, metadata),
                        updated_at = NOW()
                    WHERE id = %s
                    RETURNING id
                    """,
                    (json.dumps(content), json.dumps(metadata) if metadata is not None else None, asset_id),
                )
                _ = cursor.fetchone()[0]
                conn.commit()
                conn.close()
                return str(asset_id)
            else:
                cursor.execute(
                    """
                    INSERT INTO public.assets (project_id, asset_type, name, content, metadata)
                    VALUES (%s, %s, %s, %s::jsonb, %s::jsonb)
                    RETURNING id
                    """,
                    (project_id, asset_type, name, json.dumps(content), json.dumps(metadata) if metadata is not None else None),
                )
                asset_id = cursor.fetchone()[0]
                conn.commit()
                conn.close()
                return str(asset_id)

@tool
def fetch_assets_by_type(project_id: str, asset_type: str) -> list[dict]:
    """Fetch assets for a project filtered by type."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute(
            """
            SELECT id, name, document_number, status, content, metadata, created_at, updated_at
            FROM public.assets
            WHERE project_id = %s AND asset_type = %s
            ORDER BY created_at DESC
            """,
            (project_id, asset_type),
        )
        rows = cursor.fetchall()
    conn.close()
    result: list[dict] = []
    for r in rows:
        result.append(
            {
                "id": str(r[0]),
                "name": r[1],
                "document_number": r[2],
                "status": r[3],
                "content": r[4],
                "metadata": r[5],
                "created_at": r[6].isoformat() if r[6] else None,
                "updated_at": r[7].isoformat() if r[7] else None,
            }
        )
    return result

@tool
def upsert_qse_asset(
    project_id: str,
    asset_type: str,
    name: str,
    content: dict,
    document_number: str | None = None,
    metadata: dict | None = None,
) -> str:
    """QSE-specific upsert that avoids reliance on DB ON CONFLICT constraints.

    Behavior:
    - If document_number provided, select by (project_id, asset_type, document_number) and update/insert
    - Else, select by (project_id, asset_type, name) and update/insert
    Returns asset_id.
    """
    # Always insert new asset; no uniqueness or upsert behavior
    conn = get_db_connection()
    with conn.cursor() as cursor:
        if document_number:
            cursor.execute(
                """
                INSERT INTO public.assets (project_id, asset_type, name, document_number, content, metadata)
                VALUES (%s, %s, %s, %s, %s::jsonb, %s::jsonb)
                RETURNING id
                """,
                (
                    project_id,
                    asset_type,
                    name,
                    document_number,
                    json.dumps(content),
                    json.dumps(metadata) if metadata is not None else None,
                ),
            )
        else:
            cursor.execute(
                """
                INSERT INTO public.assets (project_id, asset_type, name, content, metadata)
                VALUES (%s, %s, %s, %s::jsonb, %s::jsonb)
                RETURNING id
                """,
                (project_id, asset_type, name, json.dumps(content), json.dumps(metadata) if metadata is not None else None),
            )
        asset_id = cursor.fetchone()[0]
        conn.commit()
        conn.close()
        return str(asset_id)

@tool
def save_document_metadata(document_id: str, document_metadata: dict) -> bool:
    """Create a new 'document' asset from extracted metadata and link it to the document via documents.asset_id.

    Behavior (simple):
    - Reads project_id and file_name from public.documents
    - Inserts a new row in public.assets with:
        - asset_type='document'
        - name = metadata.name if provided else file_name
        - document_number = metadata.document_number (can be null)
        - content = { document_id, file_name, type? }
        - metadata = { category: metadata.category || 'Other', revision: metadata.revision }
    - Updates public.documents.asset_id with the new asset id
    - Returns True on success, False otherwise
    """
    logger.info(
        "save_document_metadata called",
        extra={
            "document_id": document_id,
            "document_metadata": document_metadata,
        },
    )
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            # 1) Get project_id and file_name from documents
            cursor.execute(
                """
                SELECT project_id, file_name
                FROM public.documents
                WHERE id = %s
                """,
                (document_id,),
            )
            row = cursor.fetchone()
            if not row:
                logger.error("save_document_metadata: document not found", extra={"document_id": document_id})
                return False
            project_id, file_name = row[0], row[1]

            name = (document_metadata or {}).get("name") or file_name
            extracted_doc_number = (document_metadata or {}).get("document_number")
            revision = (document_metadata or {}).get("revision")
            doc_type = (document_metadata or {}).get("type")
            category = (document_metadata or {}).get("category") or "Other"

            logger.info(
                "save_document_metadata: prepared fields",
                extra={
                    "project_id": str(project_id) if project_id else None,
                    "file_name": file_name,
                    "doc_name": name,
                    "extracted_document_number": extracted_doc_number,
                    "revision": revision,
                    "type": doc_type,
                    "category": category,
                },
            )

            content_payload = {
                "document_id": document_id,
                "file_name": file_name,
            }
            if doc_type is not None:
                content_payload["type"] = doc_type
            metadata_payload = {
                "category": category,
                "revision": revision,
                "document_number": extracted_doc_number,
            }

            # 2) Insert new asset row
            logger.debug("save_document_metadata: inserting asset row (no duplicate check)")
            cursor.execute(
                """
                INSERT INTO public.assets (
                    project_id, asset_type, name, document_number, content, metadata
                )
                VALUES (%s, 'document', %s, %s, %s::jsonb, %s::jsonb)
                RETURNING id
                """,
                (
                    project_id,
                    name,
                    str(document_id),
                    json.dumps(content_payload),
                    json.dumps(metadata_payload),
                ),
            )
            asset_id = cursor.fetchone()[0]
            logger.info("save_document_metadata: asset inserted", extra={"asset_id": str(asset_id)})

            # 3) Link asset to document (strict, no fallback)
            logger.debug("save_document_metadata: linking asset to document")
            cursor.execute(
                """
                UPDATE public.documents
                SET asset_id = %s,
                    updated_at = NOW()
                WHERE id = %s
                """,
                (asset_id, document_id),
            )
            if cursor.rowcount == 0:
                logger.error(
                    "save_document_metadata: linking update affected 0 rows",
                    extra={"document_id": document_id, "asset_id": str(asset_id)},
                )
                conn.rollback()
                return False

            conn.commit()
            logger.info("save_document_metadata: success", extra={"document_id": document_id, "asset_id": str(asset_id)})
            return True
    except Exception as e:
        try:
            conn.rollback()
        except Exception:
            pass
        logger.exception("save_document_metadata: exception raised", extra={"document_id": document_id})
        return False
    finally:
        conn.close()
@tool
def fetch_reference_documents() -> list[dict]:
    """Fetch all reference documents metadata from DB."""
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute("SELECT id, spec_id, spec_name, org_identifier FROM reference_documents ORDER BY org_identifier, spec_id")
        results = cursor.fetchall()
    conn.close()
    return [{"id": str(r[0]), "spec_id": r[1], "spec_name": r[2], "org_identifier": r[3]} for r in results]

# Description: DB tools for fetching/saving document info.
# Source: Ported from agents_v7 document_content_extraction.py. Note: Easy to swap to Supabase URL—replace connect() with URL string. 

@tool
def save_lbs_and_mapping_to_project(project_id: str, lbs_json: str, mapping_json: str | None = None) -> bool:
    """Save LBS adjacency list and optional WBS-LBS mapping JSON to the projects table.

    - lbs_json: JSON string representing an adjacency list (array of nodes)
    - mapping_json: JSON string for wbs_lbs_mapping object (can be null)
    """
    conn = get_db_connection()
    try:
        with conn.cursor() as cursor:
            cursor.execute(
                """
                UPDATE public.projects
                SET lbs = %s::jsonb,
                    wbs_lbs_mapping = COALESCE(%s::jsonb, wbs_lbs_mapping),
                    updated_at = NOW()
                WHERE id = %s
                """,
                (lbs_json, mapping_json, project_id),
            )
            conn.commit()
            return cursor.rowcount > 0
    except Exception:
        try:
            conn.rollback()
        except Exception:
            pass
        return False
    finally:
        conn.close()from langchain_core.tools import tool

@tool
def create_master_cache_tool(input: str) -> str:
    """Tool to create master cache."""
    # Placeholder: Implement caching logic, e.g., to Supabase
    return "Master cache created"

@tool
def create_project_docs_cache_tool(input: str) -> str:
    """Tool to create project docs cache."""
    # Placeholder: Implement logic
    return "Docs cache created"

# Description: Tools for caching operations.
# Source: Adapted from agents V7 cache tools. import os
from azure.storage.blob import generate_blob_sas, BlobSasPermissions
from azure.ai.documentintelligence import DocumentIntelligenceClient
from azure.core.credentials import AzureKeyCredential
from datetime import datetime, timedelta
from langchain_core.tools import tool
from dotenv import load_dotenv
from typing import Dict, Any
import logging

load_dotenv()

AZURE_STORAGE_ACCOUNT_NAME = os.getenv("AZURE_STORAGE_ACCOUNT_NAME")
AZURE_STORAGE_ACCOUNT_KEY = os.getenv("AZURE_STORAGE_ACCOUNT_KEY")
AZURE_STORAGE_CONTAINER_DOCUMENTS = os.getenv("AZURE_STORAGE_CONTAINER_DOCUMENTS", "documents")
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
AZURE_DOCUMENT_INTELLIGENCE_API_KEY = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_API_KEY")

logger = logging.getLogger(__name__)

@tool
def generate_sas_token(blob_path: str) -> str:
    """Generate SAS token for Azure blob access (read)."""
    sas_token = generate_blob_sas(
        account_name=AZURE_STORAGE_ACCOUNT_NAME,
        container_name=AZURE_STORAGE_CONTAINER_DOCUMENTS,
        blob_name=blob_path,
        account_key=AZURE_STORAGE_ACCOUNT_KEY,
        permission=BlobSasPermissions(read=True),
        expiry=datetime.utcnow() + timedelta(hours=2)
    )
    return f"https://{AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{AZURE_STORAGE_CONTAINER_DOCUMENTS}/{blob_path}?{sas_token}"

@tool
def build_asset_attachment_blob_path(asset_id: str, filename: str, asset_row_id: str | None = None) -> str:
    """Return standardized blob path for asset attachments: attachments/{asset_id}/[asset_row_id/]{filename}."""
    if asset_row_id:
        return f"attachments/{asset_id}/{asset_row_id}/{filename}"
    return f"attachments/{asset_id}/{filename}"

@tool
def extract_document_content(blob_url: str, file_name: str) -> Dict[str, Any]:
    """Extract content from document using Azure Document Intelligence v4.0 (supports PDF, images, DOCX, XLSX, PPTX, HTML)."""
    try:
        endpoint = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT")
        key = os.getenv("AZURE_DOCUMENT_INTELLIGENCE_API_KEY")
        if not endpoint or not key:
            raise ValueError("Missing Azure Document Intelligence credentials")
        
        # Use v4.0 API with 2024-11-30 API version that supports DOCX, XLSX, PPTX, HTML
        client = DocumentIntelligenceClient(
            endpoint=endpoint, 
            credential=AzureKeyCredential(key),
            api_version="2024-11-30"
        )
        
        # Use prebuilt-read model which supports all file formats in v4.0
        poller = client.begin_analyze_document("prebuilt-read", {"urlSource": blob_url})
        result = poller.result()
        
        content = result.content if hasattr(result, 'content') else ''
        if not content:
            raise ValueError("No content extracted from document")
            
        return {"status": "success", "content": content}
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Failed to extract content from {file_name}: {error_msg}")
        return {"status": "error", "error": error_msg}

# Description: Azure tools for SAS and content extraction using Document Intelligence v4.0 API.
# Supports PDF, images (JPEG/JPG, PNG, BMP, TIFF, HEIF), and Microsoft Office files (DOCX, XLSX, PPTX) + HTML.
# Source: Ported from agents_v7 document_content_extraction.py and updated to v4.0 API. from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from sub_agents.document_content_extraction_agent import document_extraction_graph
from sub_agents.project_details_agent import project_details_graph
from sub_agents.itp_generation_agent import itp_generation_graph
from sub_agents.lbs_extraction_agent import lbs_extraction_graph
# from sub_agents.project_info_extraction_agent import project_info_extraction_graph
from sub_agents.standards_extraction_agent import standards_extraction_graph
from sub_agents.wbs_extraction_agent import wbs_extraction_graph
from sub_agents.plan_generation_agent import plan_generation_sequencer_graph
from typing_extensions import TypedDict
from typing import Optional, Annotated, List, Dict, Any
from operator import add
import logging

logger = logging.getLogger(__name__)

class OrchestratorState(TypedDict):
    project_id: str
    document_ids: Optional[List[str]]
    txt_project_documents: Annotated[List[Dict[str, Any]], add]
    standards_from_project_documents: Annotated[List[Dict[str, Any]], add]
    # Carry WBS forward from the WBS extraction subgraph directly to LBS
    wbs_structure: Optional[Dict[str, Any]]

class MainInputState(TypedDict):
    project_id: str

class MainOutputState(TypedDict):
    result: str
    error: Optional[str]
    done: bool

builder = StateGraph(OrchestratorState, input=MainInputState, output=MainOutputState)

# Add sub-agents as nodes
builder.add_node("document_extraction", document_extraction_graph)
builder.add_node("project_details", project_details_graph)
builder.add_node("itp_generation", itp_generation_graph)
builder.add_node("lbs_extraction", lbs_extraction_graph)
# builder.add_node("project_info_extraction", project_info_extraction_graph)
builder.add_node("standards_extraction", standards_extraction_graph)
builder.add_node("wbs_extraction", wbs_extraction_graph)
builder.add_node("plan_generation", plan_generation_sequencer_graph)

# Define edges for sequential flow (adjusted after removing content_extraction, cache agents, and metadata_extraction, temporarily bypassing project_info_extraction)
builder.add_edge(START, "document_extraction")
builder.add_edge("document_extraction", "project_details")
builder.add_edge("project_details", "standards_extraction")
# builder.add_edge("document_extraction", "project_info_extraction")
# builder.add_edge("project_info_extraction", "metadata_extraction")
# Insert plan generation before WBS extraction
builder.add_edge("standards_extraction", "plan_generation")
builder.add_edge("plan_generation", "wbs_extraction")
builder.add_edge("wbs_extraction", "lbs_extraction")
builder.add_edge("lbs_extraction", "itp_generation")
builder.add_edge("itp_generation", END)

# Enable checkpoints with SqliteSaver for persistent memory
memory = SqliteSaver.from_conn_string("checkpoints.db")
app = builder.compile(checkpointer=memory)  # Note: To view expandable subgraphs in Studio, invoke with 'subgraphs': true in the config

# Description: Top-level orchestrator graph composing all sub-agents.
# Sub-agents: itp_generation, lbs_extraction, standards_extraction, wbs_extraction, generate_itp, generate_wbs_lbs_metadata_cards.
# Note: project_info_extraction temporarily commented out, metadata_extraction removed.
# Uses langchain-google-genai for Gemini integration in sub-agents.
# Checkpoints enable rewinding/restarting runs using built-in LangGraph memory features.
# Source: Adapted from agents V7 main orchestration workflow. 
# Updated: Added state keys for subgraph outputs with reducers. 